<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]>
<us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230225551A1-20230720.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20230704" date-publ="20230720">
<us-bibliographic-data-application lang="EN" country="US">
<publication-reference>
<document-id>
<country>US</country>
<doc-number>20230225551</doc-number>
<kind>A1</kind>
<date>20230720</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>18186071</doc-number>
<date>20230317</date>
</document-id>
</application-reference>
<us-application-series-code>18</us-application-series-code>
<priority-claims>
<priority-claim sequence="01" kind="national">
<country>KR</country>
<doc-number>10-2020-0120328</doc-number>
<date>20200918</date>
</priority-claim>
</priority-claims>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>47</class>
<subclass>J</subclass>
<main-group>36</main-group>
<subgroup>32</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>V</subclass>
<main-group>20</main-group>
<subgroup>68</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>9</main-group>
<subgroup>31</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>G</subclass>
<main-group>19</main-group>
<subgroup>414</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classifications-cpc>
<main-cpc>
<classification-cpc>
<cpc-version-indicator><date>20180801</date></cpc-version-indicator>
<section>A</section>
<class>47</class>
<subclass>J</subclass>
<main-group>36</main-group>
<subgroup>321</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</main-cpc>
<further-cpc>
<classification-cpc>
<cpc-version-indicator><date>20220101</date></cpc-version-indicator>
<section>G</section>
<class>06</class>
<subclass>V</subclass>
<main-group>20</main-group>
<subgroup>68</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>H</section>
<class>04</class>
<subclass>N</subclass>
<main-group>9</main-group>
<subgroup>3179</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>01</class>
<subclass>G</subclass>
<main-group>19</main-group>
<subgroup>4146</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>06</class>
<subclass>F</subclass>
<main-group>3</main-group>
<subgroup>017</subgroup>
<symbol-position>L</symbol-position>
<classification-value>A</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</further-cpc>
</classifications-cpc>
<invention-title id="d2e61">VIDEO DISPLAY DEVICE AND CONTROL METHOD THEREFOR</invention-title>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>PCT/KR2021/009381</doc-number>
<date>20210721</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>18186071</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>Samsung Electronics Co., Ltd.</orgname>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
<residence>
<country>KR</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="00" designation="us-only">
<addressbook>
<last-name>CHOI</last-name>
<first-name>Yonghun</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="01" designation="us-only">
<addressbook>
<last-name>WOO</last-name>
<first-name>Jiyoung</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
<inventor sequence="02" designation="us-only">
<addressbook>
<last-name>SHIN</last-name>
<first-name>Youngsun</first-name>
<address>
<city>Suwon-si</city>
<country>KR</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
</us-bibliographic-data-application>
<abstract id="abstract">
<p id="p-0001" num="0000">An image display device according to disclosed one aspect comprises: a plate for detecting the weight of food ingredients; a projector for projecting images onto the plate; a camera for capturing food ingredients and user inputs relative to the images projected; and a controller for controlling the projector so that the changed images are outputted in response to the user inputs or changes in weight of the food ingredients.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="225.89mm" wi="127.76mm" file="US20230225551A1-20230720-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="238.93mm" wi="129.79mm" file="US20230225551A1-20230720-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="125.39mm" wi="137.92mm" file="US20230225551A1-20230720-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="136.82mm" wi="121.58mm" file="US20230225551A1-20230720-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="240.20mm" wi="152.82mm" orientation="landscape" file="US20230225551A1-20230720-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="240.20mm" wi="154.35mm" orientation="landscape" file="US20230225551A1-20230720-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="238.93mm" wi="153.42mm" orientation="landscape" file="US20230225551A1-20230720-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="123.44mm" wi="165.10mm" file="US20230225551A1-20230720-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="238.76mm" wi="152.57mm" orientation="landscape" file="US20230225551A1-20230720-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="189.91mm" wi="168.06mm" file="US20230225551A1-20230720-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="199.14mm" wi="166.96mm" file="US20230225551A1-20230720-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="241.47mm" wi="154.52mm" orientation="landscape" file="US20230225551A1-20230720-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="237.91mm" wi="153.59mm" orientation="landscape" file="US20230225551A1-20230720-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="239.61mm" wi="154.09mm" orientation="landscape" file="US20230225551A1-20230720-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a Bypass Continuation of International Application No. PCT/KR2021/009381, filed Jul. 21, 2021, which claims priority to Korean Patent Application No. 10-2020-0120328, filed Sep. 18, 2020, the disclosures of which are herein incorporated by reference in their entirety.</p>
<?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?>
<?summary-of-invention description="Summary of Invention" end="lead"?>
<heading id="h-0002" level="1">BACKGROUND</heading>
<heading id="h-0003" level="1">1. Field</heading>
<p id="p-0003" num="0002">The disclosure relates to a video display device and control method therefor. Specifically, the disclosure relates to a video display device for providing cooking information for the user through a projector and a plate.</p>
<heading id="h-0004" level="1">2. Description of Related Art</heading>
<p id="p-0004" num="0003">Users commonly cook food with various cooking tools and home appliances based on the users' experiences and intuitions.</p>
<p id="p-0005" num="0004">Such a common method is, however, sometimes inconvenient because food ingredients are measured inaccurately and an extra recipe needs to be searched for.</p>
<p id="p-0006" num="0005">Hence, a technique is required for a user to obtain cooking information and control various home appliances required for cooking in a single device.</p>
<heading id="h-0005" level="1">SUMMARY</heading>
<p id="p-0007" num="0006">The disclosure provides a virtual cooking environment for the user to experience convenience in the kitchen. The disclosure also provides an integrated platform connected with various home appliances to control a home appliance required for cooking.</p>
<p id="p-0008" num="0007">According to an aspect of the disclosure, a video display device includes a plate configured to detect a weight of a food ingredient; a projector configured to project an image onto the plate; a camera configured to capture an input of a user relative to the image projected, and the food ingredient; and a controller configured to change the image and control the projector to project the image changed, in response to a weight change of the food ingredient or the input of the user.</p>
<p id="p-0009" num="0008">The controller may control a main body to recognize the food ingredient located on the plate through the camera and output cooking information regarding the food ingredient in the image.</p>
<p id="p-0010" num="0009">The controller may control the main body to output cooking information including weight information of the food ingredient, calorie information of the food ingredient, a cooking list using the food ingredient and information about a recommended amount of the food ingredient in the image.</p>
<p id="p-0011" num="0010">The controller may control the main body to output a recipe based on a plurality of food ingredients in the image in response to recognition of the plurality of food ingredients on a surface of the plate.</p>
<p id="p-0012" num="0011">The controller may control a cutting line to be displayed on the food ingredient located on the plate, wherein the cutting line is generated based on at least one of weight information, calorie information or information about a recommended amount of the food ingredient.</p>
<p id="p-0013" num="0012">The video display device may further include a communicator configured to communicate with at least one of a server or a home appliance.</p>
<p id="p-0014" num="0013">The communicator may control the communicator to transmit a cooking command to the home appliance in response to detection of a user input about the cooking command.</p>
<p id="p-0015" num="0014">The communicator may control the communicator to transmit a cooking value based on a recipe to the home appliance in response to detection of a user input selecting the recipe based on the food ingredient.</p>
<p id="p-0016" num="0015">The communicator may control the home appliance to update a list registered in the home appliance with a portion of the food ingredient in response to separation of the food ingredient from the plate, and the home appliance may be a refrigerator.</p>
<p id="p-0017" num="0016">The controller may control the main body to output a message confirming or rejecting the updating in the image based on the separation of the food ingredient from the plate.</p>
<p id="p-0018" num="0017">The controller may control the main body to output a plurality of zones in which different cooking is performed in the image, and control the communicator to receive an input of the user determining a cooking value for each of the plurality of zones, and transmit the cooking value to the home appliance, and the home appliance may be an oven capable of multi-zone cooking.</p>
<p id="p-0019" num="0018">The controller may control the main body to output a recipe for each stage of cooking which mixes a plurality of food ingredients in the image, output a weight of a first food ingredient in real time based on input of the first food ingredient to a container for performing the cooking among the plurality of food ingredients, and output a message based on completion of the inputting of the first food ingredient. The message is output visually for display or output as sound.</p>
<p id="p-0020" num="0019">The controller may initialize an output weight in response to completion of the inputting of the first food ingredient.</p>
<p id="p-0021" num="0020">The controller may update a required amount of a second food ingredient to maintain a ratio of the second food ingredient to the first food ingredient set in the recipe in response to the input amount of the first food ingredient exceeding a required amount.</p>
<p id="p-0022" num="0021">The video display device may further include a communicator configured to communicate with at least one of a server or a home appliance, the controller may transmit the required amount of the second food ingredient corresponding to the ratio of the second food ingredient to the first food ingredient set in the recipe to the home appliance in response to completion of inputting of the first food ingredient, and the home appliance may include a water purifier or an aerated water maker.</p>
<p id="p-0023" num="0022">According to an aspect of the disclosure, a method of controlling a video display device including a projector and a plate includes detecting a weight of a food ingredient; projecting an image onto the plate; capturing the food ingredient and an input of a user about the image; and controlling the projector to output an image changed in response to a weight change of the food ingredient or the input of the user.</p>
<p id="p-0024" num="0023">The method of controlling the video display device may further include transmitting a cooking value based on a recipe to a home appliance in response to detection of a user input selecting the recipe based on the food ingredient.</p>
<p id="p-0025" num="0024">The method of controlling the video display device may further include controlling the home appliance to update a list registered in the home appliance connected to a main body with a portion of the food ingredient in response to separation of the food ingredient from the plate.</p>
<p id="p-0026" num="0025">The method of controlling the video display device may further include controlling the main body to output a recipe for each state of cooking which mixes a plurality of food ingredients in the image, outputting a weight of a first food ingredient in real time based on inputting of the first food ingredient to a container for performing the cooking among the plurality of food ingredients, and outputting a message in sound or display in response to an input amount of the first food ingredient reaching a required amount, and updating a required amount of a second food ingredient to maintain a ratio of the second food ingredient to the first food ingredient set in the recipe in response to the input amount of the first food ingredient exceeding the required amount.</p>
<p id="p-0027" num="0026">According to an aspect of the disclosure, a computer program coupled to a computing device is stored in a recording medium to carry out operations of detecting a weight of a food ingredient; projecting an image onto the plate; capturing the food ingredient and an input of a user about the image; and controlling the projector to output an image changed in response to a weight change of the food ingredient or the input of the user</p>
<p id="p-0028" num="0027">According to the disclosure, a virtual cooking environment may be provided to give convenience in the kitchen. Furthermore, connection is made with various home appliances to control a home appliance required for cooking.</p>
<p id="p-0029" num="0028">Before undertaking the DETAILED DESCRIPTION below, it may be advantageous to set forth definitions of certain words and phrases used throughout this patent document: the terms &#x201c;include&#x201d; and &#x201c;comprise,&#x201d; as well as derivatives thereof, mean inclusion without limitation; the term &#x201c;or,&#x201d; is inclusive, meaning and/or; the phrases &#x201c;associated with&#x201d; and &#x201c;associated therewith,&#x201d; as well as derivatives thereof, may mean to include, be included within, interconnect with, contain, be contained within, connect to or with, couple to or with, be communicable with, cooperate with, interleave, juxtapose, be proximate to, be bound to or with, have, have a property of, or the like; and the term &#x201c;controller&#x201d; means any device, system or part thereof that controls at least one operation, such a device may be implemented in hardware, firmware or software, or some combination of at least two of the same. It should be noted that the functionality associated with any particular controller may be centralized or distributed, whether locally or remotely.</p>
<p id="p-0030" num="0029">Moreover, various functions described below can be implemented or supported by one or more computer programs, each of which is formed from computer readable program code and embodied in a computer readable medium. The terms &#x201c;application&#x201d; and &#x201c;program&#x201d; refer to one or more computer programs, software components, sets of instructions, procedures, functions, objects, classes, instances, related data, or a portion thereof adapted for implementation in a suitable computer readable program code. The phrase &#x201c;computer readable program code&#x201d; includes any type of computer code, including source code, object code, and executable code. The phrase &#x201c;computer readable medium&#x201d; includes any type of medium capable of being accessed by a computer, such as read only memory (ROM), random access memory (RAM), a hard disk drive, a compact disc (CD), a digital video disc (DVD), or any other type of memory. A &#x201c;non-transitory&#x201d; computer readable medium excludes wired, wireless, optical, or other communication links that transport transitory electrical or other signals. A non-transitory computer readable medium includes media where data can be permanently stored and media where data can be stored and later overwritten, such as a rewritable optical disc or an erasable memory device.</p>
<p id="p-0031" num="0030">Definitions for certain words and phrases are provided throughout this patent document, those of ordinary skill in the art should understand that in many, if not most instances, such definitions apply to prior, as well as future uses of such defined words and phrases.</p>
<?summary-of-invention description="Summary of Invention" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0006" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0032" num="0031">For a more complete understanding of the present disclosure and its advantages, reference is now made to the following description taken in conjunction with the accompanying drawings, in which like reference numerals represent like parts:</p>
<p id="p-0033" num="0032"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates system in which a video display device is implemented, according to an embodiment of the disclosure.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a video display device, according to an embodiment of the disclosure.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a method of controlling a video display device, according to an embodiment of the disclosure.</p>
<p id="p-0036" num="0035"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an image output by a video display device based on a food ingredient placed on a plate, according to an embodiment.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an image output by a video display device based on a plurality of food ingredients placed on a plate, according to an embodiment.</p>
<p id="p-0038" num="0037"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an image with cutting lines created by a video display device on a food ingredient placed on a plate, according to an embodiment.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a control sequence chart between a video display device and a home appliance, according to an embodiment.</p>
<p id="p-0040" num="0039"><figref idref="DRAWINGS">FIG. <b>8</b></figref> illustrates multi-zone cooking control of a video display device, according to an embodiment.</p>
<p id="p-0041" num="0040"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a control sequence chart between a video display device and a home appliance, according to an embodiment.</p>
<p id="p-0042" num="0041"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates a control sequence chart between a video display device and a home appliance, according to another embodiment.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIGS. <b>11</b>, <b>12</b>, and <b>13</b></figref> illustrate examples of images projected onto a plate according to the control sequence chart of <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?detailed-description description="Detailed Description" end="lead"?>
<heading id="h-0007" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIGS. <b>1</b> through <b>13</b></figref>, discussed below, and the various embodiments used to describe the principles of the present disclosure in this patent document are by way of illustration only and should not be construed in any way to limit the scope of the disclosure. Those skilled in the art will understand that the principles of the present disclosure may be implemented in any suitably arranged system or device.</p>
<p id="p-0045" num="0044">Like numerals refer to like elements throughout the specification. Not all elements of embodiments of the disclosure will be described, and description of what are commonly known in the art or what overlap each other in the embodiments will be omitted. The term &#x2018;unit, module, member, or block&#x2019; may refer to what is implemented in software or hardware, and a plurality of units, modules, members, or blocks may be integrated in one component or the unit, module, member, or block may include a plurality of components, depending on the embodiment of the disclosure.</p>
<p id="p-0046" num="0045">It will be further understood that the term &#x201c;connect&#x201d; or its derivatives refer both to direct and indirect connection, and the indirect connection includes a connection over a wireless communication network.</p>
<p id="p-0047" num="0046">The term &#x201c;include (or including)&#x201d; or &#x201c;comprise (or comprising)&#x201d; is inclusive or open-ended and does not exclude additional, unrecited elements or method steps, unless otherwise mentioned.</p>
<p id="p-0048" num="0047">Throughout the specification, when it is said that a member is located &#x201c;on&#x201d; another member, it implies not only that the member is located adjacent to the other member but also that a third member exists between the two members.</p>
<p id="p-0049" num="0048">It will be understood that, although the terms first, second, third, etc., may be used herein to describe various elements, components, regions, layers and/or sections, these elements, components, regions, layers and/or sections should not be limited by these terms. These terms are only used to distinguish one element, component, region, layer or section from another region, layer or section.</p>
<p id="p-0050" num="0049">It is to be understood that the singular forms &#x201c;a,&#x201d; &#x201c;an,&#x201d; and &#x201c;the&#x201d; include plural references unless the context clearly dictates otherwise.</p>
<p id="p-0051" num="0050">Reference numerals used for method steps are just used for convenience of explanation, but not to limit an order of the steps. Thus, unless the context clearly dictates otherwise, the written order may be practiced otherwise.</p>
<p id="p-0052" num="0051">Reference will now be made in detail to embodiments of the disclosure, which are illustrated in the accompanying drawings.</p>
<p id="p-0053" num="0052"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates system in which a video display device is implemented, according to an embodiment of the disclosure, and <figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a video display device, according to an embodiment of the disclosure.</p>
<p id="p-0054" num="0053">Referring to <figref idref="DRAWINGS">FIG. <b>1</b></figref>, a system in which a video display device <b>1</b> is implemented includes the video display device <b>1</b> including a main body <b>100</b> and a plate <b>200</b>, a mobile device <b>300</b>, a server <b>400</b> and a home appliance <b>500</b>.</p>
<p id="p-0055" num="0054">The main body <b>100</b> includes a projector <b>110</b> for projecting an image onto the plate <b>200</b>, a camera <b>120</b> or an infrared sensor <b>130</b> for recognizing a food ingredient placed on the plate <b>200</b>, and a communicator <b>140</b> for communicating with a network and receiving data from the plate <b>200</b>.</p>
<p id="p-0056" num="0055">The projector <b>110</b> is equipped in the main body <b>100</b> to project an image including various information onto a surface of the plate <b>200</b>. As shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, the projector <b>110</b> is arranged on the front surface of the main body <b>100</b> to emit light toward the plate <b>200</b> so that an image may not be blocked by a hand of the user.</p>
<p id="p-0057" num="0056">The projector <b>110</b> may receive certain information from the mobile device <b>300</b>, the server <b>400</b>, and the home appliance <b>500</b> over the network, and project an image based on the received information onto the plate <b>200</b>.</p>
<p id="p-0058" num="0057">The projector <b>110</b> may project the image onto the plate <b>200</b> to output a program stored in a memory (not shown) under the control of a controller <b>150</b>. Furthermore, the projector <b>110</b> may project an image onto the plate <b>200</b> based on a user input to output information according to the user input.</p>
<p id="p-0059" num="0058">The projector <b>110</b> outputs cooking information relating to the food ingredient in the image, when the controller <b>150</b> recognizes the food ingredient placed on the plate <b>200</b> through the camera <b>120</b>. The cooking information includes at least one of weight information of the food ingredient, calorie information of the food ingredient, a cooking list using the food ingredient, or information about a daily recommended amount of the food recommendation.</p>
<p id="p-0060" num="0059">The camera <b>120</b> obtains image data by capturing the food ingredient placed on the plate <b>200</b> and an input (gesture) of the user over the plate <b>200</b>, and provides the image data to the controller <b>150</b>. The controller <b>150</b> may recognize the food ingredient placed on the plate <b>200</b> through the camera <b>120</b> and control the projector <b>110</b> to output information about the food ingredient onto the plate <b>200</b>. Furthermore, the controller <b>150</b> may recognize the input of the user over the plate <b>200</b> through the camera <b>120</b> and control the projector <b>110</b> to output a response to the input of the user onto the plate <b>200</b>.</p>
<p id="p-0061" num="0060">The infrared sensor <b>130</b> may be equipped in the main body <b>100</b> in addition to the camera <b>120</b> to detect a touch input of the user on the plate <b>200</b>. Specifically, the infrared sensor <b>130</b> may recognize a touched point when the user touches a point on the plate <b>200</b> onto which an image is projected, so that the controller <b>150</b> may control the projector <b>110</b> to output information according to the user input.</p>
<p id="p-0062" num="0061">The communicator <b>140</b> may perform call setup and data communication with a base station (BS) over a cellular network such as third generation (3G)/fourth generation (4G)/fifth generation 5G, and transmit or receive data to or from the mobile device <b>300</b>, the server <b>400</b> and the home appliance <b>500</b>. Furthermore, the communicator <b>140</b> may perform a function for short-range communication such as Bluetooth or near field communication (NFC), receive data to obtain weight information from the plate <b>200</b>, and receive certain information from the mobile device <b>300</b> and the home appliance <b>500</b>, allowing the projector <b>110</b> to output them in an image.</p>
<p id="p-0063" num="0062">The communicator <b>140</b> may transmit a cooking command corresponding to an input of the user on or over the plate <b>200</b> to the home appliance <b>500</b> when the input of the user is recognized through the camera <b>120</b> or the infrared sensor <b>130</b>. Moreover, the communicator <b>140</b> may transmit a cooking value based on a recipe to the home appliance in response to detection of a user input selecting a recipe based on the food ingredient. In this case, the cooking value based on the recipe corresponds to data received by the video display device <b>1</b> through the server <b>400</b> and stored in the memory.</p>
<p id="p-0064" num="0063">The controller <b>150</b> may control the projector <b>110</b> to display various information on the plate <b>200</b> by executing a program stored in the memory. Furthermore, the controller <b>150</b> may reflect various information received from the mobile device <b>300</b>, the server <b>400</b>, and the home appliance <b>500</b> on a program stored in the memory and control the projector <b>110</b> to output an image corresponding to a user input.</p>
<p id="p-0065" num="0064">The controller <b>150</b> may receive an image of the food ingredient from the projector <b>110</b> or the mobile device <b>300</b> and analyze the received image of the food ingredient to identify a name, a type and a weight of the food ingredient.</p>
<p id="p-0066" num="0065">The controller <b>150</b> may control the projector <b>110</b> to display a cooking list and a recipe that may use the food ingredient when the type of the food ingredient placed on the surface of the plate <b>200</b> is recognized. Furthermore, the controller <b>150</b> may control the projector <b>110</b> to display a cooking list that may use a combination of a plurality of food ingredients when the plurality of food ingredients on the surface of the plate <b>200</b> are recognized. Moreover, the controller <b>150</b> may control the projector <b>110</b> to output a recipe corresponding to a cooking list in response to an input of the user.</p>
<p id="p-0067" num="0066">The controller <b>150</b> may include at least one memory for storing a program for carrying out the following operations, and at least one processor (not shown) for executing the program. In a case that the memory and the processor are each provided in the plural, the memory and the processor may be integrated in a single chip or physically distributed.</p>
<p id="p-0068" num="0067">The plate <b>200</b> provides a surface to reflect light irradiated from the projector <b>110</b>. In other words, the plate <b>200</b> may provide a surface to reflect an image produced by the projector <b>110</b> and provide various information for the user in the image projected onto the surface.</p>
<p id="p-0069" num="0068">A food ingredient may be placed in at least a portion of the plate <b>200</b>, and the plate <b>200</b> may be divided by the projector <b>110</b> to display various information.</p>
<p id="p-0070" num="0069">Although the plate <b>200</b> is shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref> as including the form of a rectangle, the plate <b>200</b> is not limited thereto and the plate <b>200</b> may be manufactured in other various forms.</p>
<p id="p-0071" num="0070">The plate <b>200</b> may include a weight sensor <b>210</b> to detect a weight of a food ingredient placed on the plate <b>200</b>, and send the weight information to the controller <b>150</b>.</p>
<p id="p-0072" num="0071">The mobile device <b>300</b> may be connected with the video display device <b>1</b> to obtain cooking information regarding a certain food ingredient, recipe information regarding a plurality of food ingredients, or the like and provide the obtained information to the video display device <b>1</b>. Furthermore, the mobile device <b>300</b> may download a program to be executed by the video display device <b>1</b> from the server <b>400</b> and provide the program to the video display device <b>1</b>, and send a command to update the program to the video display device <b>1</b>.</p>
<p id="p-0073" num="0072">The mobile device <b>300</b> may output information about a food ingredient obtained by the camera <b>120</b> and output the information regarding the food ingredient on the screen of the mobile device <b>300</b>. In this case, the mobile device <b>300</b> may output the information about the food ingredient through the same interface as the image displayed on the plate <b>200</b>, and output the information about the food ingredient through an interface implemented in an application installed on the mobile device <b>300</b>.</p>
<p id="p-0074" num="0073">The server <b>400</b> may provide at least one of information about the food ingredient placed on the plate <b>200</b>, a recommended food list, or information about cooking of the food ingredient to the mobile device <b>300</b>. The server <b>400</b> may receive an image of the food ingredient from the main body <b>100</b> or the mobile device <b>300</b> and analyze the received image of the food ingredient to identify a name, a type and a weight of the food ingredient. Furthermore, the server <b>400</b> may receive user information from the mobile device <b>300</b> and recommend a certain food based on the user information and information about the food ingredient. Moreover, the server <b>400</b> may provide information about food ingredients required for cooking a food and information about detailed cooking stages for cooking the food to the mobile device <b>300</b>.</p>
<p id="p-0075" num="0074">The home appliance <b>500</b> may refer to any electronic device accessible by the user and capable of storing or cooking food ingredients of a food. For example, the home appliance <b>500</b> may include a refrigerator, a gas stove, an oven, an electric burner, a water purifier, a aerated water maker, a blender, a coffee machine, etc. The home appliance <b>500</b> may be equipped with Bluetooth or NFC to transmit or receive data to or from the video display device <b>1</b>.</p>
<p id="p-0076" num="0075">Features of the video display device <b>1</b> according to the disclosure and features of a system in which the video display device <b>1</b> is implemented will now be described. Respective steps of controlling performed by the video display device <b>1</b> will now be described in detail.</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a method of controlling a video display device, according to an embodiment of the disclosure. <figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an image output by a video display device based on a food ingredient placed on a plate, according to an embodiment, <figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an image output by a video display device based on a plurality of food ingredients placed on a plate, according to an embodiment, and <figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates an image with cutting lines created by a video display device on a food ingredient placed on a plate, according to an embodiment. The control method of <figref idref="DRAWINGS">FIG. <b>3</b></figref> will be described by referring to <figref idref="DRAWINGS">FIGS. <b>4</b> to <b>6</b></figref>.</p>
<p id="p-0078" num="0077">The controller <b>150</b> controls the projector <b>301</b> to project an image onto the plate <b>200</b>, in <b>301</b>. The image projected onto the plate <b>200</b> may include an interface implemented in an application installed on the mobile device <b>300</b>, or an interface implemented in an application installed on the video display device <b>1</b> itself.</p>
<p id="p-0079" num="0078">The controller <b>150</b> recognizes a food ingredient placed on the plate <b>200</b> through the camera <b>120</b>, in <b>302</b>. Referring to <figref idref="DRAWINGS">FIG. <b>4</b></figref>, the controller <b>150</b> controls the projector <b>110</b> to output the weight information of a food ingredient I<b>1</b> and calorie information of the food ingredient when the food ingredient I<b>1</b> placed on the plate <b>200</b> is recognized. In this case, the controller <b>150</b> may obtain the weight information by detecting a weight of the food ingredient I<b>1</b> through the weight sensor <b>210</b> arranged in the plate <b>200</b> or obtain the weight information in consideration of a type of the food ingredient and volume of the food ingredient by obtaining the image data through the camera <b>120</b>.</p>
<p id="p-0080" num="0079">The controller <b>150</b> outputs an image including cooking information regarding the food ingredient, in <b>304</b>. Specifically, the controller <b>150</b> may figure out the type of the food ingredient I<b>1</b> by obtaining the image data through the camera <b>120</b>, and control the projector <b>110</b> to output recipe information for a food that uses the food ingredient I<b>1</b> based on the weight information.</p>
<p id="p-0081" num="0080">Furthermore, in an embodiment, the controller <b>150</b> may simultaneously output pieces of information about a plurality of food ingredients I<b>1</b> and I<b>2</b> when the plurality of food ingredients I<b>1</b> and I<b>2</b> placed on the plate <b>200</b> are recognized. Referring to <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the controller <b>150</b> may obtain individual weight information by detecting the plurality of food ingredients I<b>1</b> and I<b>2</b> on the plate <b>200</b> with a certain time gap. For example, when detecting the second food ingredient I<b>2</b>, e.g., an egg, after detecting the first food ingredient I<b>1</b>, e.g., a tomato, the controller <b>150</b> may obtain the weight information of the second food ingredient I<b>2</b>, the egg, by subtracting the weight of the first food ingredient I<b>1</b>, the tomato, from a total weight. Once obtaining the weight information of each of the plurality of food ingredients I<b>1</b> and I<b>2</b>, the controller <b>150</b> controls the projector <b>110</b> to output the calorie information onto the plate <b>200</b> based on the type and weight information of the food ingredients. The controller <b>150</b> may also provide information about types and recipes of foods that may be made with the plurality of food ingredients I<b>1</b> and I<b>2</b>.</p>
<p id="p-0082" num="0081">Furthermore, the controller <b>150</b> may control the projector <b>110</b> to provide a cutting line on a food ingredient that needs to be subdivided.</p>
<p id="p-0083" num="0082">Referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the controller <b>150</b> may recognize a type of the food ingredient placed on the plate <b>200</b> and provide cutting lines CL<b>1</b> and CL<b>2</b> based on user information, calorie information, and a daily recommended amount. For example, the controller <b>150</b> may recognize that the food ingredient placed on the plate <b>200</b> is a salmon, and provide the cutting lines CL<b>1</b> and CL<b>2</b> based on the calorie information of the salmon. Furthermore, the controller <b>150</b> may display the cutting lines on the surface of the salmon for the user who intends to have the food to be able to cut the salmon according to the daily recommended amount when the user inputs multiple pieces of user information (e.g., age, sex, weight, etc.). In <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the first cutting line CL<b>1</b> and the second cutting line CL<b>2</b> are shown to provide daily recommended amounts for the first user and the second user, respectively. Furthermore, the controller <b>150</b> may obtain weight information of a portion of the food ingredient left by the second cutting line CL<b>2</b> and transmit the weight information to a home appliance (e.g., a refrigerator) connected with the video display device <b>1</b>.</p>
<p id="p-0084" num="0083">The controller <b>150</b> may output a recipe based on the food ingredient placed on the plate <b>200</b>, in <b>306</b>. The recipe may be provided according to data provided from the server <b>400</b> or stored in a memory (not shown), and provided in voice instructions or in video.</p>
<p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates a control sequence chart between a video display device and a home appliance, according to an embodiment.</p>
<p id="p-0086" num="0085">In an embodiment, the video display device <b>1</b> may transmit a cooking command to at least one home appliance <b>500</b> to operate the home appliance <b>500</b>. For example, in the embodiment, the home appliance <b>500</b> may be one of a gas stove, a microwave, an oven and an electric burner, and the user may control the home appliance <b>500</b> to operate the home appliance <b>500</b> through an input to the video display device <b>1</b> without inputting the cooking command directly to the home appliance <b>500</b>.</p>
<p id="p-0087" num="0086">The video display device <b>1</b> detects an input of the user about a cooking command or a selection of recipe, in <b>701</b>. For example, the video display device <b>1</b> may control the projector <b>110</b> to display an interface of an input module (not shown) of the home appliance <b>500</b> connected with the video display device <b>1</b> on the plate <b>200</b>.</p>
<p id="p-0088" num="0087">In this case, the user may make a touch input to the interface displayed on the plate <b>200</b> to transmit a cooking command to the home appliance <b>500</b>. Furthermore, the user may make a touch input to the interface displayed on the plate <b>200</b> to transmit a recipe-based cooking value to the home appliance <b>500</b>.</p>
<p id="p-0089" num="0088">The video display device <b>1</b> may control the communicator <b>140</b> to transmit the cooking command or the recipe-based cooking value input from the user to the home appliance <b>500</b>, in <b>702</b>.</p>
<p id="p-0090" num="0089">On receiving the cooking command or the recipe-based cooking value from the video display device <b>1</b>, the home appliance <b>500</b> may be operated based on the cooking command or the cooking value. For example, in a case that the home appliance <b>500</b> is a microwave, when the user inputs an operation period of time of the microwave through the interface displayed on the plate <b>200</b>, put a food ingredient into the microwave and close the door, the microwave may be automatically operated without extra button input.</p>
<p id="p-0091" num="0090">Referring to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the video display device <b>1</b> may transmit a cooking command for each of the plurality of zones Z<b>1</b> and Z<b>2</b> to an oven capable of multi-zone cooking. Specifically, the video display device <b>1</b> may control the projector <b>110</b> to display an interior image of an actual oven on the plate <b>200</b> so that different food ingredients may be divided into a first zone Z<b>1</b> and a second zone Z<b>2</b>.</p>
<p id="p-0092" num="0091">In an embodiment, when the user places salmon in the first zone Z<b>1</b> and asparagus in the second zone Z<b>2</b>, the controller <b>150</b> may display temperature and heating time suitable for cooking the salmon in the first zone Z<b>1</b> and display temperature and heating time suitable for cooking the asparagus in the second zone Z<b>2</b>. In this case, the temperature and heating time displayed in the first zone Z<b>1</b> and the second zone Z<b>2</b> may be automatically displayed based on the video display device <b>1</b> recognizing the food ingredients through the camera <b>120</b>. Furthermore, cooking values including the temperature and heating time may be automatically displayed based on the recognition of the food ingredients as described above, or may be input by the user in person to transmit the cooking command to the oven.</p>
<p id="p-0093" num="0092"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a control sequence chart between a video display device and a home appliance, according to an embodiment. In the embodiment, the home appliance <b>500</b> may be a refrigerator for storing food ingredients, or may be other various devices equipped with a memory to store information about food ingredients stored in the home appliance <b>500</b>.</p>
<p id="p-0094" num="0093">The embodiment of <figref idref="DRAWINGS">FIG. <b>9</b></figref> will now be described in detail in connection with <figref idref="DRAWINGS">FIG. <b>6</b></figref>.</p>
<p id="p-0095" num="0094">The home appliance <b>500</b> transmits a list of food ingredients stored therein to the video display device <b>1</b>, in <b>901</b>. The list is information including names, amounts, expiration dates, etc., of various food ingredients stored in the home appliance <b>500</b>. The video display device <b>1</b> capable of performing wireless communication with the home appliance <b>500</b> may request a list of food ingredients stored in the home appliance <b>500</b> from the home appliance <b>500</b> and receive information about the food ingredients stored in the home appliance <b>500</b>. Furthermore, the video display device <b>1</b> may receive information stored in the home appliance <b>500</b> in real time according to an automatic reception setting.</p>
<p id="p-0096" num="0095">When the user inputs information about food ingredients through an input device (not shown) included in the home appliance <b>500</b>, the home appliance <b>500</b> may add the food ingredient information to the list and stored the list. Furthermore, the home appliance <b>500</b> may generate a list of food ingredients stored, through a camera included in the home appliance <b>500</b>.</p>
<p id="p-0097" num="0096">The video display device <b>1</b> detects food ingredients on the plate <b>200</b> and recognizes the food ingredients included in the list, in <b>902</b>. In this case, the video display device <b>1</b> may obtain detailed information (e.g., an amount or an expiration date) of a food ingredient based on the list received from the home appliance <b>500</b> and the type of the food ingredient obtained through the camera <b>120</b>. Furthermore, the video display device <b>1</b> may recognize a food ingredient taken out from inside the home appliance <b>500</b> and receive detailed information about the recognized food ingredient.</p>
<p id="p-0098" num="0097">As shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the user may cook the food ingredient taken out from the home appliance <b>500</b> on the plate <b>200</b> and subdivide the food ingredient according to the cutting line CL provided by the video display device <b>1</b>.</p>
<p id="p-0099" num="0098">The video display device <b>903</b> detects separation of the food ingredient from the plate, in <b>903</b>. The video display device <b>1</b> may figure out an amount of the rest of the food ingredient other than the portion of the food ingredient separated according to the cutting line. Specifically, the video display device <b>903</b> may figure out the weight of the rest of the food ingredient by subtracting the weight of the portion of the food ingredient to be cooked by the user from the weight included in the list. For example, referring to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, the video display device <b>1</b> may figure out the weight of the rest of the food ingredient I<b>1</b>-<b>3</b> separated according to the second cutting line CL<b>2</b>.</p>
<p id="p-0100" num="0099">When the weight of the rest of the food ingredient is figured out, the video display device <b>1</b> outputs a recommendation message for updating the list with the remaining food ingredient, in <b>904</b>. For example, once the subdivision of the food ingredient placed on the plate <b>200</b> is completed, the video display device <b>1</b> may control the projector <b>110</b> to output a recommendation message &#x201c;Will you update the list with the remaining salmon? yes or no&#x201d; onto the plate <b>200</b>. In this case, the user may select &#x201c;yes&#x201d; to store the remaining food ingredient in the refrigerator. Furthermore, the user may select &#x201c;no&#x201d; to discard the remaining food ingredient.</p>
<p id="p-0101" num="0100">When receiving confirmation of the user about the updating from the user in <b>905</b>, the video display device <b>1</b> transmits an updated list in <b>906</b>. In another embodiment, the video display device <b>1</b> may not provide the recommendation message in <b>904</b> but may automatically transmit the updated list. In addition, when the expiration date of the food ingredient is not expired, the video display device <b>1</b> may not provide the recommendation message in <b>904</b> but may automatically transmit the updated list.</p>
<p id="p-0102" num="0101">The home appliance <b>907</b> receives the updated list from the video display device <b>1</b> and stores the updated list in <b>907</b>.</p>
<p id="p-0103" num="0102">In the meantime, the video display device <b>1</b> may provide a recipe of a food made by mixing two or more food ingredients. For example, the video display device <b>1</b> may sequentially provide processes of the recipe of a drink made by mixing a concentrate and water (or aerated water), dough made by mixing flour and water, etc. In addition, the video display device <b>1</b> may provide a guide by reflecting amounts of input food ingredients, in preparation for a failure of ratio control when the two or more food ingredients are mixed. This will now be described in connection with <figref idref="DRAWINGS">FIGS. <b>10</b> to <b>13</b></figref>. Embodiments as will be described below are merely examples, and may be applied to various foods made by mixing at least two or more food ingredients.</p>
<p id="p-0104" num="0103"><figref idref="DRAWINGS">FIG. <b>10</b></figref> illustrates a control sequence chart between a video display device and a home appliance, according to another embodiment, and <figref idref="DRAWINGS">FIGS. <b>11</b> to <b>13</b></figref> are diagrams to be referred to in describing the control sequence chart of <figref idref="DRAWINGS">FIG. <b>10</b></figref>.</p>
<p id="p-0105" num="0104">The video display device <b>1</b> outputs a recipe by which a first food ingredient and a second food ingredient are mixed, in <b>101</b>. For example, when the user selects the number of consumers and a food type, the video display device <b>1</b> may output a corresponding recipe. In this case, the recipe may include amount information and a making sequence about the food ingredients including the concentrate and the aerated water to make a strawberry soda.</p>
<p id="p-0106" num="0105">The video display device <b>1</b> detects a weight of an empty container when the user puts the empty container on the plate <b>200</b>, in <b>1002</b>. Accordingly, the video display device <b>1</b> may perform zero-point adjustment to detect the weight of a pure food ingredient by detecting the weight of the container through the weight sensor <b>210</b> equipped in the plate <b>200</b>. Referring to <figref idref="DRAWINGS">FIG. <b>11</b></figref>, when the user puts a container for making a strawberry soda on the plate <b>200</b> the video display device <b>1</b> may control the projector <b>110</b> to check that the current weight has been subjected to zero-point adjustment into 0 gram (g). When the zero-point adjustment is completed, the video display device <b>1</b> may control the projector <b>110</b> to display a required amount of the first food ingredient that the user needs to input.</p>
<p id="p-0107" num="0106">The video display device <b>1</b> detects the weight of the input first food ingredient in real time, in <b>1003</b>. For example, referring to <figref idref="DRAWINGS">FIG. <b>12</b></figref>, the video display device <b>1</b> displays the weight of the first food ingredient input by the user on the plate <b>210</b>. However, as shown in <figref idref="DRAWINGS">FIG. <b>12</b></figref>, according to recipe information R displayed on the right-hand side, when the required amount of the first food ingredient is 30 g, the user may not perform optimal cooking with the required amount of the second food ingredient suggested earlier. Hence, the video display device <b>1</b> according to the embodiment may provide a required amount of the second food ingredient corresponding to the changed first food ingredient.</p>
<p id="p-0108" num="0107">The video display device <b>1</b> determines whether the weight of the first food ingredient exceeds the required amount, in <b>1004</b>. In this case, when the inputting of the first food ingredient is completed or exceeds the required amount, the video display device <b>1</b> may output a message in sound or display.</p>
<p id="p-0109" num="0108">When the video display device <b>1</b> determines that the weight of the first food ingredient put in the container corresponds to the required amount, the video display device <b>1</b> may output a completion message or make weight initialization to identify the weight of the second food ingredient before inputting of the second food ingredient, in <b>1005</b>. Accordingly, the user may input the second food ingredient into the container to fit the required amount of the second food ingredient.</p>
<p id="p-0110" num="0109">On the other hand, when the weight of the first food ingredient put in the container exceeds the required amount, the video display device <b>1</b> updates a required amount of the second food ingredient, in <b>1006</b>. Specifically, the video display device <b>1</b> controls the projector <b>110</b> to display an amount of the second food ingredient changed to maintain the ratio between the first food ingredient and the second food ingredient suggested earlier. Referring to <figref idref="DRAWINGS">FIG. <b>13</b></figref>, the video display device <b>1</b> may provide a message to increase an input amount of the aerated water as the user exceedingly inputs the first food ingredient. Accordingly, the user may input the second food ingredient to the container to fit the changed required amount of the second food ingredient.</p>
<p id="p-0111" num="0110">As described above, the user may input the second food ingredient in person according to a guide suggested by the video display device <b>1</b>. Furthermore, according to the embodiment, the video display device <b>1</b> transmits a required amount of the second food ingredient to the home appliance <b>500</b> that provides the second food ingredient, so that the user may not control the amount of the second food ingredient in person. In this example, the home appliance <b>500</b> that receives data from the video display device <b>1</b> may be e.g., a water purifier or an aerated water maker.</p>
<p id="p-0112" num="0111">The home appliance <b>500</b> may receive the existing required amount of the second food ingredient in <b>1007</b> or receive an updated required amount of the second food ingredient in <b>1008</b>. In this case, the home appliance <b>1009</b> may provide the second food ingredient based on the received required amount without a need for the user to control the amount through the home appliance <b>1009</b>. For example, the aerated water maker may provide aerated water that fits the received required amount when detecting an input from the user to release water.</p>
<p id="p-0113" num="0112">Meanwhile, the embodiments of the disclosure may be implemented in the form of a recording medium for storing instructions to be carried out by a computer. The instructions may be stored in the form of program codes, and when executed by a processor, may generate program modules to perform operation in the embodiments of the disclosure. The recording media may correspond to computer-readable recording media.</p>
<p id="p-0114" num="0113">The computer-readable recording medium includes any type of recording medium having data stored thereon that may be thereafter read by a computer. For example, it may be a read only memory (ROM), a random access memory (RAM), a magnetic tape, a magnetic disk, a flash memory, an optical data storage device, etc.</p>
<p id="p-0115" num="0114">The machine-readable storage medium may be provided in the form of a non-transitory recording medium. The term &#x2018;non-transitory recording medium&#x2019; may mean a tangible device without including a signal, e.g., electromagnetic waves, and may not distinguish between storing data in the recording medium semi-permanently and temporarily. For example, the non-transitory recording medium may include a buffer that temporarily stores data.</p>
<p id="p-0116" num="0115">In an embodiment of the disclosure, the aforementioned method according to the various embodiments of the disclosure may be provided in a computer program product. The computer program product may be a commercial product that may be traded between a seller and a buyer. The computer program product may be distributed in the form of a storage medium (e.g., a compact disc read only memory (CD-ROM)), through an application store (e.g., Play Store&#x2122;) directly between two user devices (e.g., smart phones), or online (e.g., downloaded or uploaded). In the case of online distribution, at least part of the computer program product (e.g., a downloadable app) may be at least temporarily stored or arbitrarily created in a storage medium that may be readable to a device such as a server of the manufacturer, a server of the application store, or a relay server.</p>
<p id="p-0117" num="0116">The embodiments of the disclosure have thus far been described with reference to accompanying drawings. The disclosure may be practiced in other forms than the embodiments of the disclosure as described above without changing the technical idea or essential features of the disclosure. The above embodiments of the disclosure are only by way of example, and should not be construed in a limited sense.</p>
<p id="p-0118" num="0117">Although the present disclosure has been described with various embodiments, various changes and modifications may be suggested to one skilled in the art. It is intended that the present disclosure encompass such changes and modifications as fall within the scope of the appended claims.</p>
<?detailed-description description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text><b>1</b>. A video display device comprising:
<claim-text>a plate configured to detect a weight of a food ingredient;</claim-text>
<claim-text>a projector configured to project an image onto the plate;</claim-text>
<claim-text>a camera configured to capture an input of a user relative to the image projected, and the food ingredient; and</claim-text>
<claim-text>a controller configured to change the image and control the projector to project the image changed, in response to a weight change of the food ingredient or the input of the user.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text><b>2</b>. The video display device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the controller is configured to recognize the food ingredient located on the plate through the camera, and control the projector to project the image changed to include cooking information regarding the food ingredient.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text><b>3</b>. The video display device of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the controller is configured to control a main body to output the image changed to include the cooking information including weight information of the food ingredient, calorie information of the food ingredient, a cooking list using the food ingredient, and information about a recommended amount of the food ingredient.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text><b>4</b>. The video display device of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the controller is configured to control the projector to project a recipe based on a plurality of food ingredients in the image, in response to recognition of the plurality of food ingredients on a surface of the plate.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text><b>5</b>. The video display device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the controller is configured to control the projector to project a cutting line to be displayed on the food ingredient located on the plate, wherein the cutting line is generated based on at least one of weight information, calorie information, or information about a recommended amount of the food ingredient.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text><b>6</b>. The video display device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising: a communicator configured to communicate with at least one of a server or a home appliance.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text><b>7</b>. The video display device of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the controller is configured to control the communicator to transmit a cooking command to the home appliance in response to detection of a user input about the cooking command.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text><b>8</b>. The video display device of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the controller is configured to control the communicator to transmit a cooking value based on a recipe to the home appliance, in response to detection of a user input selecting the recipe based on the food ingredient.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text><b>9</b>. The video display device of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein:
<claim-text>the communicator is configured to control the home appliance to update a list registered in the home appliance with a portion of the food ingredient, in response to separation of the food ingredient from the plate; and</claim-text>
<claim-text>the home appliance is a refrigerator.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text><b>10</b>. The video display device of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the controller is configured to control a main body to output a message confirming or rejecting updating in the image based on separation of the food ingredient from the plate.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text><b>11</b>. The video display device of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the controller is configured to:
<claim-text>control a main body to output the image changed to include a plurality of zones for which different cooking is performed by a home appliance, and</claim-text>
<claim-text>control the communicator to receive an input of the user determining a cooking value for each of the plurality of zones, and</claim-text>
<claim-text>transmit the cooking value for each of the plurality of zones to the home appliance, wherein the home appliance is an oven capable of multi-zone cooking.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text><b>12</b>. The video display device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the controller is configured to control a main body to:
<claim-text>output a recipe for each stage of cooking which mixes a plurality of food ingredients in the image;</claim-text>
<claim-text>output a weight of a first food ingredient in real time based on input of the first food ingredient to a container for performing the stage of cooking, the first food ingredient among the plurality of food ingredients; and</claim-text>
<claim-text>output a message based on completion of the inputting of the first food ingredient, wherein the message is output visually for display or output as sound.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text><b>13</b>. The video display device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the controller is configured to initialize an output weight in response to completion of the inputting of the first food ingredient.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text><b>14</b>. The video display device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the controller is configured to update a required amount of a second food ingredient to maintain a ratio of the second food ingredient to the first food ingredient set in the recipe, in response to the inputted amount of the first food ingredient exceeding a required amount of the first food ingredient.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text><b>15</b>. The video display device of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein:
<claim-text>the main body further comprises a communicator configured to communicate with at least one of a server or a home appliance;</claim-text>
<claim-text>the controller is configured to transmit, to the home appliance, a required amount of a second food ingredient corresponding to a ratio of the second food ingredient to the first food ingredient set in the recipe, in response to completion of inputting of the first food ingredient; and</claim-text>
<claim-text>the home appliance comprises a water purifier or an aerated water maker.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text><b>16</b>. A method comprising:
<claim-text>detecting a weight of a food ingredient, the food ingredient located on a plate;</claim-text>
<claim-text>projecting, by a projector, an image onto the plate;</claim-text>
<claim-text>capturing, by a camera, an input of a user relative to the image projected, and the food ingredient; and</claim-text>
<claim-text>in response to a weight change of the food ingredient or the input of the user:</claim-text>
<claim-text>changing, by a controller, the image; and</claim-text>
<claim-text>projecting, by the projector, the image changed.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text><b>17</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising:
<claim-text>controlling a main body to output a recipe for each stage of cooking which mixes a plurality of food ingredients in the image;</claim-text>
<claim-text>outputting a weight of a first food ingredient in real time, based on input of the first food ingredient to a container,
<claim-text>wherein the container is for performing the stage of cooking, and</claim-text>
<claim-text>wherein the first food ingredient is from among the plurality of food ingredients; and</claim-text>
</claim-text>
<claim-text>outputting, visually for display or as a sound, a message based on completion of the inputting of the first food ingredient into the container.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising initializing an output weight in response to completion of the inputting of the first food ingredient into the container.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text><b>19</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising in response to the inputted amount of the first food ingredient exceeding a required amount of the first food ingredient, updating a required amount of a second food ingredient to maintain a ratio of the second food ingredient to the first food ingredient set in the recipe.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text><b>20</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising in response to completion of inputting of the first food ingredient into the container, transmitting, to a home appliance, a required amount of a second food ingredient corresponding to a ratio of the second food ingredient to the first food ingredient set in the recipe,
<claim-text>wherein the main body further comprises a communicator configured to communicate with at least one of a server or the home appliance, and</claim-text>
<claim-text>wherein the home appliance comprises a water purifier or an aerated water maker.</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-application>
