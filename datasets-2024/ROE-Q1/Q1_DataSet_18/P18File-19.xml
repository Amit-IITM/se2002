<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]>
<us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230225620A1-20230720.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20230704" date-publ="20230720">
<us-bibliographic-data-application lang="EN" country="US">
<publication-reference>
<document-id>
<country>US</country>
<doc-number>20230225620</doc-number>
<kind>A1</kind>
<date>20230720</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>18184608</doc-number>
<date>20230315</date>
</document-id>
</application-reference>
<us-application-series-code>18</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>01</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>16</class>
<subclass>H</subclass>
<main-group>10</main-group>
<subgroup>60</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>16</class>
<subclass>H</subclass>
<main-group>50</main-group>
<subgroup>30</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classifications-cpc>
<main-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>015</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</main-cpc>
<further-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>4806</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>746</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>7267</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20180101</date></cpc-version-indicator>
<section>G</section>
<class>16</class>
<subclass>H</subclass>
<main-group>10</main-group>
<subgroup>60</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20180101</date></cpc-version-indicator>
<section>G</section>
<class>16</class>
<subclass>H</subclass>
<main-group>50</main-group>
<subgroup>30</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</further-cpc>
</classifications-cpc>
<invention-title id="d2e43">DETECTION OF ELEVATED BODY TEMPERATURE USING CIRCADIAN RHYTHMS SYSTEMS AND METHODS</invention-title>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>PCT/US2021/051484</doc-number>
<date>20210922</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>18184608</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>63082385</doc-number>
<date>20200923</date>
</document-id>
</us-provisional-application>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>FLIR Systems AB</orgname>
<address>
<city>T&#xe4;by</city>
<country>SE</country>
</address>
</addressbook>
<residence>
<country>SE</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="00" designation="us-only">
<addressbook>
<last-name>Sandsten</last-name>
<first-name>Jonas</first-name>
<address>
<city>T&#xe4;by</city>
<country>SE</country>
</address>
</addressbook>
</inventor>
<inventor sequence="01" designation="us-only">
<addressbook>
<last-name>Ramberg</last-name>
<first-name>Nicklas Bahram</first-name>
<address>
<city>T&#xe4;by</city>
<country>SE</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
</us-bibliographic-data-application>
<abstract id="abstract">
<p id="p-0001" num="0000">Various techniques are disclosed to provide for improved detection of elevated human body temperatures. In one example, a method includes receiving a thermal image. The method also includes processing the thermal image to detect a person's face and a characteristic associated with the person. The method also includes selecting a circadian rhythm model associated with the detected characteristic.</p>
<p id="p-0002" num="0000">The method also includes determining an expected body temperature using the circadian rhythm model. The method also includes extracting a temperature associated with the person's face from the thermal image. The method also includes comparing the extracted temperature with the expected body temperature to detect an elevated body temperature condition. Additional methods and systems are also provided.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="137.50mm" wi="158.75mm" file="US20230225620A1-20230720-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="166.03mm" wi="152.99mm" orientation="landscape" file="US20230225620A1-20230720-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="173.40mm" wi="147.15mm" orientation="landscape" file="US20230225620A1-20230720-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="205.49mm" wi="104.56mm" orientation="landscape" file="US20230225620A1-20230720-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="129.20mm" wi="139.19mm" file="US20230225620A1-20230720-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="227.58mm" wi="155.28mm" file="US20230225620A1-20230720-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="171.03mm" wi="155.28mm" file="US20230225620A1-20230720-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?>
<heading id="h-0001" level="1">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0003" num="0001">This application is a continuation of International Patent Application No. PCT/US2021/051484 filed Sep. 22, 2021 and entitled &#x201c;DETECTION OF ELEVATED BODY TEMPERATURE USING CIRCADIAN RHYTHMS SYSTEMS AND METHODS,&#x201d; which claims the benefit of and priority to U.S. Provisional Patent Application No. 63/082,385 filed Sep. 23, 2020 and entitled &#x201c;DETECTION OF ELEVATED BODY TEMPERATURE USING CIRCADIAN RHYTHMS SYSTEMS AND METHODS,&#x201d; all of which are incorporated herein by reference in their entirety.</p>
<?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?>
<?summary-of-invention description="Summary of Invention" end="lead"?>
<heading id="h-0002" level="1">TECHNICAL FIELD</heading>
<p id="p-0004" num="0002">The present invention relates generally to thermal imaging and, more particularly, to detecting elevated body temperature with thermal imaging.</p>
<heading id="h-0003" level="1">BACKGROUND</heading>
<p id="p-0005" num="0003">Thermal imaging systems are frequently used to detect the temperatures of various objects or persons in a scene. For example, in the case of human beings, such systems may be used to detect body temperature. Such systems can be particularly useful in the detection of elevated body temperatures associated with possible health conditions (e.g., infections or disease). For example, if the detected body temperature of a person is found to exceed a predetermined threshold, then the person may be identified as having an elevated body temperature and subject to further review for a possible health condition.</p>
<p id="p-0006" num="0004">Conventional detection systems typically rely on predetermined threshold temperatures. However, such approaches can fail to account for natural variations in body temperature among different persons that are not associated with health conditions. For example, persons may exhibit different body temperatures due to natural variations associated with differences in circadian rhythms, thermo-regulation, and/or physical exertion (e.g., exercise).</p>
<p id="p-0007" num="0005">Some detection systems may rely on a moving average of temperature values measured from random groups of people. However, the moving average may not be useful in circumstances where the group is diverse with persons of different ages or other characteristics (e.g., children, post-menopause, seniors, or others). In these cases, the moving average may be applicable to only a subset of the group and may not yield helpful results when applied to individual persons that vary significantly from the average for non-health related reasons.</p>
<heading id="h-0004" level="1">SUMMARY</heading>
<p id="p-0008" num="0006">Various techniques are disclosed to provide for improved detection of elevated human body temperatures. In some embodiments, such techniques may classify persons into groups associated with certain circadian rhythms so as to perform an accurate comparison of a person's body temperature to elevated body temperature threshold values associated with the group. In some embodiments, temperature values (e.g., temperature measurements) associated with multiple facial regions of a person may be extracted from thermal images and compared to provide an accurate measurement of the person's body temperature. Additional fever detection techniques are also provided.</p>
<p id="p-0009" num="0007">In one embodiment, a method includes receiving a thermal image; processing the thermal image to detect a person's face and a characteristic associated with the person; selecting a circadian rhythm model associated with the detected characteristic; determining an expected body temperature using the circadian rhythm model; extracting a temperature associated with the person's face from the thermal image; and comparing the extracted temperature with the expected body temperature to detect an elevated body temperature condition.</p>
<p id="p-0010" num="0008">In another embodiment, a system includes a thermal imager; and a logic device configured to: operate the thermal imager to capture a thermal image, process the thermal image to detect a person's face and a characteristic associated with the person, select a circadian rhythm model associated with the detected characteristic, determine an expected body temperature using the circadian rhythm model, extract a temperature associated with the person's face from the thermal image, and compare the extracted temperature with the expected body temperature to detect an elevated body temperature condition.</p>
<p id="p-0011" num="0009">The scope of the invention is defined by the claims, which are incorporated into this section by reference. A more complete understanding of embodiments of the invention will be afforded to those skilled in the art, as well as a realization of additional advantages thereof, by a consideration of the following detailed description of one or more embodiments. Reference will be made to the appended sheets of drawings that will first be described briefly.</p>
<?summary-of-invention description="Summary of Invention" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading id="h-0005" level="1">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0012" num="0010"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a block diagram of an imaging system in accordance with an embodiment of the disclosure.</p>
<p id="p-0013" num="0011"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a block diagram of a thermal imager in accordance with an embodiment of the disclosure.</p>
<p id="p-0014" num="0012"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a block diagram of an artificial neural network in accordance with an embodiment of the disclosure.</p>
<p id="p-0015" num="0013"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a thermal image undergoing processing in accordance with an embodiment of the disclosure.</p>
<p id="p-0016" num="0014"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a process of detecting elevated body temperature using circadian rhythms in accordance with an embodiment of the disclosure.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?detailed-description description="Detailed Description" end="lead"?>
<p id="p-0017" num="0015">Embodiments of the present invention and their advantages are best understood by referring to the detailed description that follows. It should be appreciated that like reference numerals are used to identify like elements illustrated in one or more of the figures.</p>
<heading id="h-0006" level="1">DETAILED DESCRIPTION</heading>
<p id="p-0018" num="0016">In accordance with embodiments discussed herein, various methods and systems are provided in which thermal images are processed to determine elevated body temperatures of human beings (e.g., persons) using a heuristic approach that accounts for temperature variances associated with the particular circadian rhythms of persons of different ages, genders, and/or other characteristics.</p>
<p id="p-0019" num="0017">Circadian rhythms are processes within living organisms that repeat in cycles approximately every 24 hours. For example, human body temperature can vary over the course of each circadian rhythm cycle and can be affected by age, gender, and other characteristics associated with a person. In some cases, the average cosinor amplitude of a person's body temperature can vary as much as 2 degrees C. over the course of each circadian rhythm cycle. Indeed, some individuals may experience even larger variations as high as 3 or 4 degrees C.</p>
<p id="p-0020" num="0018">By classifying persons into groups with shared associated characteristics that affect their circadian rhythms, the body temperature of a person in the group may be compared with temperatures (e.g., moving average temperatures or other measurements) of other persons in the group having the shared associated characteristics (e.g., and consequently the same or similar expected circadian rhythm temperature variations). As a result, elevated body temperature can be detected more accurately over conventional approaches that utilize temperatures (e.g., moving average temperatures or other measurements) associated with random collections of persons with dissimilar characteristics.</p>
<p id="p-0021" num="0019">In some embodiments, an artificial neural network (e.g., a convolution neural network in some cases) may be used to process images of a person captured by a thermal imaging system (e.g., a thermal imaging camera). For example, the neural network may be used to detect the person's face and various characteristics such as age, gender, and/or others. In some embodiments, the neural network may process one or more thermal images captured by the thermal imaging system of persons passing through a scene imaged by the thermal imaging system. In some embodiments, the one or more thermal images may be converted to corresponding visible light representations of the thermal images before being processed by the neural network.</p>
<p id="p-0022" num="0020">As discussed, circadian rhythms can be affected by a person's age, gender, and other characteristics. In this regard, groups of persons having shared characteristics (e.g. having the same gender, an age within a particular range of ages, and/or other shared characteristics) may share similar variations in body temperature over the course of their circadian rhythm cycles. Accordingly, by comparing a person's body temperature with the body temperatures of a group of persons having similar circadian rhythm cycles, and also determining the time (e.g., to determine the expected phase of the circadian rhythm cycle), it can be accurately determined whether the person's body temperature is elevated relative to the group. Such an approach can provide an accurate detection of elevated body temperature that correctly accounts for individual characteristics of the person.</p>
<p id="p-0023" num="0021">In some embodiments, a fever may be detected in a person by using temperature values taken from two or more sites on the person's face, such as one or both bilateral canthi regions and/or an oral region (e.g., mouth). Such an approach can be useful for detecting potential fever in a person, particularly if that person's body temperature falls outside of expected circadian rhythm body temperature variations associated with other persons having the same or similar shared characteristics. In some cases, a fever may be detected with increased probability over conventional approaches if one or more of the following conditions are met: a difference in temperature between the inner canthus regions is lower than a fixed value (e.g., less than 0.2 degrees C.); a difference in temperature between one of the inner canthus regions and the oral region is less than another fixed value (e.g., less than 0.5 degrees C.); and/or an absolute value of the average values of both the inner canthus regions and the oral region is above 37 degrees C.</p>
<p id="p-0024" num="0022">Turning now to the drawings, <figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates a block diagram of an imaging system <b>100</b> in accordance with an embodiment of the disclosure. As shown, imaging system <b>100</b> includes a housing <b>151</b> (e.g., a camera body) having an aperture <b>158</b>, one or more filters <b>160</b>, one or more optical components <b>162</b>, a thermal imager <b>164</b>, an imager interface <b>166</b>, a logic device <b>168</b>, user controls <b>170</b>, a memory <b>172</b>, a communication interface <b>174</b>, a machine readable medium <b>176</b>, a display <b>178</b>, a clock <b>179</b>, other sensors <b>180</b>, and other components <b>182</b>.</p>
<p id="p-0025" num="0023">In various embodiments, imaging system <b>100</b> may be implemented, for example, as a camera system such as a portable (e.g., handheld) thermal camera system, a small form factor camera system implemented as part of another device, a fixed camera system, and/or other appropriate implementations. Imaging system <b>100</b> may be positioned to receive infrared radiation <b>194</b> from a scene <b>190</b> (e.g., a field of view of imaging system <b>100</b>). In various embodiments, scene <b>190</b> may include various features of interest such as one or more persons <b>192</b> (e.g., human beings).</p>
<p id="p-0026" num="0024">Clock <b>179</b> may be implemented as any appropriate type of device used to measure time of day. In some embodiments, such time measurements may be used to determine the current phase of a circadian rhythm associated with person <b>192</b> to detect a possible elevated body temperature.</p>
<p id="p-0027" num="0025">Infrared radiation <b>194</b> is received through aperture <b>158</b> and passes through one or more filters <b>160</b> which may be provided to selectively filter particular thermal wavelengths of interest for images to be captured by thermal imager <b>164</b>. Optical components <b>162</b> (e.g., an optical assembly including one or more lenses, additional filters, transmissive windows, and/or other optical components) pass the filtered infrared radiation <b>194</b> for capture by thermal imager <b>164</b>.</p>
<p id="p-0028" num="0026">Thus, it will be appreciated that filters <b>160</b> and/or optical components <b>162</b> may operate together to selectively filter out portions of infrared radiation <b>194</b> such that only desired wavelengths and/or desired thermal radiation intensities are ultimately received by thermal imager <b>164</b>. In various embodiments, any desired combination of such components may be provided (e.g., various components may be included and/or omitted as appropriate for various implementations).</p>
<p id="p-0029" num="0027">Thermal imager <b>164</b> may capture thermal images of scene <b>190</b> in response to infrared radiation <b>194</b>. Thermal imager <b>164</b> may include an array of sensors for capturing thermal images (e.g., thermal image frames) of scene <b>190</b>. In some embodiments, thermal imager <b>164</b> may also include one or more analog-to-digital converters for converting analog signals captured by the sensors into digital data (e.g., pixel values) to provide the captured images. Imager interface <b>166</b> provides the captured images to logic device <b>168</b> which may be used to process the images, store the original and/or processed images in memory <b>172</b>, and/or retrieve stored images from memory <b>172</b>. Additional implementation details of an embodiment of thermal imager <b>164</b> are discussed herein with regard to <figref idref="DRAWINGS">FIG. <b>2</b></figref>.</p>
<p id="p-0030" num="0028">Logic device <b>168</b> may include, for example, a microprocessor, a single-core processor, a multi-core processor, a microcontroller, a programmable logic device configured to perform processing operations, a digital signal processing (DSP) device, one or more memories for storing executable instructions (e.g., software, firmware, or other instructions), and/or any other appropriate combinations of devices and/or memory to perform any of the various operations described herein. Logic device <b>168</b> is configured to interface and communicate with the various components of imaging system <b>100</b> to perform various method and processing steps described herein. In various embodiments, processing instructions may be integrated in software and/or hardware as part of logic device <b>168</b>, or code (e.g., software and/or configuration data) which may be stored in memory <b>172</b> and/or a machine readable medium <b>176</b>. In various embodiments, the instructions stored in memory <b>172</b> and/or machine readable medium <b>176</b> permit logic device <b>168</b> to perform the various operations discussed herein and/or control various components of system <b>100</b> for such operations.</p>
<p id="p-0031" num="0029">Memory <b>172</b> may include one or more memory devices (e.g., one or more memories) to store data and information. The one or more memory devices may include various types of memory including volatile and non-volatile memory devices, such as RAM (Random Access Memory), ROM (Read-Only Memory), EEPROM (Electrically-Erasable Read-Only Memory), flash memory, fixed memory, removable memory, and/or other types of memory.</p>
<p id="p-0032" num="0030">Machine readable medium <b>176</b> (e.g., a memory, a hard drive, a compact disk, a digital video disk, or a flash memory) may be a non-transitory machine readable medium storing instructions for execution by logic device <b>168</b>. In various embodiments, machine readable medium <b>176</b> may be included as part of imaging system <b>100</b> and/or separate from imaging system <b>100</b>, with stored instructions provided to imaging system <b>100</b> by coupling the machine readable medium <b>176</b> to imaging system <b>100</b> and/or by imaging system <b>100</b> downloading (e.g., via a wired or wireless link) the instructions from the machine readable medium (e.g., containing the non-transitory information).</p>
<p id="p-0033" num="0031">Logic device <b>168</b> may be configured to process captured images and provide them to display <b>178</b> for presentation to and viewing by the user. Display <b>178</b> may include a display device such as a liquid crystal display (LCD), an organic light-emitting diode (OLED) display, and/or other types of displays as appropriate to display images and/or information to the user of system <b>100</b>. Logic device <b>168</b> may be configured to display images and information on display <b>178</b>. For example, logic device <b>168</b> may be configured to retrieve images and information from memory <b>172</b> and provide images and information to display <b>178</b> for presentation to the user of system <b>100</b>. Display <b>178</b> may include display electronics, which may be utilized by logic device <b>168</b> to display such images and information.</p>
<p id="p-0034" num="0032">User controls <b>170</b> may include any desired type of user input and/or interface device having one or more user actuated components, such as one or more buttons, slide bars, knobs, keyboards, joysticks, and/or other types of controls that are configured to generate one or more user actuated input control signals. In some embodiments, user controls <b>170</b> may be integrated with display <b>178</b> as a touchscreen to operate as both user controls <b>170</b> and display <b>178</b>. Logic device <b>168</b> may be configured to sense control input signals from user controls <b>170</b> and respond to sensed control input signals received therefrom. In some embodiments, portions of display <b>178</b> and/or user controls <b>170</b> may be implemented by appropriate portions of a tablet, a laptop computer, a desktop computer, and/or other types of devices.</p>
<p id="p-0035" num="0033">In various embodiments, user controls <b>170</b> may be configured to include one or more other user-activated mechanisms to provide various other control operations of imaging system <b>100</b>, such as auto-focus, menu enable and selection, field of view (FoV), brightness, contrast, gain, offset, spatial, temporal, and/or various other features and/or parameters.</p>
<p id="p-0036" num="0034">Imaging system <b>100</b> may include various types of other sensors <b>180</b> including, for example, microphones, navigation sensors, temperature sensors, and/or other sensors as appropriate.</p>
<p id="p-0037" num="0035">Logic device <b>168</b> may be configured to receive and pass images from imager interface <b>166</b> and signals and data from clock <b>179</b>, sensors <b>180</b>, and/or user controls <b>170</b> to one or more external devices (e.g., remote systems) through communication interface <b>174</b> (e.g., through wired and/or wireless communications). In this regard, communication interface <b>174</b> may be implemented to provide wired communication over a cable and/or wireless communication over an antenna. For example, communication interface <b>174</b> may include one or more wired or wireless communication components, such as an Ethernet connection, a wireless local area network (WLAN) component based on the IEEE 802.11 standards, a wireless broadband component, mobile cellular component, a wireless satellite component, or various other types of wireless communication components including radio frequency (RF), microwave frequency (MWF), and/or infrared frequency (IRF) components configured for communication with a network. As such, communication interface <b>174</b> may include an antenna coupled thereto for wireless communication purposes. In other embodiments, the communication interface <b>174</b> may be configured to interface with a DSL (e.g., Digital Subscriber Line) modem, a PSTN (Public Switched Telephone Network) modem, an Ethernet device, and/or various other types of wired and/or wireless network communication devices configured for communication with a network.</p>
<p id="p-0038" num="0036">In some embodiments, a network may be implemented as a single network or a combination of multiple networks. For example, in various embodiments, the network may include the Internet and/or one or more intranets, landline networks, wireless networks, and/or other appropriate types of communication networks. In another example, the network may include a wireless telecommunications network (e.g., cellular phone network) configured to communicate with other communication networks, such as the Internet. As such, in various embodiments, imaging system <b>100</b> and/or its individual associated components may be associated with a particular network link such as for example a URL (Uniform Resource Locator), an IP (Internet Protocol) address, and/or a mobile phone number.</p>
<p id="p-0039" num="0037">Imaging system <b>100</b> may include various other components <b>182</b> such as speakers, additional displays, visual indicators (e.g., recording indicators), vibration actuators, a battery or other power supply (e.g., rechargeable or otherwise), and/or additional components as appropriate for particular implementations.</p>
<p id="p-0040" num="0038">In some embodiments, imaging system <b>100</b> may include hardware (e.g., implemented in optical components <b>162</b>, imager <b>164</b>, and/or other components <b>192</b>) and/or software (e.g., implemented in logic device <b>168</b> and/or machine readable medium <b>176</b>) to perform image stabilization and/or averaging of spatial and temporal pixel values associated with particular facial features of person <b>192</b>.</p>
<p id="p-0041" num="0039">Although various features of imaging system <b>100</b> are illustrated together in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, any of the various illustrated components and subcomponents may be implemented in a distributed manner and used remotely from each other as appropriate (e.g., through appropriate wired and/or wireless network communication).</p>
<p id="p-0042" num="0040">Although imaging system <b>100</b> has been described in the context of a thermal imaging system, other embodiments are also contemplated. In some embodiments, aperture <b>158</b>, filters <b>160</b>, optical components <b>162</b>, and/or imager <b>164</b> may be implemented to pass and capture other wavelengths such as visible light wavelengths in addition to or instead of thermal wavelengths. For example, imaging system <b>100</b> may be implemented to capture both thermal images and visible light images of scene <b>190</b> for comparison with each other to detect scaling or other phenomena. As another example, different imaging systems <b>100</b> implemented for different wavelengths may be used to capture thermal images and visible light images of scene <b>190</b>.</p>
<p id="p-0043" num="0041"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates a block diagram of thermal imager <b>164</b> in accordance with an embodiment of the disclosure. In this illustrated embodiment, thermal imager <b>164</b> is a focal plane array (FPA) including a sensor array <b>230</b> of infrared sensors <b>232</b> (e.g., implemented as unit cells) and a read out integrated circuit (ROIC) <b>202</b>. Although an 8 by 8 array of infrared sensors <b>232</b> is shown (e.g., corresponding to rows and columns of pixels), this is merely for purposes of example and ease of illustration. Any desired sensor array size may be used as desired.</p>
<p id="p-0044" num="0042">Each infrared sensor <b>232</b> may be implemented, for example, by an infrared detector such as a microbolometer and associated circuitry to provide image data (e.g., a data value associated with a captured voltage) for a pixel of a captured thermal image. In this regard, time-multiplexed electrical signals may be provided by the infrared sensors <b>232</b> to ROIC <b>202</b>.</p>
<p id="p-0045" num="0043">ROIC <b>202</b> includes bias generation and timing control circuitry <b>204</b>, column amplifiers <b>205</b>, a column multiplexer <b>206</b>, a row multiplexer <b>208</b>, and an output amplifier <b>210</b>. Images captured by infrared sensors <b>232</b> may be provided by output amplifier <b>210</b> to logic device <b>168</b> and/or any other appropriate components to perform various processing techniques described herein. Further descriptions of ROICs and infrared sensors (e.g., microbolometer circuits) may be found in U.S. Pat. No. 6,028,309 issued Feb. 22, 2000, which is incorporated herein by reference in its entirety.</p>
<p id="p-0046" num="0044"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates a block diagram of an artificial neural network <b>300</b> in accordance with an embodiment of the disclosure. For example, in some embodiments, neural network <b>300</b> may be implemented by logic device <b>168</b>. As discussed, neural network <b>300</b> (e.g., a convolution neural network in some cases) may be used to process images of person <b>192</b> to detect their face and additional characteristics such as age, gender, and/or other characteristics.</p>
<p id="p-0047" num="0045">As shown, neural network <b>300</b> includes various nodes <b>302</b> (e.g., neurons) arranged in multiple layers including an input layer <b>304</b> receiving one or more inputs <b>310</b>, hidden layers <b>306</b>, and an output layer <b>308</b> providing one or more outputs <b>320</b>. Although particular numbers of nodes <b>302</b> and layers <b>304</b>, <b>306</b>, and <b>308</b> are shown, any desired number of such features may be provided in various embodiments.</p>
<p id="p-0048" num="0046">In some embodiments, neural network <b>300</b> may be used to perform face detection and additional characteristic detection on various thermal images captured by imaging system <b>100</b> and provided to inputs <b>310</b> of neural network <b>300</b>. The results of such detection may be provided by neural network <b>300</b> at outputs <b>320</b>. In some embodiments, neural network <b>300</b> may be trained by providing thermal and/or visible light images of known human faces with known characteristics (e.g., images and related information regarding the characteristics stored in machine readable medium <b>176</b> and/or received through communication interface <b>174</b>) to inputs <b>310</b>.</p>
<p id="p-0049" num="0047">In some embodiments, neural network <b>300</b> operates as a multi-layer classification tree using a set of non-linear transformations between the various layers <b>304</b>, <b>306</b>, and/or <b>308</b> to extract features and information from thermal images captured by imager <b>164</b> (or visible images generated therefrom in some embodiments). For example, neural network <b>300</b> may be trained on large amounts of data (e.g., thermal or visible images of human faces) such that it learns to distinguish human characteristics. This iterative procedure is repeated until neural network <b>300</b> has trained on enough data such that it can perform predictions of its own.</p>
<p id="p-0050" num="0048">In some embodiments, facial recognition may be performed by neural network <b>300</b> detecting facial features such as eye spacing, nose width, eye hole depth, jaw width, and/or other features. In some embodiments, age may be determined by neural network <b>300</b> detecting actual age, appearance age, apparent age, and/or estimated age.</p>
<p id="p-0051" num="0049">As discussed, in some embodiments, neural network <b>300</b> may be implemented as a convolution neural network. For example, in such a convolution neural network, one or more of layers <b>304</b>, <b>306</b>, and/or <b>308</b> may be implemented as convolution layers, pooling layers, and/or fully connected layers. In this regard, a convolution layer provides a representation of various features to be detected by utilizing several convolution kernels where a single node <b>302</b> in a feature map is connected to a set of nodes <b>302</b> in a feature of a previous layer. A pooling layer obtains shift invariance by reducing the resolution of the feature map and is typically implemented between two convolution layers. A fully connected layer uses all the nodes <b>302</b> in a previous layer and connects them to every node <b>302</b> in the fully connected layer.</p>
<p id="p-0052" num="0050"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates a thermal image <b>400</b> undergoing processing in accordance with an embodiment of the disclosure. For example, thermal image <b>400</b> may be an image of person <b>192</b> captured by imager <b>164</b>. In this regard, imager <b>164</b> may be implemented with sufficient resolution to capture individual features (e.g., corresponding to appropriate spot size ratios) on a face <b>420</b> of person <b>192</b>. As shown, face <b>420</b> of person <b>192</b> has been detected (e.g., denoted by a square perimeter superimposed on thermal image <b>400</b>) by neural network <b>300</b> performing appropriate processing. As discussed herein, neural network <b>300</b> may perform additional processing as appropriate to detect the age, gender, and/or other characteristics of person <b>192</b>.</p>
<p id="p-0053" num="0051">As also shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref>, several temperature measurement locations (e.g., sites) <b>430</b>, <b>440</b>, and <b>450</b> are identified. In this regard, locations <b>430</b> and <b>440</b> correspond to the left inner canthus and the right inner canthus, respectively, of person <b>192</b>. Location <b>450</b> corresponds to an oral region (e.g., mouth or throat) of person <b>192</b>. Temperature values may be extracted from one or more of locations <b>430</b>, <b>440</b>, and/or <b>450</b> of thermal image <b>400</b> which correlate to body temperature to determine whether person <b>192</b> exhibits an elevated body temperature and/or a fever.</p>
<p id="p-0054" num="0052">As discussed, imaging system <b>100</b> may include hardware and/or software to perform image stabilization and/or averaging of spatial and temporal pixel values associated with one or more of locations <b>430</b>, <b>440</b>, and/or <b>450</b> to improve the accuracy of temperature values extracted from a plurality of thermal images <b>400</b>. Additional aspects of the processing of thermal image <b>400</b> are discussed with regard to the process of <figref idref="DRAWINGS">FIG. <b>5</b></figref>.</p>
<p id="p-0055" num="0053"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates a process of detecting elevated body temperature using circadian rhythms in accordance with an embodiment of the disclosure. In various embodiments, the actions discussed with regard to <figref idref="DRAWINGS">FIG. <b>5</b></figref> may be performed by appropriate portions of imaging system <b>100</b> and/or other systems in communication therewith.</p>
<p id="p-0056" num="0054">In block <b>500</b>, neural network <b>300</b> (e.g., implemented by logic device <b>168</b>) is trained to detect human faces and characteristics affecting human circadian rhythms (e.g., age, gender, and/or other characteristics). For example, as discussed, this may be performed by providing thermal or visible light images of known human faces with known characteristics to neural network <b>300</b>. Following the training of block <b>500</b>, neural network will be able to detect human faces and the characteristics in newly received images.</p>
<p id="p-0057" num="0055">In block <b>505</b>, logic device <b>168</b> obtains one or more circadian rhythm models corresponding to a moving average or median of expected body temperatures and expected body temperature variations associated with persons with particular characteristics (e.g., the circadian rhythm models may be categorized into various sub-classes associated with particular characteristics). For example, persons having an age in a particular range (e.g., 40 to 49 years old) and gender (e.g., female) may exhibit an expected body temperature and an expected variation in the expected body temperature associated with phases of the daily circadian rhythm cycle, while persons having a different age (e.g., 30 to 39 years old) and gender (e.g., male) may exhibit a different expected body temperature and a different expected variation. As a result, a large number of different circadian rhythm models may be provided, each corresponding to expected body temperatures and expected body temperature variations associated with any desired combination of age, gender, and/or other characteristics.</p>
<p id="p-0058" num="0056">In some embodiments, such circadian rhythm models may be provided to logic device <b>168</b>. In some embodiments, logic device <b>168</b> may adjust, generate, and/or otherwise provide the circadian rhythm models based on processing performed on images. For example, in some embodiments, after a thermal image <b>400</b> is processed to determine characteristics of person <b>192</b> and one or more temperature values are extracted from the thermal image corresponding to a particular time of day (e.g., a phase of the person's <b>192</b> circadian rhythm) in subsequent blocks of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, the association between the person's characteristics and temperature values may be used to update circadian rhythm models corresponding to the person's <b>192</b> combination of characteristics. For example, such information may be used to adjust the expected body temperatures and expected body temperature variations associated with the relevant circadian rhythm models for the person's <b>192</b> combination of characteristics.</p>
<p id="p-0059" num="0057">In block <b>510</b>, imager <b>164</b> begins capturing thermal images <b>400</b> of scene <b>190</b> including person <b>192</b>. For example, thermal image <b>400</b> of <figref idref="DRAWINGS">FIG. <b>4</b></figref> represents a thermal image captured in block <b>510</b>.</p>
<p id="p-0060" num="0058">In block <b>515</b>, neural network <b>300</b> of logic device <b>168</b> processes thermal image <b>400</b> to detect face <b>420</b> of person <b>192</b>. For example, in some embodiments, imager <b>164</b> may be positioned to capture thermal images of persons <b>192</b> passing through scene <b>190</b>. Thus, in some embodiments, imager <b>164</b> may continue to repeatedly capture and process thermal images <b>400</b> in blocks <b>510</b> and <b>515</b> until face <b>420</b> of person is detected. In some embodiments, logic device <b>168</b> may convert thermal image <b>400</b> to a visible light image which is processed to detect face <b>420</b>.</p>
<p id="p-0061" num="0059">In block <b>520</b>, neural network <b>300</b> further processes thermal image <b>400</b> to detect characteristics of person <b>192</b> that may affect their circadian rhythm. As discussed, such characteristics may include age, gender, and/or other characteristics. In some embodiments, logic device <b>168</b> may convert thermal image <b>400</b> to a visible light image which is processed to detect the characteristics.</p>
<p id="p-0062" num="0060">In block <b>525</b>, logic device <b>168</b> selects a circadian rhythm model corresponding to the detected characteristics of person <b>192</b>. In this regard, as discussed in relation to block <b>505</b>, different circadian rhythm models may be available, each being associated with a particular combination of characteristics. Thus, by selecting the corresponding circadian rhythm model for person <b>192</b> in block <b>525</b>, an expected body temperature and expected variation in such body temperature may be determined for person <b>192</b> from the selected circadian rhythm model.</p>
<p id="p-0063" num="0061">In block <b>530</b>, logic device <b>168</b> detects (e.g., measures) a time and any additional environmental conditions that may affect the body temperature of person <b>192</b>. For example, logic device <b>168</b> may receive the time from clock <b>179</b> to identify the phase of the determined circadian rhythm model (e.g., corresponding to the phase within the circadian rhythm model experienced by person <b>192</b> at the time thermal image <b>400</b> was captured). Additional environmental conditions (e.g., ambient temperature, humidity, and/or other data) that may affect body temperature in some cases may also be determined in block <b>530</b>, such as data from other sensors <b>180</b> and/or other components <b>182</b> as appropriate.</p>
<p id="p-0064" num="0062">In block <b>535</b>, logic device <b>168</b> determines an expected body temperature for person <b>192</b> using the selected circadian rhythm model and the time. For example, in some embodiments, the time may be associated with a weight factor applied to an overall expected body temperature provided by the circadian rhythm model that is adjusted by the weight factor to account for phase-based variations to obtain the expected body temperature of person <b>192</b> adjusted for variations. In some embodiments, the circadian rhythm model may include a plurality of different expected body temperatures associated with different phases of the circadian rhythm cycle. In such embodiments, the time may be used to select the phase and thus obtain the expected body temperature of person <b>192</b>.</p>
<p id="p-0065" num="0063">In block <b>540</b>, logic device <b>168</b> further adjusts the expected body temperature of person <b>192</b> to account for the environmental conditions determined in block <b>530</b> as appropriate. For example, if environmental conditions exist that may be expected to affect the body temperature of person <b>192</b>, the expected body temperature may be adjusted accordingly to compensate for the expected effects of such environmental conditions.</p>
<p id="p-0066" num="0064">In block <b>545</b>, logic device <b>168</b> extracts one or more temperature values from thermal image <b>400</b> corresponding to locations on face <b>420</b> of person <b>192</b>. For example, in some embodiments, logic device <b>168</b> may extract temperature values from one or more of locations <b>430</b>, <b>440</b>, <b>450</b>, and/or others which correlate to body temperature.</p>
<p id="p-0067" num="0065">In block <b>550</b>, logic device <b>168</b> compares one or more of the extracted temperature values with the expected body temperature determined in block <b>535</b> and/or <b>540</b> to determine whether the extracted temperature values are elevated in relation to the expected body temperature. In some embodiments, logic device <b>168</b> may compare a single extracted temperature value that correlates to body temperature. In some embodiments, logic device <b>168</b> combine multiple temperature values (e.g., by calculating an average or median) to provide a combined extracted temperature value correlating to body temperature for comparison.</p>
<p id="p-0068" num="0066">In block <b>555</b>, logic device <b>168</b> determines whether the extracted temperature value corresponds to an elevated body temperature value. For example, in some embodiments, logic device <b>168</b> may determine whether the extracted temperature value exceeds the expected body temperature value by a sufficient threshold (e.g., greater than 1 degree C., 2 degrees C., or other threshold). If the threshold is exceeded, then logic device <b>168</b> determines that person <b>192</b> exhibits an elevated body temperature (e.g., person <b>192</b> exhibits an elevated body temperature condition) and the process continues to block <b>560</b>. Otherwise, the process continues to block <b>565</b>.</p>
<p id="p-0069" num="0067">In block <b>560</b>, logic device <b>168</b> generates a notification regarding the detected elevated body temperature. For example, in various embodiments, logic device <b>168</b> may generate a visible and/or audible notification in the form of text, icons, colors, flashing lights, sounds, alarms, and/or other types notifications to be provided using the various components of imaging system <b>100</b> as appropriate.</p>
<p id="p-0070" num="0068">In block <b>565</b>, logic device <b>168</b> performs a fever analysis by processing a plurality of temperature values previously extracted in block <b>545</b>. For example, the fever analysis of block <b>565</b> can provide a further confirmation (e.g., verification) of the existence or non-existence of an elevated body temperature, regardless of whether an elevated body temperature was previously detected in block <b>555</b>. As discussed, such an approach can be particularly useful to detect a fever in cases where a person's <b>192</b> body temperature falls outside of expected circadian rhythm body temperature variations associated with other persons having the same or similar shared characteristics.</p>
<p id="p-0071" num="0069">Accordingly, in block <b>565</b>, logic device <b>168</b> may process the extracted temperature values in one or more ways to detect a fever. In one embodiment, a fever may be detected if temperature values extracted from inner canthus locations <b>430</b> and <b>440</b> exhibit a difference less than a fixed value (e.g., less than 0.2 degrees C.). In another embodiment, a fever may be detected if temperature values extracted from one of inner canthus locations <b>430</b> or <b>440</b> and oral region <b>450</b> exhibit a difference less than another fixed value (e.g., less than 0.5 degrees C.). In another embodiment, a fever may be detected if an absolute value of the average extracted temperature values of both inner canthus regions <b>430</b> and <b>440</b> and oral region <b>450</b> is above a threshold temperature (e.g., 37 degrees C.).</p>
<p id="p-0072" num="0070">In block <b>570</b>, logic device <b>168</b> determines whether a fever has been detected using the conditions set forth in block <b>565</b>. If a fever is detected, then the process continues to block <b>575</b>. Otherwise, the process returns to block <b>505</b>.</p>
<p id="p-0073" num="0071">In block <b>575</b>, logic device <b>168</b> generates a notification regarding the detected fever, for example, in a manner as similarly discussed with regard to block <b>560</b>. Thereafter, the process of <figref idref="DRAWINGS">FIG. <b>5</b></figref> returns to block <b>505</b>.</p>
<p id="p-0074" num="0072">Upon returning to block <b>505</b> (e.g., from either block <b>570</b> or block <b>575</b>), the process of <figref idref="DRAWINGS">FIG. <b>5</b></figref> repeats blocks <b>505</b> to <b>575</b> as appropriate to capture and process additional thermal images to detect elevated body temperature and fevers for additional persons <b>192</b> in scene <b>190</b>. Also, as block <b>505</b> is repeated, logic device <b>168</b> may update one or more of the circadian rhythm models using the detected characteristics, extracted temperatures, elevated body temperature detections, and/or fever detections determined in the previous iteration of any of blocks <b>520</b> to <b>575</b>. For example, appropriate circadian rhythm models may be updated with temperature values extracted from thermal image <b>400</b> to improve the accuracy of expected body temperatures and expected body temperature variations used by the circadian rhythm models to improve their accuracy using real world real time measurements provided by thermal image <b>400</b>.</p>
<p id="p-0075" num="0073">Other embodiments are also contemplated. Although the process of <figref idref="DRAWINGS">FIG. <b>5</b></figref> has been discussed in relation to thermal images, visible light images may be used for certain processing. For example, in some embodiments, the thermal images may be converted to visible light images (e.g., visible light representations of the thermal images) which are processed for purposes of performing face detection (e.g., block <b>515</b>) and/or characteristics detection (e.g., block <b>520</b>). In some embodiments, visible light images concurrently captured with the thermal images (e.g., using an additional visible light imager) may be used for such processing. In yet another embodiment, the features discussed herein may be used to detect the occurrence and stage of a menopause condition that may be present in person <b>192</b>. For example, menopause occurrence and its associated stage may be one or more characteristics determined in block <b>520</b> and associated with one or more sub-classes of circadian rhythm models.</p>
<p id="p-0076" num="0074">Where applicable, various embodiments provided by the present disclosure can be implemented using hardware, software, or combinations of hardware and software. Also where applicable, the various hardware components and/or software components set forth herein can be combined into composite components comprising software, hardware, and/or both without departing from the spirit of the present disclosure. Where applicable, the various hardware components and/or software components set forth herein can be separated into sub-components comprising software, hardware, or both without departing from the spirit of the present disclosure. In addition, where applicable, it is contemplated that software components can be implemented as hardware components, and vice-versa.</p>
<p id="p-0077" num="0075">Software in accordance with the present disclosure, such as program code and/or data, can be stored on one or more computer readable mediums. It is also contemplated that software identified herein can be implemented using one or more general purpose or specific purpose computers and/or computer systems, networked and/or otherwise. Where applicable, the ordering of various steps described herein can be changed, combined into composite steps, and/or separated into sub-steps to provide features described herein.</p>
<p id="p-0078" num="0076">Embodiments described above illustrate but do not limit the invention. It should also be understood that numerous modifications and variations are possible in accordance with the principles of the present invention. Accordingly, the scope of the invention is defined only by the following claims.</p>
<?detailed-description description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text><b>1</b>. A method comprising:
<claim-text>receiving a thermal image;</claim-text>
<claim-text>processing the thermal image to detect a person's face and a characteristic associated with the person;</claim-text>
<claim-text>selecting a circadian rhythm model associated with the detected characteristic;</claim-text>
<claim-text>determining an expected body temperature using the circadian rhythm model;</claim-text>
<claim-text>extracting a temperature associated with the person's face from the thermal image; and</claim-text>
<claim-text>comparing the extracted temperature with the expected body temperature to detect an elevated body temperature condition.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising receiving a time associated with the thermal image, wherein the determining comprises using the time to identify a phase of the circadian rhythm model.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text><b>3</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the determining comprises selecting the expected body temperature corresponding to the phase from a plurality of expected body temperatures corresponding to a plurality of phases of the circadian rhythm model.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text><b>4</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the determining comprises adjusting the expected body temperature in response to the identified phase.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text><b>5</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the circadian rhythm model corresponds to a sub-class associated with the characteristic, the method further comprising updating the circadian rhythm model corresponding to the sub-class using the extracted temperature to improve accuracy of the circadian rhythm model.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text><b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising determining a difference between extracted temperatures from the thermal image to detect a fever condition associated with the person, wherein the extracted temperatures comprise a temperature of a left inner canthus of the person, a temperature of a right inner canthus of the person, and/or a temperature of an oral region of the person.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text><b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising generating a notification of the elevated body temperature condition and/or the fever condition.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text><b>8</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing is performed using the thermal image and a visible light image to detect the characteristic, wherein the characteristic is a first characteristic comprising an age associated with the person, wherein the method further comprises processing the thermal image and the visible light image to detect a second characteristic comprising a gender associated with the person.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text><b>9</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the processing is performed using the thermal image and a visible light image to detect the characteristic, wherein the characteristic is an age and/or a gender of the person.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text><b>10</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<claim-text>the method is performed by a portable thermal camera;</claim-text>
<claim-text>the processing is performed by a neural network using the thermal image and a visible light image; and</claim-text>
<claim-text>the method further comprises:
<claim-text>training the neural network to detect the face and the characteristic,</claim-text>
<claim-text>stabilizing the thermal image, and</claim-text>
<claim-text>averaging spatial and temporal pixel values of a plurality of thermal images to improve accuracy of the extracted temperature, wherein the extracted temperature is associated with an inner canthus of the person's face.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text><b>11</b>. A system comprising:
<claim-text>a thermal imager; and</claim-text>
<claim-text>a logic device configured to:
<claim-text>operate the thermal imager to capture a thermal image,</claim-text>
<claim-text>process the thermal image to detect a person's face and a characteristic associated with the person,</claim-text>
<claim-text>select a circadian rhythm model associated with the detected characteristic,</claim-text>
<claim-text>determine an expected body temperature using the circadian rhythm model,</claim-text>
<claim-text>extract a temperature associated with the person's face from the thermal image, and</claim-text>
<claim-text>compare the extracted temperature with the expected body temperature to detect an elevated body temperature condition.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text><b>12</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the logic device is configured to receive a time associated with the thermal image and use the time to identify a phase of the circadian rhythm model.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text><b>13</b>. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the logic device is configured to select the expected body temperature corresponding to the phase from a plurality of expected body temperatures corresponding to a plurality of phases of the circadian rhythm model.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text><b>14</b>. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the logic device is configured to adjust the expected body temperature in response to the identified phase.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text><b>15</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the circadian rhythm model corresponds to a sub-class associated with the characteristic, wherein the logic device is configured to update the circadian rhythm model corresponding to the sub-class using the extracted temperature to improve accuracy of the circadian rhythm model.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text><b>16</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the logic device is configured to determine a difference between extracted temperatures from the thermal image to detect a fever condition associated with the person, wherein the extracted temperatures comprise a temperature of a left inner canthus of the person, a temperature of a right inner canthus of the person, and/or a temperature of an oral region of the person.</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text><b>17</b>. The system of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the logic device is configured to generate a notification of the elevated body temperature condition and/or the fever condition.</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text><b>18</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the logic device is configured to process the thermal image and a visible light image to detect the characteristic, wherein the characteristic is a first characteristic comprising an age associated with the person, wherein the logic device is configured to process the thermal image and the visible light image to detect a second characteristic comprising a gender associated with the person.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text><b>19</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the logic device is configured to process the thermal image and a visible light image to detect the characteristic, wherein the characteristic is an age and/or a gender of the person.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text><b>20</b>. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein:
<claim-text>the system is a portable thermal camera;</claim-text>
<claim-text>the logic device comprises a neural network configured to process the thermal image and a visible light image to detect the person's face and the characteristic;</claim-text>
<claim-text>the neural network is configured to be trained to detect the face and the characteristic; and</claim-text>
<claim-text>the system is configured to:
<claim-text>stabilize the thermal image, and</claim-text>
<claim-text>average spatial and temporal pixel values of a plurality of thermal images to improve accuracy of the extracted temperature, wherein the extracted temperature is associated with an inner canthus of the person's face.</claim-text>
</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-application>
