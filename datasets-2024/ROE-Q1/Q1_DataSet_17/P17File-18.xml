<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]>
<us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230225599A1-20230720.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20230710" date-publ="20230720">
<us-bibliographic-data-application lang="EN" country="US">
<publication-reference>
<document-id>
<country>US</country>
<doc-number>20230225599</doc-number>
<kind>A1</kind>
<date>20230720</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>17580194</doc-number>
<date>20220120</date>
</document-id>
</application-reference>
<us-application-series-code>17</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>1</main-group>
<subgroup>05</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>02</class>
<subclass>B</subclass>
<main-group>23</main-group>
<subgroup>24</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>J</subclass>
<main-group>3</main-group>
<subgroup>28</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classifications-cpc>
<main-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>1</main-group>
<subgroup>05</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</main-cpc>
<further-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>01</class>
<subclass>J</subclass>
<main-group>3</main-group>
<subgroup>2823</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>02</class>
<subclass>B</subclass>
<main-group>23</main-group>
<subgroup>243</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>01</class>
<subclass>J</subclass>
<main-group>2003</main-group>
<subgroup>2826</subgroup>
<symbol-position>L</symbol-position>
<classification-value>A</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</further-cpc>
</classifications-cpc>
<invention-title id="tqxgw44k2yofe">METHODS AND DEVICES FOR MULTI-SPECTRAL IMAGING</invention-title>
<us-parties>
<us-applicants>
<us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>Cilag GmbH International</orgname>
<address>
<city>Zug</city>
<country>CH</country>
</address>
</addressbook>
<residence>
<country>CH</country>
</residence>
</us-applicant>
<us-applicant sequence="01" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>JENOPTIK Optical Systems GmbH</orgname>
<address>
<city>Jena</city>
<country>DE</country>
</address>
</addressbook>
<residence>
<country>DE</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="00" designation="us-only">
<addressbook>
<last-name>Trusty</last-name>
<first-name>Robert</first-name>
<address>
<city>Cincinnati</city>
<state>OH</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="01" designation="us-only">
<addressbook>
<last-name>Henley</last-name>
<first-name>Jeremiah</first-name>
<address>
<city>Fair Oaks</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="02" designation="us-only">
<addressbook>
<last-name>Weise</last-name>
<first-name>Hannes</first-name>
<address>
<city>Jena</city>
<country>DE</country>
</address>
</addressbook>
</inventor>
<inventor sequence="03" designation="us-only">
<addressbook>
<last-name>Hambach</last-name>
<first-name>Ralf</first-name>
<address>
<city>Jena</city>
<country>DE</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
</us-bibliographic-data-application>
<abstract id="abstract">
<p id="p-0001" num="0000">An imaging system includes a first optical system configured to receive an imaging beam from a surgical region. The imaging beam including a first wavelength band and a second wavelength band. The imaging beam is directed along a first optical axis. The first optical system includes a dichroic beam splitter, and the first optical system is configured to direct a first optical beam associated with the first wavelength band along a first direction and direct a second optical beam associated with the second wavelength band along a second direction. The imaging system also includes a first sensor located along the first direction and configured to capture a first image associated with the first optical beam. The image system further includes a first relay lens system located along the second direction downstream from the first optical system and configured to receive the second optical beam.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="139.78mm" wi="202.95mm" file="US20230225599A1-20230720-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="192.36mm" wi="147.66mm" file="US20230225599A1-20230720-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="203.71mm" wi="124.21mm" file="US20230225599A1-20230720-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="197.53mm" wi="129.46mm" file="US20230225599A1-20230720-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="241.81mm" wi="122.51mm" file="US20230225599A1-20230720-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="154.43mm" wi="129.12mm" file="US20230225599A1-20230720-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="161.80mm" wi="135.97mm" file="US20230225599A1-20230720-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="227.08mm" wi="137.58mm" file="US20230225599A1-20230720-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="205.66mm" wi="139.45mm" file="US20230225599A1-20230720-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="184.66mm" wi="165.78mm" file="US20230225599A1-20230720-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
</drawings>
<description id="description">
<?summary-of-invention description="Summary of Invention" end="lead"?>
<heading level="1" id="h-0001">FIELD</heading>
<p id="p-0002" num="0001">The present disclosure relates generally to multi-spectral imaging for tissue visualization during surgery.</p>
<heading level="1" id="h-0002">BACKGROUND</heading>
<p id="p-0003" num="0002">Surgical systems often incorporate an imaging system, which can allow the clinician(s) to view the surgical site and/or one or more portions thereof on one or more displays such as a monitor. The display(s) can be local and/or remote to a surgical theater. An imaging system can include a scope with a camera or sensor that views the surgical site and transmits the view to a display that is viewable by a clinician. Scopes include, but are not limited to, laparoscopes, arthroscopes, angioscopes, bronchoscopes, choledochoscopes, colonoscopes, cytoscopes, duodenoscopes, enteroscopes, esophagogastro-duodenoscopes (gastroscopes), endoscopes, laryngoscopes, nasopharyngo-neproscopes, sigmoidoscopes, thoracoscopes, ureteroscopes, and exoscopes.</p>
<p id="p-0004" num="0003">By way of example, certain concealed structures, physical contours, and/or dimensions of structures within a surgical field may be unrecognizable intraoperatively by certain imaging systems. Additionally, certain imaging systems may be incapable of communicating and/or conveying certain information regarding the concealed structures to clinician(s) intraoperatively.</p>
<p id="p-0005" num="0004">Accordingly, there remains a need for improved imaging techniques for tissue visualization during surgery.</p>
<heading level="1" id="h-0003">SUMMARY</heading>
<p id="p-0006" num="0005">Various aspects of the disclosed subject matter may provide one or more of the following capabilities.</p>
<p id="p-0007" num="0006">In an aspect, an imaging system includes a first optical system configured to receive an imaging beam from a surgical region. The imaging beam including a first wavelength band and a second wavelength band. The imaging beam is directed along a first optical axis. The first optical system includes a dichroic beam splitter, and the first optical system is configured to direct a first optical beam associated with the first wavelength band along a first direction and direct a second optical beam associated with the second wavelength band along a second direction. The imaging system also includes a first sensor located along the first direction and configured to capture a first image associated with the first optical beam. The image system further includes a first relay lens system located along the second direction downstream from the first optical system and configured to receive the second optical beam at a first end of the first relay lens system and transmit at least a portion of the second optical beam via a second end of the first relay lens system. The imaging system also includes a second sensor located downstream from the first relay lens system and adjacent to the second end of the first relay lens system. The second sensor is configured to capture a second image associated with the second optical beam.</p>
<p id="p-0008" num="0007">One or more of the following features can be included in any feasible combination.</p>
<p id="p-0009" num="0008">In some implementations, the first optical system, the first sensor, the first relay lens system and the second sensor are located at a distal end of a surgical scope device. In some implementations, the surgical scope device is configured to receive the imaging beam in the surgical region and guide the imaging beam to the first optical system. In some implementations, the surgical scope device is a stereo scope. In some implementations, the surgical scope device is one of an endoscope and a laparoscope. In some implementations, at least one optical element in the first optical system is a 45 degree prism. The pentaprism includes the dichroic beam splitter.</p>
<p id="p-0010" num="0009">In some implementations, at least one optical element in the first optical system is a pentaprism, The pentaprism includes the dichroic beam splitter. In some implementations, the dichroic beam splitter is located at a proximal surface of the pentaprism. In some implementations, the first sensor is located at a first image plane and the second sensor is located at a second image plane. A first distance of the first sensor relative to the first optical system is less than a second distance of the second sensor relative to the first optical system. In some implementations, a first size of the first image detected by the first sensor is different from a second size of a second image detected by the second sensor.</p>
<p id="p-0011" num="0010">In some implementations, an active optical area of the first sensor and an active area of the second sensor are of different sizes. In some implementations, the first direction is perpendicular to the second direction. In some implementations, a light source is used to illuminate the object to be imaged. In some implementations, the light source includes a plurality of individually selectable narrow or wide wavelength bands. In some implementations, the light source includes one or more of lasers, light emitting diodes and incandescent sources configured to generate the narrow or wide wavelength bands.</p>
<p id="p-0012" num="0011">In some implementations, the imaging system further includes a second optical system configured to receive the imaging beam from the surgical region. The second optical system is configured to direct a third optical beam associated with the first wavelength band along a third direction and direct a fourth optical beam associated with the second wavelength band along a fourth direction. The imaging system further includes a third sensor located along the third direction and configured to capture a third image associated with the third optical beam. The imaging system further incudes a second relay lens system located along the fourth direction downstream from the second optical system and configured to receive the fourth optical beam at a first end of the second relay lens system and transmit at least a portion of the fourth optical beam via a second end of the second relay lens system. The imaging system also includes a fourth sensor located downstream from the second relay lens system and adjacent to the second end of the second relay lens system. The fourth sensor is configured to capture a second image associated with the second optical beam.</p>
<p id="p-0013" num="0012">In an aspect, an imaging system includes a first optical system configured to receive an imaging beam from a surgical region, the imaging beam including a first wavelength band and a second wavelength band, wherein the imaging beam is directed along a first optical axis. The first optical system includes a dichroic beam splitter. The first optical system is configured to direct a first optical beam associated with the first wavelength band along a first direction and direct a second optical beam associated with the second wavelength band along a second direction. The imaging system further includes a first sensor located along the first direction and configured to capture a first image associated with the first optical beam. The imaging system further includes a second sensor located along the second direction downstream from the first optical module and configured to receive the second optical beam. The second sensor is configured to capture a second image associated with the second optical beam.</p>
<p id="p-0014" num="0013">In an aspect, a surgical instrument includes a surgical scope device including a distal end and a proximal end. The distal end of the surgical scope device is configured to be placed in a surgical region. The surgical instrument further includes an imaging system located in the distal end of the surgical scope device. The imaging system includes a first optical system configured to receive an imaging beam from a surgical region. The imaging beam including a first wavelength band and a second wavelength band. The imaging beam is directed along a first optical axis. The first optical system includes a dichroic beam splitter, and the first optical system is configured to direct a first optical beam associated with the first wavelength band along a first direction and direct a second optical beam associated with the second wavelength band along a second direction. The imaging system also includes a first sensor located along the first direction and configured to capture a first image associated with the first optical beam. The image system further includes a first relay lens system located along the second direction downstream from the first optical system and configured to receive the second optical beam at a first end of the first relay lens system and transmit at least a portion of the second optical beam via a second end of the first relay lens system. The imaging system also includes a second sensor located downstream from the first relay lens system and adjacent to the second end of the first relay lens system. The second sensor is configured to capture a second image associated with the second optical beam.</p>
<p id="p-0015" num="0014">In some implementations, the proximal end of the surgical scope includes a processor configured to receive a first signal representative of the first image detected by the first sensor and receive a second signal representative of the second image detected by the second sensor. In some implementations, the processor is configured to generate a modified image that includes a superposition of at least a portion of the first image and at least a portion of the second image.</p>
<p id="p-0016" num="0015">In an aspect, a method includes receiving, via a first optical system, an imaging beam from a surgical region, wherein the imaging beam includes a first wavelength band and a second wavelength band, and is directed along a first optical axis. The method also includes directing, by a dichroic beam splitter, a first optical beam associated with the first wavelength band along a first direction and directing a second optical beam associated with the second wavelength band along a second direction. The method further includes capturing a first image associated with the first optical beam. The first image is captured by a first sensor located along the first direction. The method further includes receiving the second optical beam by a first relay system located along the second direction downstream from the first optical system. The second optical beam is received at a first end of the first relay lens system, and transmitting at least a portion of the second optical beam via a second end of the first relay lens system. The method further includes capturing a second image associated with the second optical beam. The second image is captured by a second sensor located along the second direction downstream from the first relay lens system and adjacent to the second end of the first relay lens system. In some implementations, the method further includes generating a modified image by at least superposing at least a portion of the first image and at least a portion of the second image.</p>
<p id="p-0017" num="0016">Non-transitory computer program products (i.e., physically embodied computer program products) are also described that store instructions, which when executed by one or more data processors of one or more computing systems, causes at least one data processor to perform operations herein. Similarly, computer systems are also described that may include one or more data processors and memory coupled to the one or more data processors. The memory may temporarily or permanently store instructions that cause at least one processor to perform one or more of the operations described herein. In addition, methods can be implemented by one or more data processors either within a single computing system or distributed among two or more computing systems. Such computing systems can be connected and can exchange data and/or commands or other instructions or the like via one or more connections, including a connection over a network (e.g. the Internet, a wireless wide area network, a local area network, a wide area network, a wired network, or the like), via a direct connection between one or more of the multiple computing systems, etc.</p>
<?summary-of-invention description="Summary of Invention" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading level="1" id="h-0004">BRIEF DESCRIPTION OF DRAWINGS</heading>
<p id="p-0018" num="0017">This invention will be more fully understood from the following detailed description taken in conjunction with the accompanying drawings, in which:</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an exemplary multi-spectral surgical imaging system;</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an exemplary embodiment of a surgical instrument and a two-channel imaging system in the multi-spectral surgical imaging system of <figref idref="DRAWINGS">FIG. <b>1</b></figref>;</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an exemplary channel of the imaging system in <figref idref="DRAWINGS">FIG. <b>2</b></figref>;</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates another exemplary channel of the imaging system in <figref idref="DRAWINGS">FIG. <b>2</b></figref>;</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an exemplary optical system of the imaging system in <figref idref="DRAWINGS">FIG. <b>2</b></figref>;</p>
<p id="p-0024" num="0023"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates another exemplary optical system of the imaging system in <figref idref="DRAWINGS">FIG. <b>2</b></figref>;</p>
<p id="p-0025" num="0024"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an exemplary two-channel imaging system;</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic illustration of an exemplary control system of the multi-spectral surgical imaging system in <figref idref="DRAWINGS">FIG. <b>1</b></figref>; and</p>
<p id="p-0027" num="0026"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a flowchart of an exemplary multi-spectral surgical imaging method.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?detailed-description description="Detailed Description" end="lead"?>
<heading level="1" id="h-0005">DETAILED DESCRIPTION</heading>
<p id="p-0028" num="0027">Certain exemplary embodiments will now be described to provide an overall understanding of the principles of the structure, function, manufacture, and use of the devices and methods disclosed herein. One or more examples of these embodiments are illustrated in the accompanying drawings. Those skilled in the art will understand that the devices and methods specifically described herein and illustrated in the accompanying drawings are non-limiting exemplary embodiments and that the scope of the present invention is defined solely by the claims. The features illustrated or described in connection with one exemplary embodiment may be combined with the features of other embodiments. Such modifications and variations are intended to be included within the scope of the present invention.</p>
<p id="p-0029" num="0028">Further, in the present disclosure, like-named components of the embodiments generally have similar features, and thus within a particular embodiment each feature of each like-named component is not necessarily fully elaborated upon. Additionally, to the extent that linear or circular dimensions are used in the description of the disclosed systems, devices, and methods, such dimensions are not intended to limit the types of shapes that can be used in conjunction with such systems, devices, and methods. A person skilled in the art will recognize that an equivalent to such linear and circular dimensions can easily be determined for any geometric shape. Sizes and shapes of the systems and devices, and the components thereof, can depend at least on the anatomy of the subject in which the systems and devices will be used, the size and shape of components with which the systems and devices will be used, and the methods and procedures in which the systems and devices will be used.</p>
<p id="p-0030" num="0029">The figures provided herein are not necessarily to scale. Further, to the extent arrows are used to describe a direction a component can be tensioned or pulled, these arrows are illustrative and in no way limit the direction the respective component can be tensioned or pulled. A person skilled in the art will recognize other ways and directions for creating the desired tension or movement. Likewise, while in some embodiments movement of one component is described with respect to another, a person skilled in the art will recognize that other movements are possible. Additionally, although terms such as &#x201c;first&#x201d; and &#x201c;second&#x201d; are used to describe various aspects of a component, e.g., a first end and a second end, such use is not indicative that one component comes before the other. Use of terms of this nature may be used to distinguish two similar components or features, and often such first and second components can be used interchangeably. Still further, a number of terms may be used throughout the disclosure interchangeably but will be understood by a person skilled in the art.</p>
<p id="p-0031" num="0030">Multi-spectral imaging systems can be used in surgical procedures to acquire images or videos of a surgical region. For example, visible light can be used to image the surgical region, and radiations outside the visible light spectrum (e.g., infrared light) can be used to image portions of the surgical region that cannot be identified by visible light alone. The images associated with different wavelengths can be combined to generate a modified image of the surgical region that can be presented to a user (e.g., a surgeon) during surgery. In some implementations, surgical instruments (e.g., laparoscopes) can include a multi-spectral imaging system that can allow a surgeon to view the surgical region (e.g., multiple tissues in the surgical region) while performing the surgical procedure. For example, the multi-spectral imaging system can include imaging optics that can guide electromagnetic radiation in two or more wavelength bands from the surgical region (e.g., reflected by the surgical region) and an image sensor that can capture images associated with the electromagnetic radiation.</p>
<p id="p-0032" num="0031">A single sensor may not be suitable for multi-spectral imaging due to the limited number of images that it can acquire in a given period of time (also referred to as framerate). Using multiple wavelength bands for imaging can reduce the number of frames of visible light images that can be captured in a given period. This can adversely affect the quality of the modified image displayed to the user. Therefore, it can be desirable to use multiple sensors to acquire images associated with the different wavelength bands. For example, visible light images can be captured by a first sensor and infrared images can be captured by a second sensor. Usage of multiple sensors can be achieved by using an optical system (e.g., one that includes one or more of dichroic beam splitters, prisms, pentaprism, and lenses) that can separate a first wavelength band (which can be directed to the first sensor) from a second wavelength band (which can be directed to the second sensor).</p>
<p id="p-0033" num="0032">Typically, the first sensor and the second sensor are placed in a first image plane and a second image plane, respectively, of the optical system. The first and the second image planes can be located at similar distances from the optical system (e.g., adjacent to the optical system). As a result, in many known systems the first and the second sensors must have similar properties (e.g., generate images of similar sizes, resolution, framerates, etc.) to allow for synthesis of their respective images to generate the modified image. This is not desirable, as it can be challenging to find similar sensors that can also be placed in the image planes of the optical system. For example, if the optical element is located at the distal end of the surgical instrument, there may not be sufficient available space to fit two sensors in the image planes. In other known systems cameras that can capture images to be synthesized to generate a modified image can be customized to fit within the distal end of the surgical instrument. However, customized cameras can be unduly expensive and not easily available due to long lead times needed for manufacturing).</p>
<p id="p-0034" num="0033">In some implementations of the system disclosed herein there is described a multi-spectral imaging system that can be configured to independently capture the images associated with the first wavelength band (e.g., visible light having wavelengths ranging from about 400 nanometers to about 800 nanometers) and the second wavelength band (e.g., infrared radiation having wavelengths ranging from about 800 nanometers to about 1000 nanometers). In some implementations, a relay lens system can be introduced in the optical path of the second wavelength band prior to imaging by the second sensor. As a result, the locations of the first image plane (where the first sensor is placed to capture the image associated with the first wavelength band) and the conjugate image plane (where the second sensor is placed to capture the image associated with the second wavelength band) can be independently adjusted. This allows for the design of a multi-spectral imaging system that can be efficiently placed in the distal end of a surgical instrument that may have limited space (e.g., placed within a region of small diameter at the distal end of the surgical instrument). Moreover, the independent determination of image planes allows for the usage of off-the-shelf sensors that can reduce the cost, complexity, and manufacturing time of the multi-spectral imaging system.</p>
<p id="p-0035" num="0034"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates an exemplary multi-spectral surgical imaging system <b>100</b> that includes a surgical instrument <b>102</b> capable of performing multi-spectral imaging. The surgical instrument <b>102</b> has a distal end <b>110</b> and a proximal end <b>112</b>. The surgical instrument <b>102</b> can perform multi-spectral imaging of a portion <b>122</b> of a target tissue <b>120</b>. In some implementations, the imaging system <b>100</b> can include a light source <b>104</b> that can illuminate the target tissue <b>120</b> with a beam <b>106</b>, such as a multi-spectral beam. For example, the beam <b>106</b> can include radiation in multiple wavelength bands (e.g., visible light band, infrared band, etc.). In some implementations, the light source <b>104</b> can include one or more of sources of radiation (e.g., lasers, light emitting diodes, incandescent sources, etc.). For example, the light source <b>106</b> can include one or more of a first source that generates a first narrow wavelength band, a second source that generates a second narrow wavelength band, a third source that generates a first wide wavelength bands, a fourth source that generates a second wide wavelength band, etc.</p>
<p id="p-0036" num="0035">The target tissue <b>120</b> (e.g., portion <b>122</b> of the target tissue <b>120</b>) can interact with the beam <b>106</b> and generate an imaging beam <b>108</b>, e.g., by reflecting a portion of the beam <b>106</b>, generating new radiation based on interaction with the beam <b>106</b>, etc. The imaging beam <b>108</b> can be captured by an imaging system <b>130</b> located at the distal end <b>110</b> of the surgical instrument <b>102</b>. The multi-spectral surgical imaging system <b>100</b> can further include a control system <b>150</b> that can be operatively coupled to the surgical instrument <b>102</b> and the light source <b>104</b>. The control system <b>150</b> can control aspects of the operation of the surgical instrument <b>102</b>, by triggering image sensors in the surgical instrument <b>102</b> to capture images, process images captured by the image sensors, etc. The control system <b>150</b> can also control aspects of the light source <b>104</b>, such as by triggering the visible light source and/or the infrared source in the light source <b>104</b> to generate the beam <b>106</b>.</p>
<p id="p-0037" num="0036"><figref idref="DRAWINGS">FIG. <b>2</b></figref> illustrates an exemplary embodiment of the surgical instrument <b>102</b> that extends from the distal end <b>110</b> to the proximal end <b>112</b>. The distal end <b>110</b> of the surgical instrument <b>102</b> can be introduced into a surgical environment that includes the target tissue <b>120</b> (not shown in <figref idref="DRAWINGS">FIG. <b>2</b></figref>). The surgical instrument <b>102</b> includes the imaging system <b>130</b> located at the distal end <b>110</b>. The imaging system <b>130</b> can be configured to receive the imaging beam <b>108</b> from the target tissue <b>120</b> and capture images associated with the various wavelength bands included in the imaging beam <b>108</b> (e.g., which can correspond to the wavelength bands in the band <b>106</b> illuminated on the target tissue <b>120</b> by light source <b>104</b>). The imaging system <b>130</b> can include multiple channels that can independently receive the imaging beam <b>108</b> and capture images associated with the various wavelength bands. For example, the imaging system <b>130</b> can include a first channel <b>132</b> and a second channel <b>134</b>. A signal including data characterizing the captured images can be transmitted by each channel in the imaging system <b>130</b>.</p>
<p id="p-0038" num="0037">In some implementations, the signal(s) can be received and processed by processors <b>202</b> located at the proximal end of the surgical instrument <b>102</b>. In some implementations, the signal(s) can be received and processed by the control system <b>150</b>. It is desirable to capture the images at the distal end <b>110</b> and transmit a signal associated with the captured images to the proximal end instead of guiding the imaging beam <b>108</b> (or a portion thereof) through the surgical instrument <b>102</b> to the proximal end <b>112</b> and capturing the images at the proximal end. Capturing the images at the proximal end <b>112</b> guiding the imaging beam <b>108</b> through the surgical instrument <b>102</b> can be disadvantageous as it may require multiple optical elements (e.g., lenses, waveguides, etc.) that can lead to an increase in the cost and weight of the surgical instrument <b>102</b>.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>3</b></figref> illustrates an exemplary channel of an imaging system (e.g., imaging system <b>130</b>) that can receive a multi-spectral imaging beam (e.g., imaging beam <b>108</b>) from the surgical region and capture multiple images based on the wavelength band in the imaging beam. The imaging beam can be directed along an optical axis <b>302</b>. In some implementations, the multi-spectral imaging beam can include a first wavelength band (e.g., including electromagnetic radiations in the visible light wavelength range) and a second wavelength band (e.g., including electromagnetic radiations in the infrared wavelength range).</p>
<p id="p-0040" num="0039">The channel <b>300</b> can receive the imaging beam via an aperture <b>304</b>, and a guiding optical system <b>306</b> can guide the imaging beam to an optical system <b>308</b> configured to separate different wavelength bands in the imaging beam. For example, the optical system <b>308</b> can guide a first optical beam <b>312</b> associated with the first wavelength band along a first direction <b>314</b>, and guide a second optical beam <b>316</b> associated with the second wavelength band along the second direction <b>318</b>. The optical system <b>308</b> can include a dichroic beam splitter (not shown) that can separate the first wavelength band from the second wavelength band. The guiding optical system <b>306</b> can include a telecentric objective that can provide constant magnification regardless of the distance of the target tissue from the surgical instrument <b>102</b>.</p>
<p id="p-0041" num="0040">In some implementations, the dichroic beam splitter (or dichroic filter) can separate shorter wavelengths from longer wavelengths relative to a predetermined wavelength (e.g., 650 nanometers). In some implementations, the dichroic filter can be designed as a shortpass filter where wavelengths longer than 650 nanometers are reflected and guided along the first direction <b>314</b>, and wavelengths shorter than 650 nanometers are transmitted through and guided along the second direction <b>318</b>. In some implementations, the dichroic filter can be designed as a longpass filter where wavelengths shorter than 650 nanometers are reflected and guided along a first direction <b>314</b>, and wavelengths longer than 650 nanometers are transmitted and guided along the second direction <b>318</b>. The dichroic filter can be designed to separate only a narrow band centered at a desired wavelength. The width of the separated band can be designed to accommodate tolerances and/or multiple desired wavelengths. The separated narrow band can be reflected or transmitted. The dichroic filter can include multiple separated narrow bands. The filter can include a combination of narrow bands and wide bands.</p>
<p id="p-0042" num="0041">The channel <b>300</b> can include a first sensor <b>320</b> configured to capture an image of the surgical region associated with the first wavelength band, and a second sensor <b>322</b> configured to capture the image of the surgical region associated with the second wavelength band. The first sensor <b>320</b> is located at a first image plane <b>330</b> of the optical system <b>308</b>, and the second sensor <b>322</b> is located at the second image plane <b>330</b> of the optical system <b>308</b>. It can be desirable to place the sensors at their respective imaging planes in order to obtain sharp images of the surgical region. In some implementations, the first direction <b>314</b> and the second direction <b>318</b> can be perpendicular to each other (e.g., when the optical system <b>308</b> includes a 45 degrees prism). In other words, the first image plane <b>330</b> and the second image plane <b>332</b> can be perpendicular to each other. In some implementations, the first direction <b>314</b> and the second direction <b>318</b> can be at a non-perpendicular angle relative to each other. In other words, the first image plane <b>330</b> and the second image plane <b>332</b> can be oriented with respect to each other at a non-perpendicular angle. The image sensors <b>320</b> and <b>322</b> can have the same properties or different properties. In some implementations, the performance of an imaging system (e.g., imaging system <b>130</b>) can be improved (e.g., optimized) by using sensors with different properties. For example, a first sensor can include a color filter array that can generate a color image from broadband white light; and a second sensor can be monochrome filter (e.g., includes no color filter array) to collect wavelengths of light outside the visible spectrum and/or wavelengths of interest for the multi-spectrum imaging system. In some implementations, the sensor collecting near-infrared light can have additional sensitivity to near-infrared light.</p>
<p id="p-0043" num="0042">In some implementations, the location of the first image plane <b>330</b> and second image plane <b>332</b> relative to the optical system <b>308</b> is fixed based on the design of the optical system <b>308</b>. For example, the first and the second image planes can be located close to the optical system <b>308</b> (e.g., at similar distances from the optical system <b>308</b>) and the images formed at these planes can have similar properties (e.g., similar size, similar resolution, etc.). In such an implementation, it may be desirable that the first sensor <b>320</b> and the second sensor <b>322</b> have similar properties (e.g., generate images of similar sizes, resolution, etc.) to allow for synthesis of their respective images to generate the modified image.</p>
<p id="p-0044" num="0043"><figref idref="DRAWINGS">FIG. <b>4</b></figref> illustrates an exemplary channel <b>400</b> of an imaging system (e.g., imaging system <b>130</b>) that can perform multi-spectral imaging (e.g., of the imaging beam <b>108</b>). As described below, the channel <b>400</b> includes a relay lens system that generate a conjugate image plane of an image plane in the channel <b>400</b>. The imaging beam can be directed along an optical axis <b>402</b>, and can be received by the channel <b>400</b> via the aperture <b>404</b>. The guiding optical system <b>306</b> can guide the imaging beam to the optical system <b>308</b> that can guide a first optical beam <b>412</b> associated with the first wavelength band along a first direction <b>414</b>, and guide a second optical beam <b>416</b> associated with the second wavelength band along the second direction <b>418</b>.</p>
<p id="p-0045" num="0044">The channel <b>400</b> can include a first sensor <b>420</b> configured to capture an image of the surgical region associated with the first wavelength band, and a second sensor <b>422</b> configured to capture the image of the surgical region associated with the second wavelength band. The first sensor <b>420</b> is located at the first image plane <b>330</b> of the optical system <b>308</b>. The channel <b>400</b> includes a relay lens system <b>440</b> located along the second direction <b>418</b> downstream from the optical system <b>308</b>. The relay lens system <b>440</b> can include a first end (located proximal to the second image plane <b>332</b>) that can receive the second optical beam <b>416</b>. The relay lens system <b>440</b> can include a second end via which the second beam <b>416</b> (or a portion thereof) can be transmitted.</p>
<p id="p-0046" num="0045">One skilled in the art will understand that a relay lens system can include one or more lenses that can receive an image at one image plane and relay the image to another image plane. Relay lens systems can change the properties of the image from one image plane to another (e.g., vary the size / orientation of the image). The relay lens system <b>440</b> can generate a conjugate image plane <b>434</b> of the second image plane <b>332</b> of the optical system <b>308</b>. In some implementations, the relay lens system <b>440</b> can generate a conjugate image at the conjugate image plane <b>434</b> that can have different properties from the image generated at the second image plane <b>332</b>. For example, the relay lens system <b>440</b> can magnify the image at the second image plane <b>332</b> (e.g., the conjugate image can be larger than the image at the second image plane <b>332</b>). Alternately, the relay lens system <b>440</b> can de-magnify the image at the second image plane <b>332</b> (e.g., the conjugate image can be smaller than the image at the second image plane <b>332</b>).</p>
<p id="p-0047" num="0046">In some implementations, the images formed at the first image plane <b>330</b> and the second image plane <b>332</b> can have similar properties (e.g., similar size, similar resolution, etc.). As described above, the conjugate image and the image formed at the second image plane <b>332</b> (and the image formed at the first image plane <b>330</b>) can have different properties. This can allow the use of different sensors to capture the image at the first image plane <b>330</b> and the conjugate image at the conjugate image plane <b>434</b>. In other words, the first sensor <b>420</b> and the second sensor <b>422</b> can have different properties. By way of example, the ability to use sensors with different properties can obviate the requirement of previously known systems to have two sensors that generate images of similar sizes and/or resolution, etc.</p>
<p id="p-0048" num="0047"><figref idref="DRAWINGS">FIG. <b>5</b></figref> illustrates an exemplary optical system <b>500</b> (e.g., optical system <b>308</b>) configured to separate different wavelength bands in the imaging beam (e.g., imaging beam <b>108</b>). The optical system <b>500</b> includes a lens <b>502</b>, a notch filter <b>504</b> and a prism <b>506</b>. The optical system <b>500</b> can receive the multi-spectral imaging beam <b>510</b> (e.g., from the surgical region via the guiding optical system <b>306</b>), and separate the imaging beam <b>510</b> into a first optical beam <b>512</b> associated with the first wavelength band (e.g., including electromagnetic radiations in the visible light wavelength range) and a second optical beam <b>514</b> associated with the second wavelength band (e.g., including electromagnetic radiations in the infrared wavelength range).</p>
<p id="p-0049" num="0048">In a typical arrangement the lens <b>502</b> can focus the imaging beam <b>510</b> while the notch filter <b>504</b> can block (or attenuate) a predetermined wavelength band while allowing other wavelength bands (e.g., visible light wavelength range, infrared wavelength range) that lie outside the predetermined wavelength band to pass through. The prism <b>506</b> can include a dichroic beam splitter <b>508</b> that can separate the first wavelength band from the second wavelength band in the multi-spectral imaging beam <b>510</b> (e.g., reflect the first optical beam <b>512</b> and transmit the second optical beam <b>514</b>). In some implementations, the prism <b>506</b> can be about 45&#xb0; prism, and the imaging beam <b>510</b> can be incident on the dichroic beam splitter <b>508</b> at a 45 degrees angle (e.g., angle between the imaging beam <b>510</b> and the normal <b>520</b> of the dichroic beam splitter <b>508</b> can be 45 degrees).</p>
<p id="p-0050" num="0049"><figref idref="DRAWINGS">FIG. <b>6</b></figref> illustrates another exemplary optical system <b>600</b> (e.g., optical system <b>308</b>) configured to separate different wavelength bands in the imaging beam (e.g., imaging beam <b>108</b>). The optical system <b>600</b> includes a lens <b>602</b>, a notch filter <b>604</b> and a pentaprism <b>606</b>. The optical system <b>600</b> can receive the multi-spectral imaging beam <b>610</b> (e.g., from the surgical region via the guiding optical system <b>306</b>), and separate the imaging beam <b>610</b> into a first optical beam <b>612</b> associated with the first wavelength band (e.g., including electromagnetic radiations in the visible light wavelength range) and a second optical beam <b>614</b> associated with the second wavelength band (e.g., including electromagnetic radiations in the infrared wavelength range).</p>
<p id="p-0051" num="0050">In a typical arrangement the lens <b>602</b> can focus the imaging beam <b>610</b> while the notch filter <b>604</b> can block (or attenuate) a predetermined wavelength band while allowing other wavelength bands (e.g., visible light wavelength range, infrared wavelength range) that lie outside the predetermined wavelength band to pass through. The pentaprism <b>606</b> can include a dichroic beam splitter <b>608</b> that can separate the first wavelength band from the second wavelength band in the multi-spectral imaging beam <b>610</b> (e.g., reflect the first optical beam <b>612</b> and transmit the second optical beam <b>614</b>).</p>
<p id="p-0052" num="0051">The imaging beam <b>610</b> can enter the pentaprism <b>606</b> through a first surface <b>622</b> (a distal surface) of the pentaprism <b>606</b>. The dichroic beam splitter <b>608</b> located at a second surface <b>624</b> (a proximal surface) of the pentaprism <b>606</b> can transmit the second optical beam <b>614</b> and reflect the first optical beam <b>612</b>. The first optical beam <b>612</b> is further reflected by the third surface <b>626</b> and emitted via the fourth surface <b>628</b> of the pentaprism <b>606</b>. In some implementations, the imaging beam <b>610</b> can be incident on the dichroic beam splitter <b>608</b> at a 22.5 degrees angle (e.g., angle between the imaging beam <b>610</b> and the normal <b>620</b> of the dichroic beam splitter <b>608</b> can be 22.5 degrees). In some implementations, decreasing the angle of incidence (or the angle between the imaging beam and the normal of the dichroic beam splitter) can improve the separation between the first wavelength band and the second wavelength of the imaging beam. In other words, decreasing the angle of incidence can result in sharper edges of the transmission and reflection characteristics of the dichroic filter. This can reduce portions of the first wavelength band from being transmitted and/or portions of the second wavelength band from being reflected.</p>
<p id="p-0053" num="0052">In some implementations, the orientation of the beam splitter <b>508</b> (or beam splitter <b>608</b>) in the prism <b>506</b> (or prism <b>606</b>) can vary. For example, the angle between the beam splitter <b>508</b> (or beam splitter <b>608</b>) and a surface of the prism <b>506</b> (or prism <b>606</b>) can vary. Based on the change in the angle of the beam splitter, the orientation of the sensors (e.g., first sensor <b>320</b>, <b>420</b>, second sensor <b>322</b>, <b>422</b>, etc.) can change. For example, the sensors in a given channel (e.g., first sensor <b>320</b> and second sensor <b>322</b> in channel <b>300</b>, first sensor <b>420</b> and second sensor <b>422</b> in channel <b>400</b>, etc.) may be oriented at a non-perpendicular angle.</p>
<p id="p-0054" num="0053"><figref idref="DRAWINGS">FIG. <b>7</b></figref> illustrates an exemplary two-channel imaging system <b>700</b> that includes a first channel <b>710</b> (e.g., channel <b>300</b>, channel <b>400</b>, etc.) and a second channel <b>720</b> (e.g., channel <b>300</b>, channel <b>400</b>, etc.). The first channel <b>710</b> includes a first sensor <b>712</b> and a second sensor <b>714</b> that can capture the visible light image and infrared image of the surgical region, respectively. The first channel <b>720</b> includes a third sensor <b>722</b> and a fourth sensor <b>724</b> that can capture the visible light image and infrared image of the surgical region, respectively. The two-channel imaging system <b>700</b> can allow for simultaneous capture of four images (e.g., two visible light images and two infrared images) via four sensors (e.g., first sensor <b>712</b>, second sensor <b>714</b>, third sensor <b>722</b> and fourth sensor <b>724</b>). This can improve the image throughput of the two-channel imaging system <b>700</b> in comparison to a single channel imaging system.</p>
<p id="p-0055" num="0054"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is a schematic illustration of the exemplary control system <b>150</b> of multi-spectral surgical imaging system <b>100</b>. As shown, the control system <b>150</b> includes a controller <b>202</b> having at least one processor that is in operable communication with, among other components, a memory <b>204</b>, visible light radiation source <b>212</b> and infrared radiation source <b>214</b> (e.g., included in the source <b>104</b>), the surgical instrument <b>102</b>, and the display <b>220</b>. The memory <b>204</b> is configured to store instructions executable by the processor of the controller <b>202</b> to process images captured by the image sensors in the imaging system <b>130</b> of the surgical instrument <b>102</b>. For example, the controller <b>202</b> can generate a modified image <b>250</b> that includes a superposition of the first image (or a portion thereof) captured by the visible light sensor (e.g., first sensor <b>320</b>, <b>420</b>) and the second image (or a portion thereof) captured by the visible light sensor (e.g., second sensor <b>322</b>, <b>422</b>). The modified image can be displayed in the display <b>220</b>.</p>
<p id="p-0056" num="0055"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates a flowchart <b>900</b> of an exemplary multi-spectral surgical imaging method. At step <b>902</b>, an imaging beam (e.g., imaging beam <b>108</b>) can be received from a surgical region by an optical system (e.g., optical system <b>308</b>) in an imaging system (e.g., imaging system <b>100</b>). The imaging beam can include a first wavelength band and a second wavelength band, and is directed along an optical axis of the optical system. In some implementations, a guiding optical system (e.g., guiding optical system <b>306</b>) can guide the imaging beam from an aperture of the imaging system <b>100</b> to the optical system. At step <b>904</b>, a first optical beam associated with the first wavelength band can be directed along a first direction, and a second optical beam associated with the second wavelength band can be directed along a second direction by a dichroic beam splitter (e.g., dichroic beam splitter <b>508</b>, dichroic beam splitter <b>608</b>, etc.). At step <b>906</b>, a first image associated with the first optical beam can be captured by a first sensor (e.g., first sensor <b>320</b>, <b>420</b>) located along the first direction. At step <b>908</b>, the second optical beam can be received by a relay lens system (e.g. relay lens system <b>440</b>) located along the second direction downstream from the optical system. The second optical beam can be received by a first end of the relay lens system. The second optical beam (or a portion thereof) can be transmitted via a second end of the first relay lens system. At step <b>910</b>, a second image associated with the second optical beam is captured by a second sensor located along the second direction downstream from the relay lens system and adjacent to the second end of the relay lens system.</p>
<p id="p-0057" num="0056">The multi-step imaging method can further include generating a modified image by superposing the first image (or a portion thereof) and the second image (or a portion thereof). The first image can be a visible light image of the surgical region, and the second image can be an infrared image of the surgical region. By superposing the visible light image and the infrared image to generate the modified image, information associated with both the visible light image and the infrared image can be simultaneously be presented (e.g., via a display to a surgeon). This can allow the surgeon to view portions of the surgical region that may not be visible by visible light image alone. Additionally, having separate sensors for capturing the visible light image and the infrared image can result in a high quality modified image of the surgical region (e.g., the modified image that can have a high frame rate).</p>
<p id="p-0058" num="0057">One skilled in the art will appreciate further features and advantages of the invention based on the above-described embodiments. Accordingly, the invention is not to be limited by what has been particularly shown and described, except as indicated by the appended claims. All publications and references cited herein are expressly incorporated herein by reference in their entirety.</p>
<p id="p-0059" num="0058">In some implementations, source code can be human-readable code that can be written in program languages such as python, C++, etc. In some implementations, computer-executable codes can be machine-readable codes that can be generated by compiling one or more source codes. Computer-executable codes can be executed by operating systems (e.g., linux, windows, mac, etc.) of a computing device or distributed computing system. For example, computer-executable codes can include data needed to create runtime environment (e.g., binary machine code) that can be executed on the processors of the computing system or the distributed computing system.</p>
<p id="p-0060" num="0059">Other embodiments are within the scope and spirit of the disclosed subject matter. For example, the prioritization method described in this application can be used in facilities that have complex machines with multiple operational parameters that need to be altered to change the performance of the machines. Usage of the word &#x201c;optimize&#x201d; / &#x201c;optimizing&#x201d; in this application can imply &#x201c;improve&#x201d; / &#x201c;improving.&#x201d;</p>
<p id="p-0061" num="0060">Certain exemplary embodiments will now be described to provide an overall understanding of the principles of the structure, function, manufacture, and use of the systems, devices, and methods disclosed herein. One or more examples of these embodiments are illustrated in the accompanying drawings. Those skilled in the art will understand that the systems, devices, and methods specifically described herein and illustrated in the accompanying drawings are non-limiting exemplary embodiments and that the scope of the present invention is defined solely by the claims. The features illustrated or described in connection with one exemplary embodiment may be combined with the features of other embodiments. Such modifications and variations are intended to be included within the scope of the present invention. Further, in the present disclosure, like-named components of the embodiments generally have similar features, and thus within a particular embodiment each feature of each like-named component is not necessarily fully elaborated upon.</p>
<p id="p-0062" num="0061">The subject matter described herein can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structural means disclosed in this specification and structural equivalents thereof, or in combinations of them. The subject matter described herein can be implemented as one or more computer program products, such as one or more computer programs tangibly embodied in an information carrier (e.g., in a machine-readable storage device), or embodied in a propagated signal, for execution by, or to control the operation of, data processing apparatus (e.g., a programmable processor, a computer, or multiple computers). A computer program (also known as a program, software, software application, or code) can be written in any form of programming language, including compiled or interpreted languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file. A program can be stored in a portion of a file that holds other programs or data, in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.</p>
<p id="p-0063" num="0062">The processes and logic flows described in this specification, including the method steps of the subject matter described herein, can be performed by one or more programmable processors executing one or more computer programs to perform functions of the subject matter described herein by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus of the subject matter described herein can be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).</p>
<p id="p-0064" num="0063">Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processor of any kind of digital computer. Generally, a processor will receive instructions and data from a Read-Only Memory or a Random Access Memory or both. The essential elements of a computer are a processor for executing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. Information carriers suitable for embodying computer program instructions and data include all forms of non-volatile memory, including by way of example semiconductor memory devices, (e.g., EPROM, EEPROM, and flash memory devices); magnetic disks, (e.g., internal hard disks or removable disks); magneto-optical disks; and optical disks (e.g., CD and DVD disks). The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.</p>
<p id="p-0065" num="0064">To provide for interaction with a user, the subject matter described herein can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, (e.g., a mouse or a trackball), by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well. For example, feedback provided to the user can be any form of sensory feedback, (e.g., visual feedback, auditory feedback, or tactile feedback), and input from the user can be received in any form, including acoustic, speech, or tactile input.</p>
<p id="p-0066" num="0065">The techniques described herein can be implemented using one or more modules. As used herein, the term &#x201c;module&#x201d; refers to computing software, firmware, hardware, and/or various combinations thereof. At a minimum, however, modules are not to be interpreted as software that is not implemented on hardware, firmware, or recorded on a non-transitory processor readable recordable storage medium (i.e., modules are not software per se). Indeed &#x201c;module&#x201d; is to be interpreted to always include at least some physical, non-transitory hardware such as a part of a processor or computer. Two different modules can share the same physical hardware (e.g., two different modules can use the same processor and network interface). The modules described herein can be combined, integrated, separated, and/or duplicated to support various applications. Also, a function described herein as being performed at a particular module can be performed at one or more other modules and/or by one or more other devices instead of or in addition to the function performed at the particular module. Further, the modules can be implemented across multiple devices and/or other components local or remote to one another. Additionally, the modules can be moved from one device and added to another device, and/or can be included in both devices.</p>
<p id="p-0067" num="0066">The subject matter described herein can be implemented in a computing system that includes a back-end component (e.g., a data server), a middleware component (e.g., an application server), or a front-end component (e.g., a client computer having a graphical user interface or a web interface through which a user can interact with an implementation of the subject matter described herein), or any combination of such back-end, middleware, and front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (&#x201c;LAN&#x201d;) and a wide area network (&#x201c;WAN&#x201d;), e.g., the Internet.</p>
<p id="p-0068" num="0067">Approximating language, as used herein throughout the specification and claims, may be applied to modify any quantitative representation that could permissibly vary without resulting in a change in the basic function to which it is related. Accordingly, a value modified by a term or terms, such as &#x201c;about&#x201d; and &#x201c;substantially,&#x201d; are not to be limited to the precise value specified. In at least some instances, the approximating language may correspond to the precision of an instrument for measuring the value. Here and throughout the specification and claims, range limitations may be combined and/or interchanged, such ranges are identified and include all the sub-ranges contained therein unless context or language indicates otherwise.</p>
<?detailed-description description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text><b>1</b>. An imaging system comprising:
<claim-text>a first optical system configured to receive an imaging beam from a surgical region, the imaging beam including a first wavelength band and a second wavelength band, wherein the imaging beam is directed along a first optical axis,
<claim-text>wherein the first optical system includes a dichroic beam splitter, the first optical system is configured to direct a first optical beam associated with the first wavelength band along a first direction and direct a second optical beam associated with the second wavelength band along a second direction;</claim-text>
</claim-text>
<claim-text>a first sensor located along the first direction and configured to capture a first image associated with the first optical beam;</claim-text>
<claim-text>a first relay lens system located along the second direction downstream from the first optical system and configured to receive the second optical beam at a first end of the first relay lens system and transmit at least a portion of the second optical beam via a second end of the first relay lens system; and</claim-text>
<claim-text>a second sensor located downstream from the first relay lens system and adjacent to the second end of the first relay lens system, wherein the second sensor is configured to capture a second image associated with the second optical beam.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text><b>2</b>. The imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first optical system, the first sensor, the first relay lens system and the second sensor are located at a distal end of a surgical scope device.</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text><b>3</b>. The imaging system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the surgical scope device is configured to receive the imaging beam in the surgical region and guide the imaging beam to the first optical system.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text><b>4</b>. The imaging system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the surgical scope device is a stereo scope.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text><b>5</b>. The imaging system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the surgical scope device is one of an endoscope and a laparoscope.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text><b>6</b>. The imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one optical element in the first optical system is a 45 degree prism, wherein the pentaprism includes the dichroic beam splitter.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text><b>7</b>. The imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein at least one optical element in the first optical system is a pentaprism, wherein the pentaprism includes the dichroic beam splitter.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text><b>8</b>. The imaging system of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the dichroic beam splitter is located at a proximal surface of the pentaprism.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text><b>9</b>. The imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first sensor is located at a first image plane and the second sensor is located at a second image plane, wherein a first distance of the first sensor relative to the first optical system is less than a second distance of the second sensor relative to the first optical system.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text><b>10</b>. The imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a first size of the first image detected by the first sensor is different from a second size of a second image detected by the second sensor.</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text><b>11</b>. The imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein an active optical area of the first sensor and an active area of the second sensor are of different sizes.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text><b>12</b>. The imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first direction is perpendicular to the second direction.</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text><b>13</b>. The imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a light source is used to illuminate the object to be imaged.</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text><b>14</b>. The imaging system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the light source includes a plurality of individually selectable narrow or wide wavelength bands.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text><b>15</b>. The imaging system of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the light source includes one or more of lasers, light emitting diodes and incandescent sources configured to generate the narrow or wide wavelength bands.</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text><b>16</b>. The imaging system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>a second optical system configured to receive the imaging beam from the surgical region, wherein the second optical system is configured to direct a third optical beam associated with the first wavelength band along a third direction and direct a fourth optical beam associated with the second wavelength band along a fourth direction;</claim-text>
<claim-text>a third sensor located along the third direction and configured to capture a third image associated with the third optical beam;</claim-text>
<claim-text>a second relay lens system located along the fourth direction downstream from the second optical system and configured to receive the fourth optical beam at a first end of the second relay lens system and transmit at least a portion of the fourth optical beam via a second end of the second relay lens system; and</claim-text>
<claim-text>a fourth sensor located downstream from the second relay lens system and adjacent to the second end of the second relay lens system, wherein the fourth sensor is configured to capture a second image associated with the second optical beam.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text><b>17</b>. An imaging system comprising:
<claim-text>a first optical system configured to receive an imaging beam from a surgical region, the imaging beam including a first wavelength band and a second wavelength band, wherein the imaging beam is directed along a first optical axis,
<claim-text>wherein the first optical system includes a dichroic beam splitter, the first optical system is configured to direct a first optical beam associated with the first wavelength band along a first direction and direct a second optical beam associated with the second wavelength band along a second direction;</claim-text>
</claim-text>
<claim-text>a first sensor located along the first direction and configured to capture a first image associated with the first optical beam;</claim-text>
<claim-text>a second sensor located along the second direction downstream from the first optical module and configured to receive the second optical beam, wherein the second sensor is configured to capture a second image associated with the second optical beam.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text><b>18</b>. A surgical instrument comprising:
<claim-text>a surgical scope device including a distal end and a proximal end, wherein the distal end of the surgical scope device is configured to be placed in a surgical region; and</claim-text>
<claim-text>an imaging system located in the distal end of the surgical scope device, the imaging system including:
<claim-text>a first optical system configured to receive an imaging beam from a surgical region, the imaging beam including a first wavelength band and a second wavelength band, wherein the imaging beam is directed along a first optical axis</claim-text>
<claim-text>wherein the first optical system includes a dichroic beam splitter, the first optical system is configured to direct a first optical beam associated with the first wavelength band along a first direction and direct a second optical beam associated with the second wavelength band along a second direction;</claim-text>
</claim-text>
<claim-text>a first sensor located along the first direction and configured to capture a first image associated with the first optical beam;</claim-text>
<claim-text>a first relay lens system located along the second direction downstream from the first optical system and configured to receive the second optical beam at a first end of the first relay lens system and transmit at least a portion of the second optical beam via a second end of the first relay lens system; and</claim-text>
<claim-text>a second sensor located downstream from the first relay lens system and adjacent to the second end of the first relay lens system, wherein the second sensor is configured to capture a second image associated with the second optical beam.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text><b>19</b>. The surgical instrument of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the proximal end of the surgical scope includes a processor configured to receive a first signal representative of the first image detected by the first sensor and receive a second signal representative of the second image detected by the second sensor.</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text><b>20</b>. The surgical instrument of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the processor is configured to generate a modified image that includes a superposition of at least a portion of the first image and at least a portion of the second image.</claim-text>
</claim>
<claim id="CLM-00021" num="00021">
<claim-text><b>21</b>. A method comprising:
<claim-text>receiving, via a first optical system, an imaging beam from a surgical region, wherein the imaging beam includes a first wavelength band and a second wavelength band, and is directed along a first optical axis;</claim-text>
<claim-text>directing, by a dichroic beam splitter, a first optical beam associated with the first wavelength band along a first direction and directing a second optical beam associated with the second wavelength band along a second direction;</claim-text>
<claim-text>capturing a first image associated with the first optical beam, wherein the first image is captured by a first sensor located along the first direction;</claim-text>
<claim-text>receiving the second optical beam by a first relay system located along the second direction downstream from the first optical system, wherein the second optical beam is received at a first end of the first relay lens system, and transmitting at least a portion of the second optical beam via a second end of the first relay lens system; and</claim-text>
<claim-text>capturing a second image associated with the second optical beam, wherein the second image is captured by a second sensor located along the second direction downstream from the first relay lens system and adjacent to the second end of the first relay lens system.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00022" num="00022">
<claim-text><b>22</b>. The method of <claim-ref idref="CLM-00021">claim 21</claim-ref> further comprising generating a modified image by at least superposing at least a portion of the first image and at least a portion of the second image.</claim-text>
</claim>
</claims>
</us-patent-application>
