<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]>
<us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230225517A1-20230720.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20230621" date-publ="20230720">
<us-bibliographic-data-application lang="EN" country="US">
<publication-reference>
<document-id>
<country>US</country>
<doc-number>20230225517</doc-number>
<kind>A1</kind>
<date>20230720</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>18094751</doc-number>
<date>20230109</date>
</document-id>
</application-reference>
<us-application-series-code>18</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>47</class>
<subclass>C</subclass>
<main-group>19</main-group>
<subgroup>02</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>N</subclass>
<main-group>20</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>47</class>
<subclass>C</subclass>
<main-group>19</main-group>
<subgroup>22</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>0205</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>11</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>G</subclass>
<main-group>19</main-group>
<subgroup>44</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>G</subclass>
<main-group>19</main-group>
<subgroup>52</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>G</subclass>
<main-group>21</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>01</class>
<subclass>V</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>05</class>
<subclass>B</subclass>
<main-group>15</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>06</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>04</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>G</section>
<class>08</class>
<subclass>B</subclass>
<main-group>21</main-group>
<subgroup>22</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classifications-cpc>
<main-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>47</class>
<subclass>C</subclass>
<main-group>19</main-group>
<subgroup>027</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</main-cpc>
<further-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>47</class>
<subclass>C</subclass>
<main-group>19</main-group>
<subgroup>22</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>0205</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>725</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>1102</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>1115</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>4818</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>6891</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>6892</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>7203</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>7246</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>7267</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>7278</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>7282</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>7415</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>01</class>
<subclass>G</subclass>
<main-group>19</main-group>
<subgroup>52</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>01</class>
<subclass>G</subclass>
<main-group>19</main-group>
<subgroup>445</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>01</class>
<subclass>G</subclass>
<main-group>21</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>01</class>
<subclass>V</subclass>
<main-group>9</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>05</class>
<subclass>B</subclass>
<main-group>15</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>06</class>
<subclass>N</subclass>
<main-group>5</main-group>
<subgroup>04</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20190101</date></cpc-version-indicator>
<section>G</section>
<class>06</class>
<subclass>N</subclass>
<main-group>20</main-group>
<subgroup>00</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>G</section>
<class>08</class>
<subclass>B</subclass>
<main-group>21</main-group>
<subgroup>22</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>61</class>
<subclass>B</subclass>
<main-group>5</main-group>
<subgroup>0816</subgroup>
<symbol-position>L</symbol-position>
<classification-value>A</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</further-cpc>
</classifications-cpc>
<invention-title id="akhgtcvg2jbc0">Systems and Methods for Generating Synthetic Cardio-Respiratory Signals</invention-title>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>16777385</doc-number>
<date>20200130</date>
</document-id>
<parent-status>ABANDONED</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>18094751</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation-in-part>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>16595848</doc-number>
<date>20191008</date>
</document-id>
<parent-status>ABANDONED</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>16777385</doc-number>
</document-id>
</child-doc>
</relation>
</continuation-in-part>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>62804623</doc-number>
<date>20190212</date>
</document-id>
</us-provisional-application>
<us-provisional-application>
<document-id>
<country>US</country>
<doc-number>62804623</doc-number>
<date>20190212</date>
</document-id>
</us-provisional-application>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="obligated-assignee">
<addressbook>
<orgname>Sleep Number Corporation</orgname>
<address>
<city>Minneapolis</city>
<state>MN</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="00" designation="us-only">
<addressbook>
<last-name>Sayadi</last-name>
<first-name>Omid</first-name>
<address>
<city>San Jose</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="01" designation="us-only">
<addressbook>
<last-name>Young</last-name>
<first-name>Steven Jay</first-name>
<address>
<city>Los Gatos</city>
<state>CA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
</us-bibliographic-data-application>
<abstract id="abstract">
<p id="p-0001" num="0000">Devices and methods for generating synthetic cardio-respiratory signals from one or more ballistocardiogram (BCG) sensors. A method for determining item specific parameters includes obtaining ballistocardiogram (BCG) data from one or more sensors, where the one or more sensors capture BCG data for one or more subjects in relation to a substrate. For each subject, the captured BCG data is pre-processed to obtain cardio-respiratory BCG data. The cardio-respiratory BCG data is sub-sampled to generate the cardio-respiratory BCG data at a cardio-respiratory sampling rate conducive to cardio-respiratory signal generation. The sub-sampled cardio-respiratory BCG data is cardio-respiratory processed to generate a cardio-respiratory parameter set. A synthetic cardio-respiratory signal is generated from at least the cardio-respiratory parameter set and a cardio-respiratory event morphology template. A condition of the subject is determined based on the synthetic cardio-respiratory signal.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="159.94mm" wi="159.68mm" file="US20230225517A1-20230720-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="172.38mm" wi="143.85mm" file="US20230225517A1-20230720-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="169.59mm" wi="159.00mm" file="US20230225517A1-20230720-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="224.62mm" wi="144.27mm" file="US20230225517A1-20230720-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="228.94mm" wi="155.11mm" file="US20230225517A1-20230720-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="210.90mm" wi="157.56mm" file="US20230225517A1-20230720-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="217.51mm" wi="152.23mm" file="US20230225517A1-20230720-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="224.96mm" wi="168.49mm" file="US20230225517A1-20230720-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="216.83mm" wi="158.92mm" file="US20230225517A1-20230720-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="225.04mm" wi="150.20mm" file="US20230225517A1-20230720-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="224.96mm" wi="150.88mm" file="US20230225517A1-20230720-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="211.24mm" wi="145.46mm" file="US20230225517A1-20230720-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="206.67mm" wi="149.86mm" file="US20230225517A1-20230720-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="191.35mm" wi="147.32mm" file="US20230225517A1-20230720-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="204.81mm" wi="60.79mm" file="US20230225517A1-20230720-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="172.21mm" wi="155.28mm" file="US20230225517A1-20230720-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="231.99mm" wi="169.93mm" file="US20230225517A1-20230720-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
</drawings>
<description id="description">
<?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?>
<heading level="1" id="h-0001">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation of U.S. Pat. Application Serial No. 16/777,385, filed on Jan. 30, 2020, which is a continuation-in-part of U.S. Pat. Application Serial No. 16/595,848, filed Oct. 8, 2019, which claims priority U.S. Provisional Application Pat. Serial No. 62/804,623, filed Feb. 12, 2019, the entire disclosures of which are hereby incorporated by reference.</p>
<p id="p-0003" num="0002">This application claims priority to and the benefit of U.S. Provisional Application Pat. Serial No. 62/804,623, filed Feb. 12, 2019, the entire disclosure of which is hereby incorporated by reference.</p>
<?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?>
<?summary-of-invention description="Summary of Invention" end="lead"?>
<heading level="1" id="h-0002">TECHNICAL FIELD</heading>
<p id="p-0004" num="0003">This disclosure relates to systems and methods for determining and monitoring biosignals, such as cardiac and respiratory biosignals, based on contactless sensor signals.</p>
<heading level="1" id="h-0003">BACKGROUND</heading>
<p id="p-0005" num="0004">Cardiac and respiratory signal monitoring requires electrical equipment and sensors connected to a subject using wires, belts, nasal cannula, or like attachments. These attachments limit the mobility of the subject and cannot be conveniently done for long hours, especially in non-hospital type settings like a home. Moreover, the need to re-attach the sensors limit the repeatability and consistency of measurements over long periods of time.</p>
<heading level="1" id="h-0004">SUMMARY</heading>
<p id="p-0006" num="0005">Disclosed herein are implementations of devices and methods for generating synthetic cardio-respiratory signals from one or more ballistocardiogram (BCG) sensors. In an implementation, a method for determining item specific parameters includes obtaining ballistocardiogram (BCG) data from one or more sensors, where the one or more sensors capture BCG data for one or more subjects in relation to a substrate. For each subject, the captured BCG data is pre-processed to obtain cardio-respiratory BCG data. The cardio-respiratory BCG data is sub-sampled to generate the cardio-respiratory BCG data at a cardio-respiratory sampling rate conducive to cardio-respiratory signal generation. The sub-sampled cardio-respiratory BCG data is cardio-respiratory processed to generate a cardio-respiratory parameter set. A synthetic cardio-respiratory signal is generated from at least the cardio-respiratory parameter set and a cardio-respiratory event morphology template. A condition of the subject is determined based on the synthetic cardio-respiratory signal.</p>
<?summary-of-invention description="Summary of Invention" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading level="1" id="h-0005">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0007" num="0006">The disclosure is best understood from the following detailed description when read in conjunction with the accompanying drawings. It is emphasized that, according to common practice, the various features of the drawings are not to-scale. On the contrary, the dimensions of the various features are arbitrarily expanded or reduced for clarity.</p>
<p id="p-0008" num="0007"><figref idref="DRAWINGS">FIG. <b>1</b></figref> is an illustration of a bed incorporating sensors as disclosed herein.</p>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is an illustration of the bed frame with sensors incorporated, the bed frame configured to support a single subject.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is an illustration of a bed frame with sensors incorporated, the bed frame configured to support two subjects.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a system architecture for a multidimensional multivariate multiple sensors system.</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a processing pipeline for obtaining sensors data.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a pre-processing pipeline for processing the sensors data into multiple sensors multiple dimensions array (MSMDA) data.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart for generating synthetic cardio-respiratory signals.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is an example of signals generated in the method of generating synthetic cardio-respiratory signals.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart for generating synthetic cardio signals.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart for generating synthetic respiratory signals.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart for generating synthetic cardio-respiratory time series and sound streams using a defined template sound.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart for generating synthetic cardio-respiratory time series and sound streams using an adaptive template sound.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIG. <b>13</b>A</figref> is a flowchart for generating synthetic cardio-respiratory signals from a multiple sensor multiple dimensions system.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIGS. <b>13</b>B-E</figref> are example surface location maps for a multidimensional multivariate multiple sensors system with 4 sensors.</p>
<p id="p-0022" num="0021"><figref idref="DRAWINGS">FIG. <b>14</b></figref> is an example of surface location map and spatial cardio-respiratory maps.</p>
<p id="p-0023" num="0022"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a swim lane diagram for building and classifying individualized and population morphology templates.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?detailed-description description="Detailed Description" end="lead"?>
<heading level="1" id="h-0006">DETAILED DESCRIPTION</heading>
<p id="p-0024" num="0023">Disclosed herein are systems and methods for generating and monitoring biosignal weight, morphology, rhythm and rate information of a subject from one or more ballistocardiogram (BCG) sensors. The systems and methods use one or more patient non-contact sensors such as pressure, load, weight, force, motion, vibration or accelerometer based sensors to continuously capture the mechanical vibrations of the body, heart, and lungs and translate that into synthetic cardio-respiratory signals. In particular, the systems and methods enable contactless generation of synthetic electrocardiographic and respiratory signals. In addition, cardiac and respiratory audio streams may be generated for playback with the synthetic electrocardiographic and respiratory signals.</p>
<p id="p-0025" num="0024">The mechanical vibrations are transformed into synthetic signals that look like the electrical measurements from the heart or the flow/ventilation measurements from the lungs. The mechanical vibrations are also transformed into synthetic signals that sound like the mechanical movements from the heart or the flow/ventilation movements from the lungs. The synthetic signals along with synthetic cardiac and breathing audio streams, can be stored, displayed onsite, displayed remotely, or analyzed using automated processing or artificial intelligence (AI) techniques.</p>
<p id="p-0026" num="0025">The synthetic signals, the synthetic cardiac and breathing audio streams, or combinations thereof can be used to monitor and detect a variety of physiological conditions. In an implementation, the synthetic signals can be used to detect physiological conditions that impact the rhythm and rate of the biosignals, including atrial fibrillation, atrial flutter, ventricular fibrillation, ventricular flutter, bundle branch blocks, valve stenosis, myocardial ischemia, supraventricular tachycardia, apnea, hypopnea, Cheyne stoke breathing, snoring and the like. In an implementation, the synthetic audio streams can be used to detect physiological conditions that impact the sound of the biosignals, including heart murmurs, snoring, coughing, wheezing, rales, rhonchi, and the like.</p>
<p id="p-0027" num="0026">In an implementation, the system generates cardiac beat morphology or respiratory breath morphology templates as a baseline for a subject which can be monitored in real-time or over a period of time to identify changes from the subject&#x2019;s baseline. In an implementation, the cardiac beat morphology template can be used to predict or detect heart conditions that alter the cardiac morphology such as, but not limited to, atrial fibrillation, atrial flutter, ventricular fibrillation, ventricular flutter, bundle branch blocks, valve stenosis, myocardial ischemia, and the like. In an implementation, the respiratory breath morphology template can be used to predict or detect breathing conditions that alter the respiratory morphology such as, but not limited to, apnea, hypopnea, Cheyne stoke breathing, snoring, and the like.</p>
<p id="p-0028" num="0027">A database of cardiac beat morphology and/or respiratory breath morphology templates stored can be used to build individualized and population models of normal morphologies and different diseases and use those models to train machine learning classifiers to automatically detect changes in morphologies due to arrhythmias or diseases.</p>
<p id="p-0029" num="0028">In an implementation using multiple sensors, the system can create spatial cardiac and respiration maps which provide different views of the heart and lungs function including a complete three-dimensional view of the electrical activity of the heart and mechanical activity of the lungs. Spatial maps can be used to diagnosis conditions that affect a localized portion of the heart or lung, such as myocardial infarction for example, that would otherwise be missed or undiagnosed. The spatial maps can be used to predict and diagnose changes in health status, arrhythmias, and diseases related to, for example, cardio-respiratory conditions.</p>
<p id="p-0030" num="0029">The availability of multiple sensors enables the generation of a fuller picture of the three-dimensional electrical activity of the heart and lung. The body including the heart and lung are is a three-dimensional structure, and the electrical currents and respiratory pathways are spread out in all directions across the body. The more points of data that are recorded, the more accurate the representation of the electrical and respiratory activity. The combination of surface location maps for multiple sensors and the spatial cardiac or respiratory map(s) enables the diagnosis of conditions that affect one localized portion of the heart or lung, such as for example, myocardial infarction.</p>
<p id="p-0031" num="0030">In an implementation, the one or more sensors can be any sensor that records at least one ballistocardiogram (BCG) signal using non-contact sensors such as pressure, load, force, motion or accelerometer. The contactless signals can be obtained from one or more sensors that are implemented in a variety of forms or structures including, but not limited to, bed, couch, chair, examination table, floor, air chamber bed, wearable clothing, smart scale, and the like. The one or more sensors can be configured in any type of surface depending on the application.</p>
<p id="p-0032" num="0031">The data collected by the sensors can be collected for a particular subject for a period of time, or indefinitely, and can be collected in any location, such as at home, at work, in a hospital, nursing home or other medical facility. A limited period of time may be a doctor&#x2019;s visit to assess biometric data against baseline data or can be for a hospital stay to monitor cardiac signals for atrial fibrillation patterns. Messages can be sent to family and caregivers and/or reports can be generated for doctors.</p>
<p id="p-0033" num="0032">The data collected by the sensors can be collected and analyzed for much longer periods of time, such as years or decades, when the sensors are incorporated into a subject&#x2019;s personal or animal&#x2019;s residential bed. The sensors and associated systems and methods can be transferred from one substrate to another to continue to collect data from a particular subject.</p>
<p id="p-0034" num="0033"><figref idref="DRAWINGS">FIGS. <b>1</b> and <b>2</b></figref> illustrate a system <b>100</b> for measuring data specific to a subject <b>10</b> using gravity. The system <b>100</b> can comprise a substrate <b>20</b> on which the subject <b>10</b> can lie. The substrate <b>20</b> is held in a frame <b>102</b> having multiple legs <b>104</b> extending from the frame <b>102</b> to a floor to support the substrate <b>20</b>. Multiple load or other sensors <b>106</b> can be used, each load or other sensor <b>106</b> associated with a respective leg <b>104</b>. Any point in which a load is transferred from the substrate <b>20</b> to the floor can have an intervening load or other sensor <b>106</b>. Placement of the sensors is illustrative and they can be located in a variety of locations including, but not limited to, bed frame, mattress, and the like.</p>
<p id="p-0035" num="0034">As illustrated in <figref idref="DRAWINGS">FIG. <b>2</b></figref>, a local controller <b>200</b> can be wired or wirelessly connected to the load or other sensors <b>106</b> and collects and processes the signals from the load or other sensors <b>106</b>. The controller <b>200</b> can be attached to the frame <b>102</b> so that it is hidden from view, can be on the floor under the substrate or can be positioned anywhere a wireless transmission can be received from the load or other sensors <b>106</b> if transmission is wireless. Wiring <b>202</b> may electrically connect the load or other sensors <b>106</b> to the controller <b>200</b>. The wiring <b>202</b> may be attached to an interior of the frame <b>102</b> and/or may be routed through the interior channels <b>110</b> of the frame <b>102</b>. The controller <b>200</b> can collect and process signals from the load or other sensors <b>106</b>. The controller <b>200</b> may also be configured to output power to the sensors and/or to printed circuit boards disposed in the load or other sensors <b>106</b>.</p>
<p id="p-0036" num="0035">The controller <b>200</b> can be programmed to control other devices based on the processed data, such as bedside or overhead lighting, door locks, electronic shades, fans, etc., the control of other devices also being wired or wireless. Alternatively, or in addition to, a cloud based computer <b>212</b> or off-site controller <b>214</b> can collect the signals directly from the load or other sensors <b>106</b> for processing or can collect raw or processed data from the controller <b>200</b>. For example, the controller <b>200</b> may process the data in real time and control other local devices as disclosed herein, while the data is also sent to the off-site controller <b>214</b> that collects and stores the data over time. The controller <b>200</b> or the off-site controller <b>214</b> may transmit the processed data off-site for use by downstream third parties such a medical professionals, fitness trainers, family members, etc. The controller <b>200</b> or the off-site controller <b>214</b> can be tied to infrastructure that assists in collecting, analyzing, publishing, distributing, storing, machine learning, etc. Design of real-time data stream processing has been developed in an event-based form using an actor model of programming. This enables a producer/consumer model for algorithm components that provides a number of advantages over more traditional architectures. For example, it enables reuse and rapid prototyping of processing and algorithm modules. As another example, data streams can be enabled/disabled dynamically and routed to or from modules at any point within a group of modules comprising an algorithmic system, enabling computation to be location-independent (i.e., on a single device, combined with one or more additional devices or servers, on a server only, etc.).</p>
<p id="p-0037" num="0036">The long-term collected data can be used in both a medical and home setting to learn and predict patterns of sleep, illness, etc. for a subject. As algorithms are continually developed, the long-term data can be reevaluated to learn more about the subject. Sleep patterns, weight gains and losses, changes in heart beat and respiration can together or individually indicate many different ailments. Alternatively, patterns of subjects who develop a particular ailment can be studied to see if there is a potential link between any of the specific patterns and the ailment.</p>
<p id="p-0038" num="0037">The data can also be sent live from the controller <b>200</b> or the off-site controller <b>214</b> to a connected device <b>216</b>, which can be wirelessly connected for wired. The connected device <b>216</b> can be, as examples, a mobile phone or home computer. Devices can subscribe to the signal, thereby becoming a connected device <b>216</b>.</p>
<p id="p-0039" num="0038"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a top perspective view of a frame <b>204</b> for a bed <b>206</b> used with a substrate on which two or more subjects can lie. The bed <b>206</b> may include features similar to those of the bed <b>100</b> except as otherwise described. The bed <b>206</b> includes a frame <b>204</b> configured to support two or more subjects. The bed <b>206</b> may include eight legs, including one load or other sensor <b>106</b> disposed at each leg <b>104</b>. In other embodiments, the bed may include nine legs <b>104</b> and nine load or other sensors <b>106</b>, the additional sensor <b>106</b> disposed at the middle of the central frame member <b>208</b>. In other embodiments, the bed <b>206</b> may include any arrangement of load or other sensors <b>106</b>. Two controllers <b>200</b> and <b>201</b>, for example, can be attached to the frame <b>204</b>. The controllers <b>200</b> may be in wired or wireless communication with its respective sensors and optionally with each other. Each of the controllers <b>200</b> collects and processes signals from a subset of load or other sensors <b>106</b>. For example, one controller <b>200</b> can collect and process signals from load or other sensors <b>106</b> (e.g. four load or other sensors) configured to support one subject lying on the bed <b>206</b>. Another controller <b>200</b> can collect and process signals from the other load or other sensors <b>106</b> (e.g. four load or other sensors) configured to support the other subject lying on the bed <b>206</b>. Wiring <b>210</b> may connect the load or other sensors <b>106</b> to either or both of the controllers <b>200</b> attached to the frame <b>204</b>. In an implementation, wiring <b>220</b> can connect controllers <b>200</b> and <b>201</b>. The wiring <b>210</b> may also connect the controllers <b>200</b>. In other embodiments, the controllers may be in wireless communication with each other. In an implementation, one of the controllers <b>200</b> and <b>201</b>, can process the signals collected by both of the controllers <b>200</b> and <b>201</b>.</p>
<p id="p-0040" num="0039">Examples of data determinations that can be made using the systems herein are described. The algorithms use the number of sensors and each sensor&#x2019;s angle and distance with respect to the other sensors. This information is predetermined. Software algorithms will automatically and continuously maintain a baseline weight calibration with the sensors so that any changes in weight due to changes in a mattress or bedding is accounted for.</p>
<p id="p-0041" num="0040">The load or other sensors herein utilize macro signals and micro signals and process those signals to determine a variety of data, described herein. Macro signals are low frequency signals and are used to determine weight and center of mass, for example. The strength of the macro signal is directly influenced by the subject&#x2019;s proximity to each sensor.</p>
<p id="p-0042" num="0041">Micro signals are also detected due to the heartbeat, respiration and to movement of blood throughout the body. Micro signals are higher frequency and can be more than 1000 times smaller than macro signals. The sensors detect the heart beating and can use its corresponding amplitude or phase data to determine where on the substrate the heart is located, thereby assisting in determining in what location, angular orientation, and body position the subject is laying as described and shown herein. In addition, the heart pumps blood in such a way that it causes top to bottom changes in weight. There is approximately seven pounds of blood in a human subject, and the movement of the blood causes small changes in weight that can be detected by the sensors. These directional changes are detected by the sensors. The strength of the signal is directly influenced by the subject&#x2019;s proximity to the sensor. Respiration is also detected by the sensors. Respiration will be a different amplitude and a different frequency than the heart beat and has different directional changes than those that occur with the flow of blood. Respiration can also be used to assist in determining the exact location, angular orientation, and body position of a subject on the substrate. These bio-signals of heart beat, respiration and directional movement of blood are used in combination with the macro signals to calculate a large amount of data about a subject, including the relative strength of the signal components from each of the sensors, enabling better isolation of a subject&#x2019;s bio-signal from noise and other subjects.</p>
<p id="p-0043" num="0042">As a non-limiting example, the cardiac bio-signals in the torso area are out of phase with the signals in the leg regions. This allows the signals to be subtracted which almost eliminates common mode noise while allowing the bio-signals to be combined, increasing the signal to noise by as much as a factor of 3db or 2X and lowering the common or external noise by a significant amount. By analyzing the phase differences in the 1 Hz to 10 Hz range (typically the heart beat range) the body position of a person laying on the bed can be determined. By analyzing the phase differences in the 0 to 0.5 Hz range, it can be determined if the person is supine, prone or laying on their side, as non-limiting examples.</p>
<p id="p-0044" num="0043">Because signal strength is still quite small, the signal strength can be increased to a level more conducive to analysis by adding or subtracting signals, resulting in larger signals. The signals from each sensor can be combined by the signal from at least one, some, all or a combination of other sensors to increase the signal strength for higher resolution algorithmic analysis. The combining method can be linear or nonlinear addition, subtraction, multiplication or other transformations.</p>
<p id="p-0045" num="0044">The controller can be programmed to cancel out external noise that is not associated with the subject laying on the bed. External noise, such as the beat of a bass or the vibrations caused by an air conditioner, register as the same type of signal on all load or other sensors and is therefore canceled out when deltas are combined during processing. Other noise cancellation techniques can be used including, but not limited to, subtraction, combination of the sensor data, adaptive filtering, wavelet transform, independent component analysis, principal component analysis, and/or other linear or nonlinear transforms.</p>
<p id="p-0046" num="0045">Using superposition analysis, two subjects can be distinguished on one substrate. Superposition simplifies the analysis of the signal with multiple inputs. The usable signal equals the algebraic sum of the responses caused by each independent sensor acting alone. To ascertain the contribution of each individual source, all of the other sources must be calibrated first (turned off or set to zero). This procedure is followed for each source in turn, then the resultant responses are added to determine the true result. The resultant operation is the superposition of the various sources. By using signal strength and out-of-phase heart signal and/or respiration signal, individuals can be distinguished on the same substrate.</p>
<p id="p-0047" num="0046">The controller can be programmed to provide dynamic center of mass location and movement vectors for the subject, while eliminating those from other subjects and inanimate objects or animals on the substrate. By leveraging multiple sensor assemblies that detect the z-axis of the force vector of gravity, and by discriminating and tracking the center of mass of multiple subjects as they enter and move on a substrate, not only can presence, motion and cardiac and respiratory signals for the subject be determined, but the signals of a single or multiple subjects on the substrate can be enhanced by applying the knowledge of location to the signal received. By analyzing the bio-signal&#x2019;s amplitude and phase in different frequency bands, the center of mass (location) for a subject can be obtained using multiple methods, examples of which include:
<ul id="ul0001" list-style="none">
<li id="ul0001-0001" num="0047">DC weight;</li>
<li id="ul0001-0002" num="0048">AC low band analysis of signal, center of mass (location), respiratory and body position identification of subject;</li>
<li id="ul0001-0003" num="0049">AC mid band analysis of signal center of mass and cardiac identification of subject; and</li>
<li id="ul0001-0004" num="0050">AC upper mid band identification of snorer or apnea events.</li>
</ul>
</p>
<p id="p-0048" num="0051">The data from the load or other sensor assemblies can be used to determine presence and location X and Y, angular orientation, and body positions of a subject on a substrate. Such information is useful for calculating in/out statistics for a subject such as: period of time spent in bed, time when subject fell asleep, time when subject woke up, time spent on back, time spent on side, period of time spent out of bed. The sensor assemblies can be in sleep mode until the presence of a subject is detected on the substrate, waking up the system.</p>
<p id="p-0049" num="0052">Macro weight measurements can be used to measure the actual static weight of the subject as well as determine changes in weight over time. Weight loss or weight gain can be closely tracked as weight and changes in weight can be measured the entire time a subject is in bed every night. This information may be used to track how different activities or foods affect a person&#x2019;s weight. For example, excessive water retention could be tied to a particular food. In a medical setting, for example, a two-pound weight gain in one night or a five-pound weight gain in one week could raise an alarm that the patient is experiencing congestive heart failure. Unexplained weight loss or weight gain can indicate many medical conditions. The tracking of such unexplained change in weight can alert professionals that something is wrong.</p>
<p id="p-0050" num="0053">Center of mass can be used to accurately heat and cool particular and limited space in a substrate such as a mattress, with the desired temperature tuned to the specific subject associated with the center of mass, without affecting other subjects on the substrate. Certain mattresses are known to provide heating and/or cooling. As non-limiting examples, a subject can set the controller to actuate the substrate to heat the portion of the substrate under the center of mass when the temperature of the room is below a certain temperature. The subject can set the controller to instruct the substrate to cool the portion of the substrate under the center of mass when the temperature of the room is above a certain temperature.</p>
<p id="p-0051" num="0054">These macro weight measurements can also be used to determine a movement vector of the subject. Subject motion can be determined and recorded as a trend to determine amount and type of motion during a sleep session. This can determine a general restlessness level as well as other medical conditions such as &#x201c;restless leg syndrome&#x201d; or seizures.</p>
<p id="p-0052" num="0055">Motion detection can also be used to report in real time a subject exiting from the substrate. Predictive bed exit is also possible as the position on the substrate as the subject moves is accurately detected, so movement toward the edge of a substrate is detected in real time. In a hospital or elder care setting, predictive bed exit can be used to prevent falls during bed exit, for example. An alarm might sound so that a staff member can assist the subject exit the substrate safely.</p>
<p id="p-0053" num="0056">Data from the load or other sensors can be used to detect actual body positions of the subject on the substrate, such as whether the subject is on its back, side, or stomach. Data from the load or other sensors can be used to detect the angular orientation of the subject, whether the subject is aligned on the substrate vertically, horizontally, with his or her head at the foot of the substrate or head of the substrate, or at an angle across the substrate. The sensors can also detect changes in the body positions, or lack thereof. In a medical setting, this can be useful to determine if a subject should be turned to avoid bed sores. In a home or medical setting, firmness of the substrate can be adjusted based on the angular orientation and body position of the subject. For example, body position can be determined from the center of mass, position of heart beat and/or respiration, and directional changes due to blood flow.</p>
<p id="p-0054" num="0057">Controlling external devices such as lights, ambient temperature, music players, televisions, alarms, coffee makers, door locks and shades can be tied to presence, motion and time, for example. As one example, the controller can collect signals from each load or other sensor, determine if the subject is asleep or awake and control at least one external device based on whether the subject is asleep or awake. The determination of whether a subject is asleep or awake is made based on changes in respiration, heart rate and frequency and/or force of movement. As another example, the controller can collect signals from each load or other sensor, determine that the subject previously on the substrate has exited the substrate and change a status of the at least one external device in response to the determination. As another example, the controller can collect signals from each load sensor, determine that the subject has laid down on the substrate and change a status of the at least one external device in response to the determination.</p>
<p id="p-0055" num="0058">A light can be automatically dimmed or turned off by instructions from the controller to a controlled lighting device when presence on the substrate is detected. Electronic shades can be automatically closed when presence on the substrate is detected. A light can automatically be turned on when bed exit motion is detected or no presence is detected. A particular light, such as the light on a right side night stand, can be turned on when a subject on the right side of the substrate is detected as exiting the substrate on the right side. Electronic shades can be opened when motion indicating bed exit or no presence is detected. If a subject wants to wake up to natural light, shades can be programmed to open when movement is sensed indicating the subject has woken up. Sleep music can automatically be turned on when presence is detected on the substrate. Predetermined wait times can be programmed into the controller, such that the lights are not turned off or the sleep music is not started for ten minutes after presence is detected, as non-limiting examples.</p>
<p id="p-0056" num="0059">The controller can be programmed to recognize patterns detected by the load or other sensors. The patterned signals may be in a certain frequency range that falls between the macro and the micro signals. For example, a subject may tap the substrate three times with his or her hand, creating a pattern. This pattern may indicate that the substrate would like the lights turned out. A pattern of four taps may indicate that the subject would like the shades closed, as non-limiting examples. Different patterns may result in different actions. The patterns may be associated with a location on the substrate. For example, three taps near the top right corner of the substrate can turn off lights while three taps near the base of the substrate may result in a portion of the substrate near the feet to be cooled. Patterns can be developed for medical facilities, in which a detected pattern may call a nurse.</p>
<p id="p-0057" num="0060">While the figures illustrate the use of the load or other sensors with a bed as a substrate, it is contemplated that the load or other sensors can be used with couches, chairs, such as a desk chair, where a subject spends extended periods of time. Awheel chair can be equipped with the sensors to collect signals and provide valuable information about a patient. The sensors may be used in an automobile seat and may help to detect when a driver is falling asleep or his or her leg might go numb. Furthermore, the bed can be a baby&#x2019;s crib, a hospital bed, or any other kind of bed. The substrate can be an air chamber bed, smart scale, smart clothing, electronic clothing, textiles, and the like.</p>
<p id="p-0058" num="0061">While the figures illustrate the use of the load sensors, other sensors, examples of which are described herein, can be used without departing from the scope of the specification or claims. Other sensors can be vibration sensors, pressure sensors, force sensors, motion sensors and accelerometers as non-limiting examples. In an implementation, the other sensors may be used instead of, in addition to or with the load sensors without departing from the scope of the specification or claims.</p>
<p id="p-0059" num="0062"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a system architecture for a multidimensional multivariate multiple sensor system (MMMSA) <b>400</b>. The MMMSA <b>400</b> includes one or more devices <b>410</b> which are connected to or in communication with (collectively &#x201c;connected to&#x201d;) a computing platform <b>420</b>. In an implementation, a machine learning training platform <b>430</b> may be connected to the computing platform <b>420</b>. In an implementation, users may access the data via a connected device <b>440</b>, which may receive data from the computing platform <b>420</b> or the device <b>410</b>. The connections between the one or more devices <b>410</b>, the computing platform <b>420</b>, the machine learning training platform <b>430</b>, and the connected device <b>440</b> can be wired, wireless, optical, combinations thereof and/or the like. The system architecture of the MMMSA <b>400</b> is illustrative and may include additional, fewer or different devices, entities and the like which may be similarly or differently architected without departing from the scope of the specification and claims herein. Moreover, the illustrated devices may perform other functions without departing from the scope of the specification and claims herein.</p>
<p id="p-0060" num="0063">In an implementation, the device <b>410</b> can include one or more sensors <b>412</b>, a controller <b>414</b>, a database <b>416</b>, and a communications interface <b>418</b>. In an implementation, the device <b>410</b> can include a classifier <b>419</b> for applicable and appropriate machine learning techniques as described herein. The one or more sensors <b>412</b> can detect wave patterns of vibration, pressure, force, weight, presence, and motion due to subject(s) activity and/or configuration with respect to the one or more sensors <b>412</b>. In an implementation, the one or more sensors <b>412</b> can generate more than one data stream. In an implementation, the one or sensors <b>412</b> can be the same type. In an implementation, the one or more sensors <b>412</b> can be time synchronized. In an implementation, the one or more sensors <b>412</b> can measure the partial force of gravity on substrate, furniture or other object. In an implementation, the one or more sensors <b>412</b> can independently capture multiple external sources of data in one stream (i.e. multivariate signal), for example, weight, heart rate, breathing rate, vibration, and motion from one or more subjects or objects. In an implementation, the data captured by each sensor <b>412</b> is correlated with the data captured by at least one, some, all or a combination of the other sensors <b>412</b>. In an implementation, amplitude changes are correlated. In an implementation, rate and magnitude of changes are correlated. In an implementation, phase and direction of changes are correlated. In an implementation, the one or more sensors <b>412</b> placement triangulates the location of center of mass. In an implementation, the one or more sensors <b>412</b> can be placed under or built into the legs of a bed, chair, coach, etc. In an implementation, the one or more sensors <b>412</b> can be placed under or built into the edges of crib. In an implementation, the one or more sensors <b>412</b> can be placed under or built into the floor. In an implementation, the one or more sensors can be placed under or built into a surface area. In an implementation, the one or more sensors <b>412</b> locations are used to create a surface map that covers the entire area surrounded by sensors. In an implementation, the one or more sensors <b>412</b> can measure data from sources that are anywhere within the area surrounded by the sensors <b>412</b>, which can be directly on top of the sensor <b>412</b>, near the sensor <b>412</b>, or distant from the sensor <b>412</b>. The one or sensors <b>416</b> are not intrusive with respect to the subject(s).</p>
<p id="p-0061" num="0064">The controller <b>414</b> can apply the processes and algorithms described herein with respect to <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>15</b></figref> to the sensor data to determine biometric parameters and other person-specific information for single or multiple subjects at rest and in motion and/or to synthesize cardiac and respiratory signals and associated cardiac and respiratory audio streams. The classifier <b>419</b> can apply the processes and algorithms described herein with respect to <figref idref="DRAWINGS">FIGS. <b>7</b>, <b>9</b>, <b>10</b>, <b>11</b>, <b>12</b>, <b>13</b> and <b>15</b></figref> to the sensor data to determine biometric parameters and other person-specific information for single or multiple subjects at rest and in motion and/or to synthesize cardiac and respiratory signals and associated cardiac and respiratory audio streams. The classifier <b>419</b> can apply classifiers to the sensor data to determine the biometric parameters and other person-specific information and/or to synthesize cardiac and respiratory signals and associated cardiac and respiratory audio streams via machine learning. In an implementation, the classifier <b>419</b> may be implemented by the controller <b>414</b>. In an implementation, the sensor data and the biometric parameters and other person-specific information and/or to synthetic cardiac and respiratory signals and associated cardiac and respiratory audio streams can be stored in the database <b>416</b>. In an implementation, the sensor data, the biometric parameters and other person-specific information, the synthetic cardiac and respiratory signals and associated cardiac and respiratory audio streams, and/or combinations thereof can be transmitted or sent via the communication interface <b>418</b> to the computing platform <b>420</b> for processing, storage, and/or combinations thereof. The communication interface <b>418</b> can be any interface and use any communications protocol to communicate or transfer data between origin and destination endpoints. In an implementation, the device <b>410</b> can be any platform or structure which uses the one or more sensors <b>412</b> to collect the data from a subject(s) for use by the controller <b>414</b> and/or computing platform <b>420</b> as described herein. For example, the device <b>410</b> may be a combination of the substrate <b>20</b>, frame <b>102</b>, legs <b>104</b>, and multiple load or other sensors <b>106</b> as described in <figref idref="DRAWINGS">FIGS. <b>1</b>-<b>3</b></figref>. The device <b>410</b> and the elements therein may include other elements which may be desirable or necessary to implement the devices, systems, and methods described herein. However, because such elements and steps are well known in the art, and because they do not facilitate a better understanding of the disclosed embodiments, a discussion of such elements and steps may not be provided herein.</p>
<p id="p-0062" num="0065">In an implementation, the computing platform <b>420</b> can include a processor <b>422</b>, a database <b>424</b>, and a communication interface <b>426</b>. In an implementation, the computing platform <b>420</b> may include a classifier <b>429</b> for applicable and appropriate machine learning techniques as described herein. The processor <b>422</b> can obtain the sensor data from the sensors <b>412</b> or the controller <b>414</b> and can apply the processes and algorithms described herein with respect to <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>15</b></figref> to the sensor data to determine biometric parameters and other person-specific information for single or multiple subjects at rest and in motion and/or to synthesize cardiac and respiratory signals and associated cardiac and respiratory audio streams. In an implementation, the processor <b>422</b> can obtain the biometric parameters and other person-specific information and/or the synthetic cardiac and respiratory signals and associated cardiac and respiratory audio streams from the controller <b>414</b> to store in database <b>424</b> for temporal and other types of analysis. In an implementation, the classifier <b>429</b> can apply the processes and algorithms described herein with respect to <figref idref="DRAWINGS">FIGS. <b>5</b>-<b>15</b></figref> to the sensor data to determine biometric parameters and other person-specific information for single or multiple subjects at rest and in motion and/or to synthesize cardiac and respiratory signals and associated cardiac and respiratory audio streams. The classifier <b>429</b> can apply classifiers to the sensor data to determine the biometric parameters and other person-specific information and/or to synthesize cardiac and respiratory signals and associated cardiac and respiratory audio streams via machine learning. In an implementation, the classifier <b>429</b> may be implemented by the processor <b>422</b>. In an implementation, the sensor data and the biometric parameters and other person-specific information and/or synthetic cardiac and respiratory signals and associated cardiac and respiratory audio streams can be stored in the database <b>424</b>. The communication interface <b>426</b> can be any interface and use any communications protocol to communicate or transfer data between origin and destination endpoints. In an implementation, the computing platform <b>420</b> may be a cloud-based platform. In an implementation, the processor <b>422</b> can be the cloud-based computer <b>212</b> or off-site controller <b>214</b>. The computing platform <b>420</b> and elements therein may include other elements which may be desirable or necessary to implement the devices, systems, and methods described herein. However, because such elements and steps are well known in the art, and because they do not facilitate a better understanding of the disclosed embodiments, a discussion of such elements and steps may not be provided herein.</p>
<p id="p-0063" num="0066">In an implementation, the machine learning training platform <b>430</b> can access and process sensor data to train and generate classifiers. The classifiers can be transmitted or sent to the classifier <b>429</b> or to the classifier <b>419</b>.</p>
<p id="p-0064" num="0067"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a processing pipeline <b>500</b> for obtaining sensor data such as, but not limited to, load sensor data and other sensor data. An analog sensors data stream <b>520</b> is received from the sensors <b>510</b>. A digitizer <b>530</b> digitizes the analog sensors data stream into a digital sensors data stream <b>540</b>. A framer <b>550</b> generates digital sensors data frames <b>560</b> from the digital sensors data stream <b>540</b> which includes all the digital sensors data stream values within a fixed or adaptive time window. An encryption engine <b>570</b> encodes the digital sensors data frames <b>560</b> such that the data is protected from unauthorized access. A compression engine <b>580</b> compresses the encrypted data to reduce the size of the data that is going to be saved in the database <b>590</b>. This reduces cost and provides faster access during read time. The processing pipeline <b>500</b> shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is illustrative and can include any, all, none or a combination of the blocks or modules shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>. The processing order shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> is illustrative and the processing order may vary without departing from the scope of the specification or claims.</p>
<p id="p-0065" num="0068"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a pre-processing pipeline <b>600</b> for processing the sensor data into multiple sensors multiple dimensions array (MSMDA) data. The pre-processing pipeline <b>600</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is illustrative and can include any, all, none or a combination of the blocks or modules shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. The processing order shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref> is illustrative and the processing order may vary without departing from the scope of the specification or claims. The pre-processing pipeline <b>600</b> processes digital sensor data frames <b>610</b>. An external noise cancellation unit <b>620</b> removes or attenuates noise sources that might have the same or different level of impact on each sensor. The external noise cancellation unit <b>620</b> can use a variety of techniques including, but not limited to, subtraction, combination of the input data frames, adaptive filtering, wavelet transform, independent component analysis, principal component analysis, and/or other linear or nonlinear transforms. A common mode noise reduction unit <b>630</b> removes or attenuates noises which are captured equally by all sensors. The common mode noise reduction unit <b>630</b> may use a variety of techniques including, but not limited to, subtraction, combination of the input data frames, adaptive filtering, wavelet transform, independent component analysis, principal component analysis, and/or other linear or nonlinear transforms. A subsampling unit <b>640</b> samples the digital sensor data and can include downsampling, upsampling or resampling. The subsampling unit <b>640</b> can be implemented as a multi-stage sampling or multi-phase sampling. A signal augmentation unit <b>650</b> can improve the energy of the data or content. The signal augmentation unit <b>650</b> can be implemented as scaling, normalization, log transformation, power transformation, linear or nonlinear combination of input data frames and/or other transformations on the input data frames. A signal enhancement unit <b>660</b> can improve the signal to noise ratio of the input data. The signal enhancement unit <b>660</b> can be implemented as a linear or nonlinear combination of input data frames. For example, the signal enhancement unit <b>660</b> may combine the signal deltas to increase the signal strength for higher resolution algorithmic analysis. The pre-processing pipeline <b>600</b> outputs MSMDA data <b>670</b>, which is the primary input to the methods described herein.</p>
<p id="p-0066" num="0069"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a flowchart of a method <b>700</b> for generating synthetic cardio-respiratory signals. The processing order shown in <figref idref="DRAWINGS">FIG. <b>7</b></figref> is illustrative and the processing order may vary without departing from the scope of the specification or claims. The method <b>700</b> includes: obtaining <b>710</b> ballistocardiogram (BCG) data; pre-processing <b>720</b> the BCG data; sub-sampling <b>730</b> the pre-processed cardiac BCG data for cardiac signal synthetization and sub-sampling <b>735</b> the pre-processed respiratory BCG data for respiratory signal synthetization; cardiac processing <b>740</b> the sub-sampled cardiac BCG data and respiratory processing <b>745</b> the sub-sampled respiratory BCG data; generating <b>750</b> synthetic cardiac signals and generating <b>755</b> synthetic respiratory signals; transmitting <b>760</b> the synthetic cardiac signals to a telemetry unit and transmitting <b>760</b> the synthetic respiratory signals to a telemetry unit; and storing <b>770</b> the synthetic cardiac signals in a database and storing <b>775</b> the synthetic respiratory signals in a database.</p>
<p id="p-0067" num="0070">The method <b>700</b> includes obtaining <b>710</b> ballistocardiogram (BCG) data. The BCG data can be obtained from one or more sensors implemented in a substrate as described herein.</p>
<p id="p-0068" num="0071">The method <b>700</b> includes pre-processing <b>720</b> the BCG data. The BCG data is pre-processed using one or more signal processing techniques known or to be known. The pre-processing techniques can include any signal processing techniques with assist in the separation of cardiac associated signals and respiration associated signals from the BCG data. These techniques can include filtering, artifact removal, noise reduction, signal enhancement, augmentation, normalization, standardization, resampling, and combinations thereof.</p>
<p id="p-0069" num="0072">The method <b>700</b> includes sub-sampling <b>730</b> the pre-processed cardiac BCG data for cardiac signal synthetization and sub-sampling <b>735</b> the pre-processed respiratory BCG data for respiratory signal synthetization. Each of the pre-processed cardiac BCG data and the pre-processed respiratory BCG data are sub-sampled to change the sampling rate to sampling rates which are optimal for cardiac signal synthetization or respiratory signal synthetization, respectively. For example, each of a cardiac sampling rate and a respiratory sampling rate depends on the type of processing used to generate the synthetic cardiac signal or synthetic respiratory signal as described herein, the morphology of the pre-processed cardiac BCG data and the pre-processed respiratory BCG data as described herein, the cardiac components and respiratory components as described herein, and the associated component to noise ratios. The sub-sampling techniques can include downsampling, upsampling or resampling. The subsampling can be implemented as a multi-stage sampling or multi-phase sampling.</p>
<p id="p-0070" num="0073">The method <b>700</b> includes cardiac processing <b>740</b> the sub-sampled cardiac BCG data and respiratory processing <b>745</b> the sub-sampled respiratory BCG data. The sub-sampled cardiac BCG data is processed as described herein with respect to <figref idref="DRAWINGS">FIG. <b>9</b></figref> and <figref idref="DRAWINGS">FIGS. <b>11</b>-<b>15</b></figref> as applicable and appropriate. The sub-sampled respiratory BCG data is processed as described herein with respect to <figref idref="DRAWINGS">FIG. <b>10</b></figref> and <figref idref="DRAWINGS">FIGS. <b>11</b>-<b>15</b></figref> as applicable and appropriate.</p>
<p id="p-0071" num="0074">The method <b>700</b> includes generating <b>750</b> synthetic cardiac signals and generating <b>755</b> synthetic respiratory signals. The cardiac processed BCG data is processed as described herein with respect to <figref idref="DRAWINGS">FIG. <b>9</b></figref> and <figref idref="DRAWINGS">FIGS. <b>11</b>-<b>15</b></figref> as applicable and appropriate to generate synthetic cardiac signals which include a cardiac time series and a cardiac sound stream as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, for example. The respiratory processed BCG data is processed as described herein with respect to <figref idref="DRAWINGS">FIG. <b>10</b></figref> and <figref idref="DRAWINGS">FIGS. <b>11</b>-<b>15</b></figref> as applicable and appropriate to generate synthetic respiratory signals which include a respiratory time series and a respiratory sound stream as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>, for example.</p>
<p id="p-0072" num="0075">The method <b>700</b> includes transmitting <b>760</b> the synthetic cardiac signals to a telemetry unit and transmitting <b>760</b> the synthetic respiratory signals to a telemetry unit. Each of the generated synthetic cardiac signals and generated synthetic respiratory signals can be sent to a telemetry unit, which in turn can make the generated synthetic cardiac signals and generated synthetic respiratory signals available to remote users such as, for example, a physician or remote care giver.</p>
<p id="p-0073" num="0076">The method <b>700</b> includes storing <b>770</b> the synthetic cardiac signals in a database and storing <b>775</b> the synthetic respiratory signals in a database. Each of the generated synthetic cardiac signals and generated synthetic respiratory signals can be stored in a local or remote database. In an implementation, one or more databases can be used to store the generated synthetic cardiac signals and generated synthetic respiratory signals.</p>
<p id="p-0074" num="0077"><figref idref="DRAWINGS">FIG. <b>8</b></figref> is an example of signals <b>800</b> generated in the method of generating synthetic cardio-respiratory signals. As described herein, the cardiac processing and the respiratory processing generates a number of components which are used to synthesize synthetic cardiac signals and synthetic respiratory signals (collectively &#x201c;cardio-respiratory signals&#x201d;), respectively. As described herein for the process used for obtaining the components, some of the components include a time span <b>810</b> which is determined between dominant components in pre-synthetic cardio-respiratory signals, a template morphology <b>820</b> which is obtained from one or more databases, a real-time morphology <b>830</b> based on the template morphology <b>820</b> and other parameters described herein, a synthetic time series <b>840</b> based on the time span <b>810</b> and the real-time morphology <b>830</b>, a template sound <b>850</b> which is obtained from one or more databases or from the real-time morphology <b>830</b>, and a synthetic sound stream <b>860</b> based on the time span <b>810</b> and the template sound <b>850</b>.</p>
<p id="p-0075" num="0078"><figref idref="DRAWINGS">FIG. <b>9</b></figref> is a flowchart of a method <b>900</b> for generating synthetic cardio signals. The method <b>900</b> includes: pre-processing and sub-sampling <b>905</b> BCG data; filtering <b>910</b> the pre-processed and sub-sampled cardiac BCG data; transforming <b>915</b> the filtered cardiac BCG data; performing <b>920</b> correlation analysis on the transformed cardiac BCG data; performing <b>925</b> envelope detection on the transformed cardiac BCG data; performing <b>930</b> peak detection on the envelope detected cardiac BCG data; identifying <b>935</b> individual cardiac beats based on the correlated cardiac BCG data and the peak detected cardiac BCG data; enhancing <b>940</b> the individual cardiac beats; storing <b>945</b> the individual cardiac beats in a cardiac beat morphology (rhythm) and parameter set database or cardiac database; determining <b>950</b> heart rate from the individual cardiac beats and storing <b>945</b> same; determining <b>955</b> time span from the individual cardiac beats and storing <b>945</b> same; determining <b>960</b> beat components from the individual cardiac beats and storing <b>945</b> same; and determining <b>965</b> beat parameters of each beat component and storing <b>945</b> same. Cardiac beats are an illustrative cardiac event and other cardiac events can be determined such as heart beat pattern change rate, and heart beat with normal pattern and heart beat with abnormal pattern.</p>
<p id="p-0076" num="0079">The method <b>900</b> includes pre-processing and sub-sampling <b>905</b> BCG data. The BCG data is processed as described herein and as described with respect to the pre-processing <b>720</b> and the sub-sampling <b>730</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p>
<p id="p-0077" num="0080">The method <b>900</b> includes filtering <b>910</b> the pre-processed and sub-sampled cardiac BCG data. The filtering <b>910</b> is designed to eliminate or remove components of the pre-processed and sub-sampled cardiac BCG data which do not pertain to cardiac processing. That is, the filtering <b>910</b> retains those components which are representative of the cardiac information. In illustrative examples, the filtering <b>910</b> can preserve the diastolic and systolic components of the pre-processed and sub-sampled BCG data <b>905</b>, the atrial and ventricular components of the pre-processed and sub-sampled BCG data <b>905</b>, the cardiac beat waveforms or heartbeat oscillations in the pre-processed and sub-sampled BCG data <b>905</b>, and the spectral components within the cardiac frequency band in the pre-processed and sub-sampled BCG data <b>905</b>. In illustrative examples, the filtering <b>910</b> can remove the breathing related components of the pre-processed and sub-sampled BCG data <b>905</b> and other components outside the cardiac frequency band in the pre-processed and sub-sampled BCG data <b>905</b>. The filtering <b>910</b> can use infinite impulse response (IIR) filter processing, finite impulse response (FIR) filter processing, or combinations thereof. The filtering <b>910</b> can use low pass filters, high pass filters, bandpass filters, bandstop filters, notch filters, or combinations thereof.</p>
<p id="p-0078" num="0081">The method <b>900</b> includes transforming <b>915</b> the filtered cardiac BCG data. The transforming <b>915</b> enhances the cardiac components by modeling the filtered cardiac BCG data as a collection of waveforms of a particular form that resemble the cardiac morphology, where each waveform type is associated with one or more transforms. For example, but not limited to, the collection of waveforms can be sinusoids, mother wavelets, periodic basis functions, and the like, and an associated transform processes can be Fourier transforms, wavelet transforms, and periodicity transforms. The transforming <b>915</b> can also use cosine transforms or mathematical transform operations such as root-mean-square, absolute, moving average, moving median, and the like. The transforming <b>915</b> is used to enhance those components which are representative of the cardiac information.</p>
<p id="p-0079" num="0082">The method <b>900</b> includes performing <b>920</b> correlation analysis on the transformed cardiac BCG data. The performing <b>920</b> can use correlation techniques to measure the strength of relationships between different segments of the transformed cardiac BCG data. For example, but not limited to, the correlation techniques can include linear and nonlinear methods. Correlation analysis is used in later processing to determine identify each beat or beat locations.</p>
<p id="p-0080" num="0083">The method <b>900</b> includes performing <b>925</b> envelope detection on the transformed cardiac BCG data. Envelop detection is performed on a relatively high-frequency amplitude modulated signal (input signal) of the transformed cardiac BCG data and provides an output which is equivalent to an outline of the input signal as described by connecting all the local peaks in the input signal. For example, but not limited to, envelope detection can use a low pass filter, a Hilbert transform, or other envelope detection methods. Envelope detection is used to help determine start and stop points of a beat.</p>
<p id="p-0081" num="0084">The method <b>900</b> includes performing <b>930</b> peak detection on the envelope detected cardiac BCG data. Peak detection is performed to find local maximum and minimum points of the envelope detected cardiac BCG data. For example, peak detection can return all peaks, all valleys, dominant peaks, dominant valleys, or combinations thereof. Peak detection is used to help determine a center of the peak, which in turn is used later to determine the cardiac morphology including, but not limited to, the number of beats, time span, frequency, and width.</p>
<p id="p-0082" num="0085">The method <b>900</b> includes identifying <b>935</b> individual cardiac beats based on the correlated cardiac BCG data and the peak detected cardiac BCG data. The information available from the correlation analysis and peak detection is collectively used to identify individual cardiac beats.</p>
<p id="p-0083" num="0086">The method <b>900</b> includes enhancing <b>940</b> the individual cardiac beats. The identified individual beats undergo signal enhancement by applying a window, a factor, a transform, or like techniques to enhance specific characteristics of the individual cardiac beats which are representative of the cardiac information. The cardiac beats are indicative of a cardiac beat morphology.</p>
<p id="p-0084" num="0087">The method <b>900</b> includes storing <b>945</b> the individual cardiac beats in a cardiac beat morphology (rhythm) and parameter set database. The results from signal enhancement are stored in the cardiac beat morphology (rhythm) and parameter set database. The cardiac beat morphology (rhythm) and parameter set database can be one or more databases. For example, the cardiac beat morphology (rhythm) and parameter set database can include a normal or baseline database and one or more abnormal or disease databases. The normal or baseline database can include a cardiac beat morphology (rhythm) and parameter set which is established or identified as a baseline cardiac beat morphology (rhythm) and parameter set against which later cardiac beat morphology (rhythm) and parameter sets can be compared to determine any variances.</p>
<p id="p-0085" num="0088">The method <b>900</b> includes determining <b>950</b> heart rate from the enhanced individual cardiac beats and storing <b>945</b> the same. Heart rate information is determined from the enhanced individual cardiac beats by using time domain, frequency domain, time frequency domain analysis, or combinations thereof. The heart rate information is stored in the cardiac beat morphology (rhythm) and parameter set database.</p>
<p id="p-0086" num="0089">The method <b>900</b> includes determining <b>955</b> time span from the enhanced individual cardiac beats and storing <b>945</b> same. Dominant components, onset points, and offset points are determined from the enhanced individual cardiac beats. The dominant components can be, for example, the center of the cardiac beat or the peak of the cardiac beat. The onset and offset points are collectively used to define or determine a time span as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. The dominant components, onset points, offset points, and time span are stored in the cardiac beat morphology (rhythm) and parameter set database.</p>
<p id="p-0087" num="0090">The method <b>900</b> includes determining <b>960</b> beat components from the enhanced individual cardiac beats and storing <b>945</b> same. Beat components are determined for each of the enhanced individual cardiac beats. The beat components depend on the cardiac model. For example, the beat components can be P, Q, R, S and T waveforms, diastolic/systolic waveforms, or atrial/ventricular depolarization and repolarization. These are illustrative and other beat components can be used. The beat components are stored in the cardiac beat morphology (rhythm) and parameter set database.</p>
<p id="p-0088" num="0091">The method <b>900</b> includes determining <b>965</b> beat parameters of each beat component and storing <b>945</b> same. Parameters are determined for each of the beat components. These parameters can include, but are not limited to, amplitude, location, onset, offset, peak, width, duration, slope, latency or other parameters. The parameters for each of the beat components are stored in the cardiac beat morphology (rhythm) and parameter set database. The individual beats morphology (rhythm), heart rate, time span, beat components, and parameters collectively constitute the cardiac parameter set.</p>
<p id="p-0089" num="0092"><figref idref="DRAWINGS">FIG. <b>10</b></figref> is a flowchart of a method <b>1000</b> for generating synthetic respiratory signals. The method <b>1000</b> includes: pre-processing and sub-sampling <b>1005</b> BCG data; filtering <b>1010</b> the pre-processed and sub-sampled respiratory BCG data; transforming <b>1015</b> the filtered respiratory BCG data; performing <b>1020</b> correlation analysis on the transformed respiratory BCG data; performing <b>1025</b> peak detection on the on the transformed respiratory BCG data; identifying <b>1030</b> individual breaths based on the correlated respiratory BCG data and the peak detected respiratory BCG data; enhancing <b>1035</b> the individual breaths; storing <b>1040</b> the individual breaths in a breathing morphology and parameter set database or respiratory database; determining <b>1045</b> respiration rate from the individual breaths and storing <b>1040</b> the same; determining <b>1050</b> breath time span from the individual breaths and storing <b>1040</b> the same; determining <b>1055</b> breath components from the individual breaths and storing <b>1040</b> the same; and determining <b>1060</b> parameters of each breath component and storing <b>1040</b> the same. Breaths are an illustrative respiratory event and other respiratory events can be determined such as snores and associated data such as snoring rate, snore during inhalation, and snore during exhalation, or breath pattern changes and associated data such as a breath pattern change rate, and breathing with normal pattern and breathing with abnormal pattern.</p>
<p id="p-0090" num="0093">The method <b>1000</b> includes pre-processing and sub-sampling <b>1005</b> BCG data. The BCG data is processed as described herein and as described with respect to the pre-processing <b>720</b> and the sub-sampling <b>735</b> of <figref idref="DRAWINGS">FIG. <b>7</b></figref>.</p>
<p id="p-0091" num="0094">The method <b>1000</b> includes filtering <b>1010</b> the pre-processed and sub-sampled respiratory BCG data. The filtering <b>1010</b> is designed to eliminate or remove components of the pre-processed and sub-sampled respiratory BCG data which do not pertain to respiratory processing. That is, the filtering <b>1010</b> retains those components which are representative of the respiratory information. In illustrative examples, the filtering <b>1010</b> can preserve the inspiration (inhalation) and expiration (exhalation) components of the pre-processed and sub-sampled BCG data <b>1005</b>, the snore or the breathing sound vibrations present in the pre-processed and sub-sampled BCG data <b>1005</b>, or the spectral components within the respiratory frequency band in the pre-processed and sub-sampled BCG data <b>1005</b>. In illustrative examples, the filtering <b>1010</b> can remove the cardiac related components of the pre-processed and sub-sampled BCG data <b>1005</b> and/or other components outside the respiration frequency band in the pre-processed and sub-sampled BCG data <b>1005</b>. The filtering <b>1010</b> can use infinite impulse response (IIR) filter processing, finite impulse response (FIR) filter processing, or combinations thereof. The filtering <b>1010</b> can use low pass filters, high pass filters, bandpass filters, bandstop filters, notch filters, or combinations thereof.</p>
<p id="p-0092" num="0095">The method <b>1000</b> includes transforming <b>1015</b> the filtered respiratory BCG data. The transforming <b>1015</b> enhances the respiratory components by modeling the filtered respiratory BCG data as a collection of waveforms of a particular form that resemble the respiratory morphology, where each waveform type is associated with one or more transforms. For example, but not limited to, the collection of waveforms can be sinusoids, mother wavelets, periodic basis functions, and the like, and associated transform processes can be Fourier transforms, wavelet transforms, and periodicity transforms. The transforming <b>1015</b> can also use cosine transforms or mathematical transform operations such as root-mean-square, absolute, moving average, moving median, and the like. The transforming <b>1015</b> is used to enhance those components which are representative of the respiratory information.</p>
<p id="p-0093" num="0096">The method <b>1000</b> includes performing <b>1020</b> correlation analysis on the transformed respiratory BCG data. The performing <b>1020</b> can use correlation techniques to measure the strength of relationships between different segments of the transformed respiratory BCG data. For example, but not limited to, the correlation techniques can include linear and nonlinear methods. Correlation analysis is used in later processing to determine identify each breath.</p>
<p id="p-0094" num="0097">The method <b>1000</b> includes performing <b>1025</b> peak detection on the on the transformed respiratory BCG data. Peak detection is performed to find local maximum and minimum points of the transformed respiratory BCG data. For example, peak detection can return all peaks, all valleys, dominant peaks, dominant valleys, or combinations thereof. Peak detection is used to help determine a center of the peak, which in turn is used later to determine the transformed respiratory BCG data morphology.</p>
<p id="p-0095" num="0098">The method <b>1000</b> includes identifying <b>1030</b> individual breaths based on the correlated respiratory BCG data and the peak detected respiratory BCG data. The information available from the correlation analysis and peak detection is collectively used to identify individual breaths. The breaths are indicative of a breathing morphology.</p>
<p id="p-0096" num="0099">The method <b>1000</b> includes enhancing <b>1035</b> the individual breaths. The identified individual breaths undergo signal enhancement by applying a window, a factor, a transform, or like techniques to enhance specific characteristics of the individual breaths which are representative of the respiratory information.</p>
<p id="p-0097" num="0100">The method <b>1000</b> includes storing <b>1040</b> the individual breaths in a breathing morphology and parameter set database. The results from signal enhancement are stored in the breathing morphology and parameter set database. The breathing morphology and parameter set database can be one or more databases. For example, the breathing morphology and parameter set database can include a normal or baseline database and one or more abnormal or disease databases. The normal or baseline database can include a breathing morphology and parameter set which is established or identified as a baseline breathing morphology and parameter set against which later breathing morphology and parameter sets can be compared to determine any variances.</p>
<p id="p-0098" num="0101">The method <b>1000</b> includes determining <b>1045</b> respiration rate from the individual breaths and storing <b>1040</b> the same. Respiration rate information is determined from the enhanced individual breaths by using time domain, frequency domain, time frequency domain analysis, or combinations thereof. The respiration rate information is stored in the breathing morphology and parameter set database.</p>
<p id="p-0099" num="0102">The method <b>1000</b> includes determining <b>1050</b> breath time span from the individual breaths and storing <b>1040</b> the same. Dominant components, onset points, and offset points are determined from the enhanced individual breaths. The dominant components can be, for example, the center of the breath or the peak of the breath. The onset and offset points are collectively used to define or determine a time span as shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>. The dominant components, onset points, offset points, and time span are stored in the breathing morphology and parameter set database.</p>
<p id="p-0100" num="0103">The method <b>1000</b> includes determining <b>1055</b> breath components from the individual breaths and storing <b>1040</b> the same. Breath components are determined for each of the enhanced individual breaths. The breath components can be, for example, inhale, exhale, inspiration, expiration, and the like. These are illustrative and other breath components can be used. The breath components are stored in the breathing morphology and parameter set database.</p>
<p id="p-0101" num="0104">The method <b>1000</b> includes determining <b>1060</b> parameters of each breath component and storing <b>1040</b> the same. Parameters are determined for each of the breath components. These parameters can include, but are not limited to, amplitude, location, onset, offset, peak, width, duration, slope, latency or other parameters. The parameters for each of the breath components are stored in the breathing morphology and parameter set database. The individual breaths morphology (rhythm), respiration rate, time span, breath components, and parameters collectively constitute the respiratory parameter set.</p>
<p id="p-0102" num="0105"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a flowchart of a method <b>1100</b> for generating synthetic cardio-respiratory time series and sound streams using a defined template sound. The method <b>1100</b> includes: obtaining <b>1110</b> time span information from a cardiac (or respiratory) database; obtaining <b>1120</b> template parameters from a cardiac (or respiratory) database; obtaining <b>1130</b> template morphology from a cardiac (or respiratory) database; obtaining <b>1140</b> template sound from a cardiac (or respiratory) sound database; creating <b>1150</b> a real-time morphology from the template parameters and the template morphology; generating <b>1160</b> a synthetic time series from the time span information and the real-time morphology; and generating <b>1170</b> a synthetic sound stream for the synthetic time series based on the time span and the template sound.</p>
<p id="p-0103" num="0106">The method <b>1100</b> includes obtaining <b>1110</b> time span information from a cardiac (or respiratory) database. The cardiac and respiratory time span information are obtained from a cardiac database as described in <figref idref="DRAWINGS">FIG. <b>9</b></figref> and from a respiratory database as described in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, respectively.</p>
<p id="p-0104" num="0107">The method <b>1100</b> includes obtaining <b>1120</b> template parameters from a cardiac (or respiratory) database. The cardiac and respiratory template parameters are obtained from a cardiac database as described in <figref idref="DRAWINGS">FIG. <b>9</b></figref> and from a respiratory database as described in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, respectively.</p>
<p id="p-0105" num="0108">The method <b>1100</b> includes obtaining <b>1130</b> template morphology from a cardiac (or respiratory) database. The beat or breath template morphology is obtained from a cardiac database as described in <figref idref="DRAWINGS">FIG. <b>9</b></figref> or from a respiratory database as described in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, respectively. The respective databases can contain one or more template morphologies for different conditions, diseases, ailments, and the like. In an implementation, the template morphology can be obtained from a standalone or separate database or dictionary of pre-recorded cardiac beats or respiratory breaths. In an implementation, the template morphology can be obtained by using functions to transform a BCG morphology into a cardiac, such as an electrocardiogram (ECG) morphology or a breath morphology. For example, an inverse mapping can be used to generate characteristic points or waves for an ECG (for example, P, Q, R, S and T) from the characteristic points or waves of the BCG (H, I, J, K, L, M, N). For example, mathematical or statistical models (such as a Gaussian mixture model) can be used to create simulated cardiac beats or respiratory breaths. The model can use default parameters or the template parameters to simulate the cardiac beats or respiratory breaths.</p>
<p id="p-0106" num="0109">The method <b>1100</b> includes obtaining <b>1140</b> template sound from a database. A database has one or more template sounds which can represent normal condition, multiple cardiac conditions, multiple respiratory conditions, multiple cardio-respiratory conditions, and the like.</p>
<p id="p-0107" num="0110">The method <b>1100</b> includes creating <b>1150</b> a real-time morphology from the template parameters and the template morphology. Mathematical transformations, windowing functions, or like transforms or functions can be used to adjust or convert the template morphology into a real-time morphology using the template parameters. For example, the template morphology can be stretched, compressed, realigned, and the like in relation to the template parameters. A real-time morphology is shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p>
<p id="p-0108" num="0111">The method <b>1100</b> includes generating <b>1160</b> a synthetic time series from the time span information and the real-time morphology. The real-time morphology is effectively reproduced based on the time span. In an implementation, a convolution function can be used to convolve the real-time morphology with an impulse train located at the center of time spans. The synthetic time series is shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p>
<p id="p-0109" num="0112">The method <b>1100</b> includes generating <b>1170</b> a synthetic sound stream for the synthetic time series based on the time span and the template sound. The template sound is effectively reproduced based on the time span. In an implementation, a convolution function can be used to convolve the template sound with an impulse train located at the center of time spans. In an implementation, a modulation function such as amplitude modulation, frequency modulation, phase modulation or a combination thereof can be applied to the template sound which is in sync with the time span. The synthetic sound stream and the synthetic time series are run in synchronization to simulate an audible beating heart or pumping respiratory function, for example.</p>
<p id="p-0110" num="0113"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a flowchart of a method <b>1200</b> for generating synthetic cardio-respiratory time series and sound streams using an adaptive template sound. The method <b>1200</b> includes: obtaining <b>1210</b> time span information from a cardiac (or respiratory) database; obtaining <b>1220</b> template parameters from a cardiac (or respiratory) database; obtaining <b>1230</b> template morphology from a cardiac (or respiratory) database; creating <b>1240</b> a real-time morphology from the template parameters and the template morphology; generating <b>1250</b> a synthetic time series from the time span information and the real-time morphology; modulating <b>1260</b> the real-time morphology; creating <b>1270</b> a real-time template sound from the modulated real-time morphology; and generating <b>1280</b> a synthetic sound stream for the synthetic time series based on the time span and the real-time template sound.</p>
<p id="p-0111" num="0114">The method <b>1200</b> includes obtaining <b>1210</b> time span information from a cardiac (or respiratory) database. The cardiac and respiratory time span information are obtained from a cardiac database as described in <figref idref="DRAWINGS">FIG. <b>9</b></figref> and from a respiratory database as described in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, respectively.</p>
<p id="p-0112" num="0115">The method <b>1200</b> includes obtaining <b>1220</b> template parameters from a cardiac (or respiratory) database. The cardiac and respiratory template parameters are obtained from a cardiac database as described in <figref idref="DRAWINGS">FIG. <b>9</b></figref> and from a respiratory database as described in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, respectively.</p>
<p id="p-0113" num="0116">The method <b>1200</b> includes obtaining <b>1230</b> template morphology from a cardiac (or respiratory) database. The beat or breath template morphology is obtained from a cardiac database as described in <figref idref="DRAWINGS">FIG. <b>9</b></figref> or from a respiratory database as described in <figref idref="DRAWINGS">FIG. <b>10</b></figref>, respectively. The respective databases can contain one or more template morphologies for different conditions, diseases, ailments, and the like. In an implementation, the template morphology can be obtained from a standalone or separate database or dictionary of pre-recorded cardiac beats or respiratory breaths. In an implementation, the template morphology can be obtained by using functions to transform a BCG morphology into a cardiac, such as an electrocardiogram (ECG) morphology or a breath morphology. For example, an inverse mapping can be used to generate characteristic points or waves for an ECG (for example, P, Q, R, S and T) from the characteristic points or waves of the BCG (H, I, J, K, L, M, N). For example, mathematical or statistical models (such as a Gaussian mixture model) can be used to create simulated cardiac beats or respiratory breaths. The model can use default parameters or the template parameters to simulate the cardiac beats or respiratory breaths.</p>
<p id="p-0114" num="0117">The method <b>1200</b> includes creating <b>1240</b> a real-time morphology from the template parameters and the template morphology. Mathematical transformations, windowing functions, or like transforms or functions can be used to adjust or convert the template morphology into a real-time morphology using the template parameters. For example, the template morphology can be stretched, compressed, realigned, and the like in relation to the template parameters. A real-time morphology is shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p>
<p id="p-0115" num="0118">The method <b>1200</b> includes generating <b>1250</b> a synthetic time series from the time span information and the real-time morphology. The real-time morphology is effectively reproduced based on the time span. In an implementation, a convolution function can be used to convolve the real-time morphology with an impulse train located at the center of time spans. The synthetic time series is shown in <figref idref="DRAWINGS">FIG. <b>8</b></figref>.</p>
<p id="p-0116" num="0119">The method <b>1200</b> includes modulating <b>1260</b> the real-time morphology. In an implementation, the real-time morphology is modulated using for example, but not limited to, amplitude modulation, frequency modulation, phase modulation, or a combination thereof to achieve human audio frequency range. In an implementation, one or more modulation techniques can be used to vary one or more properties of the real-time morphology waveform to achieve human audio frequency range.</p>
<p id="p-0117" num="0120">The method <b>1200</b> includes creating <b>1270</b> a real-time template sound from the modulated real-time morphology.</p>
<p id="p-0118" num="0121">The method <b>1200</b> includes generating <b>1280</b> a synthetic sound stream for the synthetic time series based on the time span and the real-time template sound. The real-time template sound is effectively reproduced based on the time span. In an implementation, a convolution function can be used to convolve the real-time template sound with an impulse train located at the center of time spans. In an implementation, a modulation function such as amplitude modulation, frequency modulation, phase modulation or a combination thereof can be applied to the real-time template sound which is in sync with the time span. The synthetic sound stream and the synthetic time series are run in synchronization to simulate an audible beating heart or pumping respiratory function, for example.</p>
<p id="p-0119" num="0122"><figref idref="DRAWINGS">FIG. <b>13</b></figref> is a flowchart of a method <b>1300</b> for generating synthetic cardio-respiratory signals from a multiple sensor multiple dimensions system. The method <b>1300</b> includes obtaining <b>1310</b> multiple sensor multiple dimensions array (MSMDA) data; obtaining <b>1320</b> surface location map of one or more sensors; obtaining <b>1330</b> spatial cardiac or respiratory map(s); creating <b>1340</b> cardiac specific or respiratory specific combinations; and generating <b>1350</b> synthetic time series and sound streams.</p>
<p id="p-0120" num="0123">The method <b>1300</b> includes obtaining <b>1310</b> multiple sensor multiple dimensions array (MSMDA) data. In the event that multiple BCG sensors are available, MSMDA data is obtained using the pre-processing pipeline <b>600</b> for processing the sensor data into MSMDA data as described with respect to <figref idref="DRAWINGS">FIG. <b>6</b></figref>, for example.</p>
<p id="p-0121" num="0124">The method <b>1300</b> includes obtaining <b>1320</b> surface location map of one or more sensors. A two-dimensional surface location map is generated to represent the surface of a substrate, furniture or other object. <figref idref="DRAWINGS">FIGS. <b>13</b>A-D</figref> show example surface location maps for a multidimensional multivariate multiple sensors system with 4 sensors. <figref idref="DRAWINGS">FIG. <b>13</b>A</figref> shows mapping the surface into a top section and bottom section. <figref idref="DRAWINGS">FIG. <b>13</b>B</figref> shows mapping the surface into left, center, and right sections. <figref idref="DRAWINGS">FIG. <b>13</b>C</figref> shows mapping the surface into 9 coordinates: top left, middle top, top right, middle right, bottom right, middle bottom, bottom left, middle left, and center. <figref idref="DRAWINGS">FIG. <b>13</b>D</figref> shows mapping the surface into a two dimensional X-Y coordinate, where X and Y are in the range of 0-100 such that (X,Y) = (0,0) represents the bottom left corner of the surface, (X,Y) = (100,100) represent the top right corner of the surface, and (X,Y) = (50,50) shows the center of the surface. The coordinate system is illustrative and other formats can be used. The surface location maps are illustrative and other formats can be used.</p>
<p id="p-0122" num="0125">The method <b>1300</b> includes obtaining <b>1330</b> spatial cardiac or respiratory map(s). The spatial cardiac or respiratory map(s) can be standard electrocardiographic or respiratory maps or can be customized maps that model the body surface potential to different views of the heart and lungs. Examples include unipolar ECG configuration, bipolar ECG configuration, pericardial ECG configuration, chest and abdominal respiratory configuration, inferior or superior configuration, anterior or posterior configuration, and like configurations. <figref idref="DRAWINGS">FIG. <b>14</b></figref> is an example of a surface location map <b>1400</b> and spatial cardio-respiratory maps <b>1410</b> and <b>1420</b>. The surface location map <b>1400</b> illustrates the location of multiple sensors <b>1432</b>, <b>1434</b>, <b>1436</b> and <b>1438</b> in a two dimensional X-Y coordinate, where X and Y are in the range of 0-100 such that (X,Y) = (0,0) represents the bottom left corner of the surface, (X,Y) = (100,100) represent the top right corner of the surface, and (X,Y) = (50,50) shows the center of the surface, for example. The spatial cardio-respiratory map <b>1410</b> is a bipolar ECG configuration where Lead I is the left arm (LA) and right arm (RA) lead, Lead II is the left leg (LL) and RA lead, and Lead III is the LL and LA lead. The spatial cardio-respiratory map <b>1410</b> can also be used to determine a unipolar ECG configuration, where aVR = RA-0.5 * (LA+LL), aVL = LA-0.5 * (RA+LL), and aVF = LL-0.5 * (RA+LA). The spatial cardio-respiratory map <b>1420</b> is a pericardial ECG configuration using V1, V2, V3, V4, V5, and V6.</p>
<p id="p-0123" num="0126">The method <b>1300</b> includes creating <b>1340</b> cardiac specific or respiratory specific combinations. The cardiac specific or respiratory specific combinations are generated from the MSMDA data using the surface location map and the spatial cardio-respiratory maps. The resulting combinations provide the closest match to the reference spatial cardio-respiratory map given the location of the sensors in the surface location map. The output will be a set of optimized combinations of the input MSMDA data. A process similar to that described for <figref idref="DRAWINGS">FIG. <b>9</b></figref> in U.S. Pat. Application Serial No. 16/595,848, filed Oct. 8, 2019, can be used, the entire disclosure of which is hereby incorporated by reference. Other techniques can be used for joint processing as is known to those of skill in the art. Referring back to <figref idref="DRAWINGS">FIG. <b>14</b></figref>, each of the configurations can be mapped into a combination of the MSMDA data as represented by the surface location map. For example, in order to reconstruct Lead I, sensor combinations which represent RA and LA are needed. Using the shown map, RA is a function of the two left sensors <b>1432</b> and <b>1438</b> at (X,Y) = (0,0) and (X,Y) = (0,100). Similarly, LA is a function of the two right sensors <b>1434</b> and <b>1436</b> at (X,Y) = (100,0) and (X,Y) = (100,100). Other combinations are possible.</p>
<p id="p-0124" num="0127">The method <b>1300</b> includes generating <b>1350</b> synthetic time series and sound streams. The cardiac specific or respiratory specific combinations of the MSMDA data are used to generate the synthetic cardio-respiratory time series and sound streams. In an implementation, each cardiac specific or respiratory specific combination can be processed independently using the method <b>700</b>. In an implementation, the cardiac specific or respiratory specific combinations can be processed jointly to provide enhanced synthetic time series and sound streams since the MSMDA data may be correlated and may each partially capture the cardio-respiratory information. In this case, the method <b>700</b> is updated to accommodate joint pre-processing of MSMDA data. For example, this can be done using the relationship analysis described with respect to <figref idref="DRAWINGS">FIG. <b>9</b></figref> in U.S. Pat. Application Serial No. 16/595,848, filed Oct. 8, 2019, can be used, the entire disclosure of which is hereby incorporated by reference. Other techniques can be used for joint processing as is known to those of skill in the art.</p>
<p id="p-0125" num="0128"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a swim lane diagram <b>1500</b> for building individualized and population morphology templates and generating classifiers for new devices or refreshing classifiers for existing devices. The swim lane diagram <b>1500</b> includes devices <b>1505</b> which include a first set of devices <b>1525</b> and a second set of devices <b>1565</b>, a database server <b>1510</b>, classifier factory <b>1515</b>, and a configuration server <b>1520</b>. In an implementation, the database server <b>1510</b>, the classifier factory <b>1515</b>, and the configuration server <b>1520</b> can be implemented at computing platform <b>420</b>, for example.</p>
<p id="p-0126" num="0129">The first set of devices <b>1525</b> generate synthetic time series and sound stream data which are received (<b>1530</b>) and stored (<b>1535</b>) by the database server <b>1510</b>. The classifier factory <b>1515</b> retrieves the synthetic time series and sound stream data (<b>1540</b>) and generates or retrains classifiers using the synthetic time series and sound stream data (<b>1545</b>). The generated or retrained classifiers are stored by the classifier factory <b>1515</b> (<b>1550</b>). The generated or retrained classifiers are used by the classifier factory <b>1515</b> to classify morphology and sound templates (<b>1570</b>) into normal, abnormal, and like categories to automatically detect different arrhythmias or diseases, for example. The morphology and sound templates are stored (<b>1575</b>) in the database server <b>1510</b>. In an implementation, the database server <b>1510</b> can include one or more databases for each morphology or sound type. For example, a database for normal morphologies and a separate database for each condition or disease. In an implementation, the storing of the synthetic time series and sound stream data (<b>1535</b>) and the morphology and sound templates (<b>1575</b>) can be the same database or different databases. The configuration server <b>1520</b> obtains the generated or retrained classifiers and generates an update (<b>1555</b>) for devices <b>1525</b>. The configuration server <b>1520</b> sends the update (<b>1560</b>) to both the first set of devices <b>1525</b> and to the second set of devices <b>1565</b>, where the second set of devices <b>1565</b> may be new devices. This system can be used to retrain classifiers on old devices (such as the first set of devices <b>1525</b>) as more data input is available from more devices <b>1505</b>. The system can also be used to provide software updates with improved accuracy and can also learn personalized patterns and increase personalization of classifiers or data.</p>
<p id="p-0127" num="0130">Implementations of controller <b>200</b>, controller <b>214</b>, processor <b>422</b>, and/or controller <b>414</b> (and the algorithms, methods, instructions, etc., stored thereon and/or executed thereby) can be realized in hardware, software, or any combination thereof. The hardware can include, for example, computers, intellectual property (IP) cores, application-specific integrated circuits (ASICs), programmable logic arrays, optical processors, programmable logic controllers, microcode, microcontrollers, servers, microprocessors, digital signal processors or any other suitable circuit. In the claims, the term &#x201c;controller&#x201d; should be understood as encompassing any of the foregoing hardware, either singly or in combination.</p>
<p id="p-0128" num="0131">Further, in one aspect, for example, controller <b>200</b>, controller <b>214</b>, processor <b>422</b>, and/or controller <b>414</b> can be implemented using a general purpose computer or general purpose processor with a computer program that, when executed, carries out any of the respective methods, algorithms and/or instructions described herein. In addition or alternatively, for example, a special purpose computer/processor can be utilized which can contain other hardware for carrying out any of the methods, algorithms, or instructions described herein.</p>
<p id="p-0129" num="0132">Controller <b>200</b>, controller <b>214</b>, processor <b>422</b>, and/or controller <b>414</b> can be one or multiple special purpose processors, digital signal processors, microprocessors, controllers, microcontrollers, application processors, central processing units (CPU)s, graphics processing units (GPU)s, digital signal processors (DSP)s, application specific integrated circuits (ASIC)s, field programmable gate arrays, any other type or combination of integrated circuits, state machines, or any combination thereof in a distributed, centralized, cloud-based architecture, and/or combinations thereof.</p>
<p id="p-0130" num="0133">The word &#x201c;example,&#x201d; &#x201c;aspect,&#x201d; or &#x201c;embodiment&#x201d; is used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as using one or more of these words is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, use of the word &#x201c;example,&#x201d; &#x201c;aspect,&#x201d; or &#x201c;embodiment&#x201d; is intended to present concepts in a concrete fashion. As used in this application, the term &#x201c;or&#x201d; is intended to mean an inclusive &#x201c;or&#x201d; rather than an exclusive &#x201c;or&#x201d;. That is, unless specified otherwise, or clear from context, &#x201c;X includes A or B&#x201d; is intended to mean any of the natural inclusive permutations. That is, if X includes A; X includes B; or X includes both A and B, then &#x201c;X includes A or B&#x201d; is satisfied under any of the foregoing instances. In addition, the articles &#x201c;a&#x201d; and &#x201c;an&#x201d; as used in this application and the appended claims should generally be construed to mean &#x201c;one or more&#x201d; unless specified otherwise or clear from context to be directed to a singular form.</p>
<p id="p-0131" num="0134">While the disclosure has been described in connection with certain embodiments, it is to be understood that the disclosure is not to be limited to the disclosed embodiments but, on the contrary, is intended to cover various modifications and equivalent arrangements included within the scope of the appended claims, which scope is to be accorded the broadest interpretation so as to encompass all such modifications and equivalent structures as is permitted under the law.</p>
<?detailed-description description="Detailed Description" end="tail"?>
</description>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text><b>1</b>. A method for determining item specific parameters, the method comprising:
<claim-text>obtaining ballistocardiogram (BCG) data from one or more sensors, wherein the one or more sensors capture BCG data for one or more subjects in relation to a substrate;</claim-text>
<claim-text>for each subject:
<claim-text>pre-processing the captured BCG data to obtain cardio-respiratory BCG data;</claim-text>
<claim-text>sub-sampling the cardio-respiratory BCG data to generate the cardio-respiratory BCG data at a cardio-respiratory sampling rate conducive to cardio-respiratory signal generation;</claim-text>
<claim-text>cardio-respiratory processing the sub-sampled cardio-respiratory BCG data to generate a cardio-respiratory parameter set;</claim-text>
<claim-text>generating a synthetic cardio-respiratory signal from at least the cardio-respiratory parameter set and a cardio-respiratory event morphology template; and</claim-text>
<claim-text>determining a condition of the subject based on the synthetic cardio-respiratory signal.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text><b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the cardio-respiratory processing further comprising:
<claim-text>identifying cardio-respiratory events from the cardio-respiratory BCG data, the cardio-respiratory events indicating a cardio-respiratory morphology;</claim-text>
<claim-text>determining a cardio-respiratory event rate from the identified cardio-respiratory events;</claim-text>
<claim-text>determining a time span from the identified cardio-respiratory events;</claim-text>
<claim-text>determining cardio-respiratory event components from the identified cardio-respiratory events; and</claim-text>
<claim-text>determining parameters for each cardio-respiratory event component,</claim-text>
<claim-text>wherein the cardio-respiratory parameter set includes at least the cardio-respiratory morphology, the cardio-respiratory events, the cardio-respiratory event rate, the time span, and the cardio-respiratory event components.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text><b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>storing the cardio-respiratory morphology and the cardio-respiratory parameter set in one or more databases;</claim-text>
<claim-text>establishing a baseline cardio-respiratory morphology and the cardio-respiratory parameter set; and</claim-text>
<claim-text>identifying cardio-respiratory morphology and the cardio-respiratory parameter sets which vary from the baseline cardio-respiratory morphology and the cardio-respiratory parameter set.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text><b>4</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein when the cardio-respiratory BCG data is cardiac BCG data, the cardio-respiratory events are heart beats, the cardio-respiratory event rate is a heart rate, and the cardio-respiratory event components are heart beat components.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text><b>5</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein when the cardio-respiratory BCG data is cardiac BCG data, the cardio-respiratory events are heart beat pattern changes, the cardio-respiratory event rate is a heart beat pattern change rate, and the cardio-respiratory event components are heart beat with normal pattern and heart beat with abnormal pattern.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text><b>6</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the cardio-respiratory processing further comprising:
<claim-text>filtering sub-sampled cardiac BCG data to strengthen cardiac processing of the cardiac BCG data;</claim-text>
<claim-text>transforming the filtered cardiac BCG data into a defined collection of waveforms associated with a defined transform;</claim-text>
<claim-text>performing envelope detection on the transformed cardiac BCG data to generate an outline of the transformed cardiac BCG data;</claim-text>
<claim-text>performing peak detection on the transformed cardiac BCG data to generate at least one of peaks or valleys from the envelope detected cardiac BCG data;</claim-text>
<claim-text>performing correlation analysis on the transformed cardiac BCG data; and</claim-text>
<claim-text>identifying the heart beats from the correlated cardiac BCG data and the peak detected cardiac BCG data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text><b>7</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein when the cardio-respiratory BCG data is respiratory BCG data, the cardio-respiratory events are breaths, the cardio-respiratory event rate is a respiration rate, and the cardio-respiratory event components are inhalation and exhalation.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text><b>8</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein when the cardio-respiratory BCG data is respiratory BCG data, the cardio-respiratory events are snores, the cardio-respiratory event rate is a snoring rate, and the cardio-respiratory event components are snore during inhalation and snore during exhalation.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text><b>9</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein when the cardio-respiratory BCG data is respiratory BCG data, the cardio-respiratory events are breath pattern changes, the cardio-respiratory event rate is a breath pattern change rate, and the cardio-respiratory event components are breathing with normal pattern and breathing with abnormal pattern.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text><b>10</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the cardio-respiratory processing further comprising:
<claim-text>filtering sub-sampled respiratory BCG data to strengthen respiratory processing of the respiratory BCG data;</claim-text>
<claim-text>transforming the filtered respiratory BCG data into a defined collection of waveforms associated with a defined transform;</claim-text>
<claim-text>performing peak detection on the transformed respiratory BCG data to generate at least one of peaks or valleys from transformed respiratory BCG data;</claim-text>
<claim-text>performing correlation analysis on the transformed respiratory BCG data; and</claim-text>
<claim-text>identifying the breaths from the correlated respiratory BCG data and the peak detected respiratory BCG data.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text><b>11</b>. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the generating a synthetic cardio-respiratory signal further comprising:
<claim-text>generating a real-time cardio-respiratory event morphology from the cardio-respiratory event morphology template and the cardio-respiratory parameter set; and</claim-text>
<claim-text>generating the synthetic cardio-respiratory signal from the real-time cardio-respiratory event morphology and the time span.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text><b>12</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the generating a real-time cardio-respiratory event morphology further comprising:
<claim-text>modifying the template cardio-respiratory event morphology by application of the cardio-respiratory parameter set.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text><b>13</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<claim-text>generating a synthetic cardio-respiratory sound stream from a template sound and the time span.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text><b>14</b>. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<claim-text>modulating the real-time cardio-respiratory event morphology;</claim-text>
<claim-text>generating a real-time template sound; and</claim-text>
<claim-text>generating a synthetic cardio-respiratory sound stream from the real-time template sound and the time span.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text><b>15</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>training a classifier based on the cardio-respiratory BCG data to generate at least a cardio-respiratory morphology classifier and a sound stream classifier; and</claim-text>
<claim-text>making classifications on non-classified cardio-respiratory BCG data using at least one of the cardio-respiratory morphology classifier or the sound stream classifier.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text><b>16</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<claim-text>updating classifiers associated with other one or more sensors with at least the cardio-respiratory morphology classifier and the sound stream classifier,</claim-text>
<claim-text>wherein the other one or more sensors and the one or more sensors are associated with different subjects.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text><b>17</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein when the one or more sensors is multiple sensors, the method further comprising:
<claim-text>obtaining multiple sensor multiple dimensions array (MSMDA) BCG data from the multiple sensors;</claim-text>
<claim-text>generating a surface location for the multiple sensors;</claim-text>
<claim-text>obtaining spatial cardio-respiratory maps;</claim-text>
<claim-text>generating cardio-respiratory combinations from the MSMDA BCG data using the surface location map and the spatial cardio-respiratory map; and</claim-text>
<claim-text>generating the synthetic cardio-respiratory signal from at least the cardio-respiratory parameter set generated from each cardio-respiratory combination and the cardio-respiratory event morphology template.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the cardio-respiratory combinations are jointly pre-processed during the pre-processing.</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text><b>19</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising:
<claim-text>training a classifier based on the MSMDA BCG data to generate at least a cardio-respiratory morphology classifier and a sound stream classifier; and</claim-text>
<claim-text>making classifications on non-classified MSMDA BCG data using at least one of the cardio-respiratory morphology classifier or the sound stream classifier.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text><b>20</b>. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, further comprising:
<claim-text>updating classifiers associated with other multiple sensors with at least the cardio-respiratory morphology classifier and the sound stream classifier,</claim-text>
<claim-text>wherein the other multiple sensors and the multiple sensors are associated with different subjects.</claim-text>
</claim-text>
</claim>
<claim id="CLM-21-28" num="21-28">
<claim-text><b>21</b>-<b>28</b>. (canceled)</claim-text>
</claim>
</claims>
</us-patent-application>
