<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE us-patent-application SYSTEM "us-patent-application-v46-2022-02-17.dtd" [ ]>
<us-patent-application lang="EN" dtd-version="v4.6 2022-02-17" file="US20230225238A1-20230720.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20230620" date-publ="20230720">
<us-bibliographic-data-application lang="EN" country="US">
<publication-reference>
<document-id>
<country>US</country>
<doc-number>20230225238</doc-number>
<kind>A1</kind>
<date>20230720</date>
</document-id>
</publication-reference>
<application-reference appl-type="utility">
<document-id>
<country>US</country>
<doc-number>18187398</doc-number>
<date>20230321</date>
</document-id>
</application-reference>
<us-application-series-code>18</us-application-series-code>
<classifications-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>01</class>
<subclass>D</subclass>
<main-group>41</main-group>
<subgroup>127</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>01</class>
<subclass>D</subclass>
<main-group>41</main-group>
<subgroup>12</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>01</class>
<subclass>M</subclass>
<main-group>21</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
<classification-ipcr>
<ipc-version-indicator><date>20060101</date></ipc-version-indicator>
<classification-level>A</classification-level>
<section>A</section>
<class>01</class>
<subclass>M</subclass>
<main-group>21</main-group>
<subgroup>04</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
</classification-ipcr>
</classifications-ipcr>
<classifications-cpc>
<main-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>01</class>
<subclass>D</subclass>
<main-group>41</main-group>
<subgroup>127</subgroup>
<symbol-position>F</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</main-cpc>
<further-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>01</class>
<subclass>D</subclass>
<main-group>41</main-group>
<subgroup>1243</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>01</class>
<subclass>M</subclass>
<main-group>21</main-group>
<subgroup>02</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
<classification-cpc>
<cpc-version-indicator><date>20130101</date></cpc-version-indicator>
<section>A</section>
<class>01</class>
<subclass>M</subclass>
<main-group>21</main-group>
<subgroup>043</subgroup>
<symbol-position>L</symbol-position>
<classification-value>I</classification-value>
<action-date><date>20230720</date></action-date>
<generating-office><country>US</country></generating-office>
<classification-status>B</classification-status>
<classification-data-source>H</classification-data-source>
<scheme-origination-code>C</scheme-origination-code>
</classification-cpc>
</further-cpc>
</classifications-cpc>
<invention-title id="vbwqf82foovw4">AGRICULTURAL HARVESTING MACHINE WITH PRE-EMERGENCE WEED DETECTION AND MITIGATION SYSTEM</invention-title>
<us-related-documents>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>16783475</doc-number>
<date>20200206</date>
</document-id>
<parent-status>PENDING</parent-status>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>18187398</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
<continuation>
<relation>
<parent-doc>
<document-id>
<country>US</country>
<doc-number>16783511</doc-number>
<date>20200206</date>
</document-id>
<parent-grant-document>
<document-id>
<country>US</country>
<doc-number>11641800</doc-number>
</document-id>
</parent-grant-document>
</parent-doc>
<child-doc>
<document-id>
<country>US</country>
<doc-number>18187398</doc-number>
</document-id>
</child-doc>
</relation>
</continuation>
</us-related-documents>
<us-parties>
<us-applicants>
<us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee">
<addressbook>
<orgname>Deere &amp; Company</orgname>
<address>
<city>Moline</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
<residence>
<country>US</country>
</residence>
</us-applicant>
</us-applicants>
<inventors>
<inventor sequence="00" designation="us-only">
<addressbook>
<last-name>BLANK</last-name>
<first-name>Sebastian</first-name>
<address>
<city>Moline</city>
<state>IL</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="01" designation="us-only">
<addressbook>
<last-name>HAMMER</last-name>
<first-name>Curtis R.</first-name>
<address>
<city>Bettendorf</city>
<state>IA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="02" designation="us-only">
<addressbook>
<last-name>ANDERSON</last-name>
<first-name>Noel W.</first-name>
<address>
<city>Fargo</city>
<state>ND</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="03" designation="us-only">
<addressbook>
<last-name>PFEIFFER</last-name>
<first-name>Dohn W.</first-name>
<address>
<city>Bettendorf</city>
<state>IA</state>
<country>US</country>
</address>
</addressbook>
</inventor>
<inventor sequence="04" designation="us-only">
<addressbook>
<last-name>ADVANI</last-name>
<first-name>Gurmukh H.</first-name>
<address>
<city>West Fargo</city>
<state>ND</state>
<country>US</country>
</address>
</addressbook>
</inventor>
</inventors>
</us-parties>
</us-bibliographic-data-application>
<abstract id="abstract">
<p id="p-0001" num="0000">An agricultural harvesting machine includes crop processing functionality configured to engage crop in a field, perform a crop processing operation on the crop, and move the processed crop to a harvested crop repository, and a control system configured to identify a weed seed area indicating presence of weed seeds, and generate a control signal associated with a pre-emergence weed seed treatment operation based on the identified weed seed area.</p>
</abstract>
<drawings id="DRAWINGS">
<figure id="Fig-EMI-D00000" num="00000">
<img id="EMI-D00000" he="145.54mm" wi="235.80mm" file="US20230225238A1-20230720-D00000.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00001" num="00001">
<img id="EMI-D00001" he="255.10mm" wi="163.91mm" file="US20230225238A1-20230720-D00001.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00002" num="00002">
<img id="EMI-D00002" he="236.47mm" wi="170.52mm" file="US20230225238A1-20230720-D00002.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00003" num="00003">
<img id="EMI-D00003" he="235.29mm" wi="170.52mm" file="US20230225238A1-20230720-D00003.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00004" num="00004">
<img id="EMI-D00004" he="235.12mm" wi="166.96mm" file="US20230225238A1-20230720-D00004.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00005" num="00005">
<img id="EMI-D00005" he="239.35mm" wi="160.19mm" file="US20230225238A1-20230720-D00005.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00006" num="00006">
<img id="EMI-D00006" he="240.03mm" wi="157.23mm" file="US20230225238A1-20230720-D00006.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00007" num="00007">
<img id="EMI-D00007" he="134.54mm" wi="80.86mm" file="US20230225238A1-20230720-D00007.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00008" num="00008">
<img id="EMI-D00008" he="256.20mm" wi="163.49mm" file="US20230225238A1-20230720-D00008.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00009" num="00009">
<img id="EMI-D00009" he="234.87mm" wi="170.52mm" file="US20230225238A1-20230720-D00009.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00010" num="00010">
<img id="EMI-D00010" he="79.25mm" wi="97.37mm" file="US20230225238A1-20230720-D00010.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00011" num="00011">
<img id="EMI-D00011" he="205.23mm" wi="141.73mm" file="US20230225238A1-20230720-D00011.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00012" num="00012">
<img id="EMI-D00012" he="247.31mm" wi="138.51mm" file="US20230225238A1-20230720-D00012.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00013" num="00013">
<img id="EMI-D00013" he="214.29mm" wi="138.09mm" file="US20230225238A1-20230720-D00013.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00014" num="00014">
<img id="EMI-D00014" he="246.63mm" wi="161.71mm" file="US20230225238A1-20230720-D00014.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
<figure id="Fig-EMI-D00015" num="00015">
<img id="EMI-D00015" he="165.35mm" wi="136.57mm" file="US20230225238A1-20230720-D00015.TIF" alt="embedded image" img-content="drawing" img-format="tif"/>
</figure>
<figure id="Fig-EMI-D00016" num="00016">
<img id="EMI-D00016" he="231.22mm" wi="167.22mm" file="US20230225238A1-20230720-D00016.TIF" alt="embedded image" img-content="drawing" img-format="tif" orientation="landscape"/>
</figure>
</drawings>
<description id="description">
<?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="lead"?>
<heading level="1" id="h-0001">CROSS-REFERENCE TO RELATED APPLICATION</heading>
<p id="p-0002" num="0001">The present application is a continuation of and claims priority of U.S. Pat. Application Serial No. 16/783,475, filed Feb. 6, 2020, the content of which is hereby incorporated by reference in its entirety. The present application is also a continuation of and claims priority of U.S. Pat. Application Serial No. 16/783,511, filed Feb. 6, 2020, the content of which is hereby incorporated by reference in its entirety.</p>
<?cross-reference-to-related-applications description="Cross Reference To Related Applications" end="tail"?>
<?summary-of-invention description="Summary of Invention" end="lead"?>
<heading level="1" id="h-0002">FIELD OF THE DESCRIPTION</heading>
<p id="p-0003" num="0002">The present description generally relates to agricultural machines. More specifically, but not by limitation, the present description relates to pre-emergence weed detection and mitigation.</p>
<heading level="1" id="h-0003">BACKGROUND</heading>
<p id="p-0004" num="0003">There are a wide variety of different types of farming techniques. One such technique is referred to as precision farming. Precision farming, or precision agriculture, is also referred to as site-specific crop management. The technique uses observation and measurement of variations of different criteria at specific sites, from field-to-field, and even within a single field. The observation and measurement of the variation in the different criteria can then be acted on in different ways.</p>
<p id="p-0005" num="0004">The effectiveness of precision farming depends, at least in part, upon the timely gathering of information at a site-specific level, so that information can be used to make better decisions in treating and managing the crop. This type of information can include information that is indicative of plant emergence characteristics (such as maturity, emergence uniformity, etc.) pest presence, disease, water and nutrient levels, weed stresses, etc. Management techniques for weeds, which reduce crop yields, include the application of a chemical (e.g., herbicide) to the field to mitigate weed growth.</p>
<p id="p-0006" num="0005">The discussion above is merely provided for general background information and is not intended to be used as an aid in determining the scope of the claimed subject matter.</p>
<heading level="1" id="h-0004">SUMMARY</heading>
<p id="p-0007" num="0006">An agricultural harvesting machine includes crop processing functionality configured to engage crop in a field, perform a crop processing operation on the crop, and move the processed crop to a harvested crop repository, and a control system configured to identify a weed seed area indicating presence of weed seeds, and generate a control signal associated with a pre-emergence weed seed treatment operation based on the identified weed seed area.</p>
<p id="p-0008" num="0007">This Summary is provided to introduce a selection of concepts in a simplified form that is further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter. The claimed subject matter is not limited to implementations that solve any or all disadvantages noted in the background.</p>
<?summary-of-invention description="Summary of Invention" end="tail"?>
<?brief-description-of-drawings description="Brief Description of Drawings" end="lead"?>
<description-of-drawings>
<heading level="1" id="h-0005">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<p id="p-0009" num="0008"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates one example of an agricultural architecture for pre-emergence weed mitigation.</p>
<p id="p-0010" num="0009"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flow diagram illustrating an example operation of an agricultural architecture that identifies weed seed locations and performing a pre-emergence weed mitigation operation.</p>
<p id="p-0011" num="0010"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow diagram illustrating an example operation for generating weed map(s).</p>
<p id="p-0012" num="0011"><figref idref="DRAWINGS">FIG. <b>4</b></figref> is a partial pictorial, partial schematic, illustration of one example of an agricultural machine.</p>
<p id="p-0013" num="0012"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram showing one example of an agricultural machine.</p>
<p id="p-0014" num="0013"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating one example of a control system.</p>
<p id="p-0015" num="0014"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram illustrating one example of a pre-emergence weed mitigation system.</p>
<p id="p-0016" num="0015"><figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref> is a flow diagram illustrating an example operation of a pre-emergence weed mitigation system.</p>
<p id="p-0017" num="0016"><figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example weed area on a field being harvested by a combine.</p>
<p id="p-0018" num="0017"><figref idref="DRAWINGS">FIGS. <b>10</b>A and <b>10</b>B</figref> illustrates an example image from an electromagnetic sensor that senses components of a material flow in an agricultural harvesting machine.</p>
<p id="p-0019" num="0018"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram showing one example of the architecture illustrated in <figref idref="DRAWINGS">FIG. <b>3</b></figref>, deployed in a remote server architecture.</p>
<p id="p-0020" num="0019"><figref idref="DRAWINGS">FIGS. <b>12</b>-<b>14</b></figref> show examples of mobile devices that can be used in the architectures shown in the previous figures.</p>
<p id="p-0021" num="0020"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is a block diagram showing one example of a computing environment that can be used in the architectures shown in the previous figures.</p>
</description-of-drawings>
<?brief-description-of-drawings description="Brief Description of Drawings" end="tail"?>
<?detailed-description description="Detailed Description" end="lead"?>
<heading level="1" id="h-0006">DETAILED DESCRIPTION</heading>
<p id="p-0022" num="0021">The present description generally relates to agricultural machines. More specifically, but not by limitation, the present description relates to pre-emergence weed detection and mitigation. As noted above, some weed management techniques including the application of a chemical (e.g., herbicide) to an agricultural field to mitigate weed growth. For sake of the present discussion, a &#x201c;weed&#x201d; or &#x201c;weed plant&#x201d; refers to any plant other than a target crop plant type of the subject field. This can include non-crop plants as well as crop plants of a different crop type. To illustrate, in a corn field to be harvested by a corn harvester, &#x201c;weeds&#x201d; can include common non-crop plants (e.g., giant ragweed, common ragweed, horseweed (marestail), johnsongrass, palmer amaranth, ryegrass, waterhemp, etc.) and crop plants other than corn (e.g., soybeans, etc.). That is, it includes plant types other corn plants.</p>
<p id="p-0023" num="0022">Unfortunately, over time some types of weeds have developed herbicide-resistance which results in decreased effectiveness of the herbicide application. For instance, examples of weeds that have developed glyphosate resistance include, but are not limited to, those mentioned above. At best, the herbicide-resistance requires an excessive application of the herbicide and, at worst, the herbicide-resistance renders the herbicide application ineffective. Further, excessive application of herbicide has drawbacks. For instance, in addition to a significant increase in costs involved (e.g., machine operating costs, herbicide costs, etc.), excessive herbicide application may be harmful to the crop and/or is otherwise undesirable.</p>
<p id="p-0024" num="0023">One pre-emergence application technique utilizes weed maps and an expected timing of emergence to determine when to apply a pre-emergence herbicide. These maps are obtained from weed growing locations from prior year growing seasons or harvest, to predict where the weeds will emerge for the current year. This is often inaccurate, which can result in incorrect herbicide application doses and/or the application of herbicide to the incorrect areas of the field.</p>
<p id="p-0025" num="0024">The present disclosure provides a system for an agricultural environment that processes weed plant location information, such as weed maps, that supports pre-emergence mitigation. The weed plant data can be obtained from any of a wide variety of sources, such as remote sensing data obtained from image data sources. Examples of image data sources include, but are not limited to, manned aircraft cameras, unmanned aerial vehicle (UAV or drone) cameras, stationary mounted or on-board cameras, etc. For sake of illustration, as discussed below an agricultural harvester or combine identifies the locations of weed seeds, which can be utilized to control on-board weed seed mitigators. Alternatively, or in addition, weed seed maps can be generated and utilized to perform pre-emergence weed mitigation post-harvest. In either case, the system can mitigate even herbicide-resistance weeds.</p>
<p id="p-0026" num="0025"><figref idref="DRAWINGS">FIG. <b>1</b></figref> illustrates one example of an agricultural architecture <b>100</b> for pre-emergence weed mitigation. Architecture <b>100</b> includes an agricultural machine <b>102</b> configured to generate pre-emergence weed seed location information that represents the presence of weed seeds in a field and/or perform a pre-emergence weed mitigation operation using that weed seed location information. It is noted that machine <b>102</b> can be any of a wide variety of different types of agricultural machines. For instance, in examples described below machine <b>102</b> comprises an agricultural harvesting machine (also referred to as a &#x201c;harvester&#x201d; or &#x201c;combine&#x201d;). In other examples, machine <b>102</b> can comprise a sprayer, cultivator, to name a few. Also, while machine <b>102</b> is illustrated with a single box in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, machine <b>102</b> can comprise multiple machines (e.g., a towed implement towed by a towing machine). In this example, the elements of machine <b>102</b> illustrated in <figref idref="DRAWINGS">FIG. <b>1</b></figref> can be distributed across a number of different machines.</p>
<p id="p-0027" num="0026">Machine <b>102</b> includes a control system <b>108</b> configured to control other components and systems of architecture <b>100</b>. For instance, control system <b>108</b> includes a weed seed mapping system <b>109</b>, which is discussed in further detail below. Also, control system <b>108</b> includes a communication controller <b>110</b> configured to control communication system <b>112</b> to communicate between components of machine <b>102</b> and/or with other machines or systems, such as remote computing system <b>114</b> and/or machine(s) <b>115</b>, either directly or over a network <b>116</b>. Also, machine <b>102</b> can communicate with other agricultural machine(s) <b>117</b> as well. Agricultural machine(s) <b>117</b> can be a similar type of machine as machine <b>102</b>, and they can be different types of machines as well. Network <b>116</b> can be any of a wide variety of different types of networks such as the Internet, a cellular network, a local area network, a near field communication network, or any of a wide variety of other networks or combinations of networks or communication systems.</p>
<p id="p-0028" num="0027">A remote user <b>118</b> is illustrated interacting with remote computing system <b>114</b>. Remote computing system <b>114</b> can be a wide variety of different types of systems. For example, remote system <b>114</b> can be a remote server environment, remote computing system that is used by remote user <b>118</b>. Further, it can be a remote computing system, such as a mobile device, remote network, or a wide variety of other remote systems. Remote system <b>114</b> can include one or more processors or servers, a data store, and it can include other items as well.</p>
<p id="p-0029" num="0028">Communication system <b>112</b> can include wired and/or wireless communication logic, which can be substantially any communication system that can be used by the systems and components of machine <b>102</b> to communicate information to other items, such as between control system <b>108</b>, sensors <b>120</b>, controllable subsystems <b>122</b>, image capture system <b>124</b>, and plant evaluation system <b>126</b>. In one example, communication system <b>112</b> communicates over a controller area network (CAN) bus (or another network, such as an Ethernet network, etc.) to communicate information between those items. This information can include the various sensor signals and output signals generated by the sensor variables and/or sensed variables.</p>
<p id="p-0030" num="0029">Control system <b>108</b> includes a user interface component <b>127</b> configured to control interfaces, such as operator interface(s) <b>128</b> that include input mechanisms configured to receive input from an operator <b>130</b> and output mechanisms that render outputs to operator <b>130</b>. The user input mechanisms can include mechanisms such as hardware buttons, switches, joysticks, keyboards, etc., as well as virtual mechanisms or actuators such as a virtual keyboard or actuators displayed on a touch sensitive screen. The output mechanisms can include display screens, speakers, etc.</p>
<p id="p-0031" num="0030">Sensor(s) <b>120</b> can include any of a wide variety of different types of sensors. In the illustrated example, sensors <b>120</b> include position sensor(s) <b>132</b>, speed sensor(s) <b>134</b>, environmental sensor(s) <b>136</b>, and can include other types of sensors <b>138</b> as well. Position sensor(s) <b>132</b> are configured to determine a geographic position of machine <b>102</b> on the field, and can include, but are not limited to, a Global Navigation Satellite System (GNSS) receiver that receives signals from a GNSS satellite transmitter. It can also include a Real-Time Kinematic (RTK) component that is configured to enhance the precision of position data derived from the GNSS signal. Speed sensor(s) <b>134</b> are configured to determine a speed at which machine <b>102</b> is traveling the field during the spraying operation. This can include sensors that sense the movement of ground-engaging elements (e.g., wheels or tracks) and/or can utilize signals received from other sources, such as position sensor(s) <b>132</b>.</p>
<p id="p-0032" num="0031">Control system <b>108</b> includes control logic <b>140</b>, and can include other items <b>142</b> as well. As illustrated by the dashed box in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, control system <b>108</b> can include some or all of plant evaluation system <b>126</b>, which is discussed in further detail below. Also, machine <b>102</b> can include some or all of image capture system <b>124</b>. Control logic <b>140</b> is configured to generate control signals to control sensors <b>120</b>, controllable subsystems <b>122</b>, communication system <b>112</b>, or any other items in architecture <b>100</b>. Controllable subsystems <b>122</b> include a pre-emergence weed mitigation system <b>144</b>, machine actuators <b>146</b>, a propulsion subsystem <b>148</b>, a steering subsystem <b>150</b>, and can include other items <b>152</b> as well.</p>
<p id="p-0033" num="0032">Machine <b>102</b> includes a data store <b>161</b> configured to store data for use by machine <b>102</b>, such as field data. Examples include, but are not limited to, field location data that identifies a location of the field to be operated upon by a machine <b>102</b>, field shape and topography data that defines a shape and topography of the field, crop location data that is indicative of a location of crops in the field (e.g., the location of crop rows), or any other data. In the illustrated example, data store <b>161</b> stores weed maps <b>162</b> that are generated by machine <b>102</b> or otherwise obtained by machine <b>102</b>, such as from plant evaluation system <b>126</b>. Of course, data store <b>161</b> can store other data as well.</p>
<p id="p-0034" num="0033">Machine <b>102</b> is illustrated as including one or more processors or servers <b>163</b>, and it can include other items <b>164</b> as well.</p>
<p id="p-0035" num="0034">As illustrated by the dashed boxes in <figref idref="DRAWINGS">FIG. <b>1</b></figref>, machine <b>102</b> can include some or all components of image capture system <b>124</b> and/or plant evaluation system <b>126</b>, both of which are discussed in further detail below. Also, agricultural machine(s) <b>117</b> can include a pre-emergence weed mitigation system <b>119</b>, which can be similar to, or different from, system <b>144</b>.</p>
<p id="p-0036" num="0035">Image capture system <b>124</b> includes image capture components configured to capture one or more images of the area under consideration (i.e., the portions of the field to be operated upon by machine <b>102</b>) and image processing components configured to process those images. The captured images represent a spectral response captured by image capture system <b>124</b> that are provided to plant evaluations system <b>126</b> and/or stored in data store <b>174</b>. A spectral imaging system illustratively includes a camera that takes spectral images of the field under analysis. For instance, the camera can be a multispectral camera or a hyperspectral camera, or a wide variety of other devices for capturing spectral images. The camera can detect visible light, infrared radiation, or otherwise.</p>
<p id="p-0037" num="0036">In one example, the image capture components include a stereo camera configured to capture a still image, a time series of images, and/or a video of the field. An example stereo camera captures high definition video at thirty frames per second (FPS) with one hundred and ten degree wide-angle field of view. Of course, this is for sake of example only.</p>
<p id="p-0038" num="0037">Illustratively, a stereo camera includes two or more lenses with a separate image sensor for each lens. Stereo images (e.g., stereoscopic photos) captured by a stereo camera allow for computer stereo vision that extracts three-dimensional information from the digital images. In another example, a single lens camera can be utilized to acquire images (referred to as a &#x201c;mono&#x201d; image).</p>
<p id="p-0039" num="0038">Image capture system <b>124</b> can include one or more of an aerial image capture system <b>176</b>, an on-board image capture system <b>178</b>, and/or other image capture system <b>180</b>. An example of aerial image capture system <b>124</b> includes a camera or other imaging component carried on an unmanned aerial vehicle (UAV) or drone (e.g., block <b>115</b>). An example of on-board image capture system <b>178</b> includes a camera or other imaging component mounted on, or otherwise carried by, machine <b>102</b> (or <b>104</b>). An example of image capture system <b>180</b> includes a satellite imaging system. System <b>124</b> also includes a location system <b>182</b>, and can include other items <b>184</b> as well. Location system <b>182</b> is configured to generate a signal indicative of geographic location associated with the captured image. For example, location system <b>182</b> can output GPS coordinates that are associated with the captured image to obtain geo-referenced images <b>186</b> that are provided to plant evaluation system <b>126</b>.</p>
<p id="p-0040" num="0039">Plant evaluation system <b>126</b> illustratively includes one or more processors <b>188</b>, a communication system <b>189</b>, a data store <b>190</b>, an image analysis system <b>191</b>, target field identification logic <b>192</b>, trigger detection logic <b>193</b>, a weed map generator <b>194</b>, and can include other items <b>195</b> as well. Communication system <b>189</b>, in one example, is substantially similar to communication system <b>112</b>, discussed above.</p>
<p id="p-0041" num="0040">Target field identification logic <b>192</b> is configured to identify a target or subject field for which a weed map is to be generated by weed map generator <b>194</b>. The target field identification is correlated to the weed maps <b>196</b>, which are generated by weed map generator <b>194</b> and can be stored in data store <b>190</b>.</p>
<p id="p-0042" num="0041">Trigger detection logic <b>193</b> is configured to detect a triggering criterion that triggers generation (or updating) of a weed map by generator <b>194</b>. For example, in response to detection of a triggering criteria, logic <b>193</b> can communication instructions to image capture system <b>124</b> to capture images of the target field. These images are then processed by image analysis system <b>191</b>, and the results of the image analysis are utilized by weed map generator <b>194</b> to generate weed maps <b>196</b>.</p>
<p id="p-0043" num="0042"><figref idref="DRAWINGS">FIG. <b>2</b></figref> is a flow diagram <b>200</b> illustrating an example operation of architecture <b>100</b> in identifying weed seed locations and performing a pre-emergence weed mitigation operation.</p>
<p id="p-0044" num="0043">At block <b>202</b>, logic <b>192</b> identifies a target worksite (i.e., a field to be harvested). At block <b>204</b>, logic <b>193</b> detects a trigger for triggering generation (or updating) of a weed map for the identified field. For instance, this can be done periodically (block <b>206</b>), in response to an event (block <b>208</b>), and/or manually in response to a user input (block <b>210</b>). Of course, the trigger can be detected in other ways as well. This is represented by block <b>212</b>.</p>
<p id="p-0045" num="0044">At block <b>214</b>, a weed map of the field is generated. It is noted that the weed map can be generated at any of a variety of different times. For example, the weed map can be generated during the growing season, before harvest while the crops (and weeds) are growing. This is represented by block <b>216</b>. In another example, the weed map can be generated at harvest time, when a harvesting machine is performing a harvesting operation in the field. This is represented by block <b>218</b>. In another example, the weed map can be generated by a combination of inputs during the growing season and at harvest time. This is represented by block <b>220</b>. Of course, the weed map can be generated in other ways as well. This is represented by block <b>222</b>. In one example, the weed map can include two (or more) plant classifications, i.e., crop and weed. Alternatively, or in addition, the weed map can include multiple non-crop plant classifications based on, for example but not by limitation, species, size, maturity, vigor, etc.</p>
<p id="p-0046" num="0045">In one example, image capture system <b>124</b> captures spectral images of the field under analysis, as well as video images. Geographic location information is associated with those images, and they are provided to plant evaluation system <b>126</b>. System <b>126</b> identifies evaluation zones in the field under analysis and analyzes the spectral images received from system <b>124</b> to identify weed plants in the evaluation zones. This can be done in any of a number of ways. For instance, the images can be processed to identify areas that correspond to weed plants. In another example, system <b>126</b> can identify areas in the evaluation zones that represent crop plants and subtract those areas out of the images to obtain a remaining image portion that represents the weeds or non-crop plants.</p>
<p id="p-0047" num="0046">In one example, the image capture system includes a camera, such as a multispectral camera or a hyperspectral camera, or a wide variety of other devices for capturing images. A video imaging system can be utilized that includes a camera that captures images in the visible or thermal image range. For example, it can be a visible light video camera with a wide angle lens, or a wide variety of other video imaging systems.</p>
<p id="p-0048" num="0047">Additionally, plant density information can be generated and associated with the weed map. That is, in addition to the weed map identifying areas of the field that contain weeds, a density metric can be associated with those areas. For instance, the density metric can indicate a percentage of the plants within the area that are weed plants versus crop plants. In another instance, it can be weeds / unit area.</p>
<p id="p-0049" num="0048">In one example, image analysis system <b>191</b> includes spectral analysis logic that performs spectral analysis to evaluate the plants in the images. In one example, this includes identifying areas in the image that have a spectral signature that corresponds to ground versus plants. For instance, this can be a green/brown comparison. Image segmentation logic can perform image segmentation to segment or divide the image into different portions for processing. This can be based on ground and/or plant area identifications by ground/plant identification logic, and crop classification performed by crop classification logic. Briefly, this can identify areas of an image that represent ground and areas of an image that represent plants, for example using the spatial and spectral analysis. Crop classification logic can use a crop classifier, that is trained using crop training data, to identify areas in the image that represent crop plants and/or areas that represent weed plants.</p>
<p id="p-0050" num="0049">In addition to identifying the location of the plant relative to the surface plane of the field (e.g., x/y coordinates), a height of the weed plants can be identified (e.g., how high the plant rises from the terrain in the z direction).</p>
<p id="p-0051" num="0050">At block <b>224</b>, weed seed locations are identified. The weed seed locations identify the location of the weed seeds pre-emergence, that is before the seeds germinate and emerge as visible plants. The weed seed locations can be identified in any of a number of ways. For example, the weed seed locations can be identified based on a priori data (block <b>226</b>), in situ data (block <b>228</b>), or a combination of a priori and in situ data (block <b>230</b>). For instance, the weed seed locations can be based on an a priori weed map generated during the growing season at block <b>216</b>. Alternatively, or in addition, the weed seed locations can be identified based on in situ data collected by on-board sensors.</p>
<p id="p-0052" num="0051">As illustrated at block <b>232</b>, the identified weed seed locations can be utilized to generate a weed seed map that maps the locations of the weed seeds to the field under analysis. An example weed seed map identifies regions of the field that are determined to have a number of weed seeds above a threshold, which can be defined in any of a number of ways. For example, the threshold can be pre-defined, set by an operator, dynamically determined, etc.</p>
<p id="p-0053" num="0052">As illustrated at block <b>234</b>, the weed seed locations are identified based on the weed map, generated at block <b>294</b>, which maps locations of the weeds in the field, taking into account a weed seed movement model. This model projects the likely location of a weed plant&#x2019;s seeds given the location of that weed plant and external factors that affect movement of the seed from the weed plant location. For instance, the model can take into account weather or other environmental data. For instance, the location of the weed seeds on the field can be determined based on the direction and/or speed of the wind as detected by sensors on machine <b>102</b> or otherwise obtained from a remote weather data source. In another example, the weed seed model can identify terrain conditions, such as slope or topography, precipitation, among other factors which can contribute to the displacement of the seeds from a weed plant.</p>
<p id="p-0054" num="0053">Alternatively, or in addition, the weed seed movement model can model machine data that processes the weed plants. For example, in the case of an agricultural harvesting machine, the machine data can be utilized to compensate for machine delays caused by the processing through the combine. That is, the machine delay models the distance (with respect to the field surface) between when the weed plant is cut by the header of the combine and the weed seeds are discharged by a chaff spreader. This delay can be dynamically determined based on machine settings (header speed, thresher settings, chaff settings, etc.) that may vary the time that it takes for the seed to travel through the combine and be discharged onto the field. As used herein, chaff refers to any material (also referred to a &#x201c;residue&#x201d;) that is ejected from the harvesting machine (typically from the rear of the machine), even though it may contain some crop material. That is, during operation of the combine, it is often the case that some crop material ends up in the non-crop material flow, and vice versa. Of course, the weed seed locations can be identified in other ways as well. This is represented by block <b>236</b>.</p>
<p id="p-0055" num="0054">At block <b>238</b>, the current weed seed locations (e.g., the weed seed map generated at block <b>232</b>) is stored. The weed seed locations can be stored locally (e.g., in data store <b>161</b>), can be sent to another agricultural machine (e.g., machine <b>117</b>), and/or can be sent to a remote computing system (e.g., system <b>114</b>).</p>
<p id="p-0056" num="0055">At block <b>240</b>, a control signal is generated for a pre-emergence weed mitigation operation. This can be performed during and/or after a harvesting operation. For example, a mitigation operation performed during the harvesting operation comprises a selective harvest. This is represented by block <b>242</b>. For instance, the harvesting machine can be controlled to selectively harvest different areas of the field based on the weed seed locations. That is, an area of high weed seed occurrence can be ignored, and then mitigated after the harvesting operation. In another example, the harvesting operation can selectively harvest areas of high weed seed presence in a single harvesting operation (so all of the material is collected together in the material repository) and then can be subsequently processed. These, of course, are for sake of example only.</p>
<p id="p-0057" num="0056">In another example, the weed seeds are collecting during the harvesting operation. For instance, a collector or other apparatus is positioned to collect the discharge from the combine and prevent the weed seeds from being ejected back onto the field. Alternatively, or in addition, a mitigator can be utilized to destroy or otherwise devitalize the weed seeds, inhibiting further germination or promulgation of the weed seeds. This can include mechanical mitigators, chemical mitigators, irradiation mitigators, etc. Examples of this are discussed in further detail below. Briefly, however, an example mitigator (mechanical, chemical, or otherwise) includes a device that interacts with the weed seed such that the weed seed has a lower ability to promulgate or germinate in a subsequent growing season.</p>
<p id="p-0058" num="0057">Also, the pre-emergence weed mitigation operation can discourage growth of the weed seeds. This is represented by block <b>248</b>. For example, a tiller machine can be utilized to till the area, post-harvest, to bury the weed seeds at a threshold depth (e.g., twelve inches or greater) at which the weed seeds are unlikely to germinate. In another example, early germination of the weed seeds can be stimulated (i.e., during the fall) so that the germinated weeds are exposed to the cold fall/winter weather which is likely to destroy the weed plants. In another example, a chemical can be applied to the weed seeds to discourage their spring germination and/or increase predation (e.g., being consumed by predator animals).</p>
<p id="p-0059" num="0058">Of course, the pre-emergence weed mitigation operation can comprise other types of operations as well. This is represented by block <b>250</b>.</p>
<p id="p-0060" num="0059"><figref idref="DRAWINGS">FIG. <b>3</b></figref> is a flow diagram <b>300</b> illustrating an example operation for generating weed map(s). For sake of illustration, but not by limitation, <figref idref="DRAWINGS">FIG. <b>3</b></figref> will be described in the context of systems <b>124</b> and <b>126</b> generating weed maps <b>196</b> for use by machine <b>102</b>.</p>
<p id="p-0061" num="0060">A block <b>302</b>, image data of the field is collected during the growing season and/or at harvest. As discussed above, this can include multispectral and/or hyperspectral images, represented by block <b>304</b>. Alternatively, or in addition, closeup video of the plants can be obtained at block <b>306</b>. Of course, other images can be obtained as well. This is represented by block 308.</p>
<p id="p-0062" num="0061">Also, the image data can be collected from a wide variety of different sources, for example, the image data can be collected from a UAV (block <b>310</b>), a satellite system (block <b>312</b>), on-board cameras (block <b>314</b>) that are on board machine <b>102</b>, and/or from other machines or devices (block <b>316</b>).</p>
<p id="p-0063" num="0062">A physiological plant growth model can be obtained at block <b>318</b>. Illustratively, a plant growth model can be used to understand what weed/crop maturity stage(s) to expect at a given time and location in the field. This can facilitate improvement of classifier results, especially if the characteristics change significantly during the growth cycle (i.e. less misclassification, better ability to differentiate). The model can represent irrigation patterns of the field (block <b>320</b>), weather data (block <b>322</b>), and/or soil/terrain data (block <b>324</b>). The weather data at block <b>322</b> can represent precipitation during the growing season and the soil/terrain data <b>324</b> can indicate soil characteristics, such as moisture, etc., as well as terrain topology data, such as the slope of the field.</p>
<p id="p-0064" num="0063">Also, the plant growth model can be generated based on data from a farm management information system (FMIS). This is represented by block <b>326</b>. An example FMIS system provides information on the type and/or variety of the planted crop, plant date of the crop, treatments that have been applied to the crop (e.g., before or during the growing season). Of course, the model can be obtained using other data as well. This is represented by block <b>328</b>.</p>
<p id="p-0065" num="0064">At block <b>330</b>, crop characteristics are obtained. In one example, this models where the crop maturity should be given the growth model. For instance, the crop characteristics obtained at block <b>330</b> can indicate that the crop and/or weeds should be at a particular emergence stage. In one example, this can represent crop/weed dry up characteristics prior to harvest. This can be utilized to differentiate crops and weeds, and is represented by block <b>332</b>. In another example, relative maturity rate data can be obtained at block <b>334</b>. In one example, this is utilized to find zones of similar agronomic behavior that can be utilized to classify weeds versus crops in smaller areas of the field, rather than across the entire field collectively.</p>
<p id="p-0066" num="0065">Of course, other crop characteristics can be obtained as well. This is represented by block <b>336</b>. At block <b>338</b>, the images collected at block <b>332</b> are classified to obtain a georeferenced weed map. For example, the classification can utilize a normalized difference vegetation index (NDVI). In one example, a crop mask is applied on the NDVI to obtain better crop development monitoring.</p>
<p id="p-0067" num="0066">In another example, weed/crop identifying characteristics can include reflectance spectra (block <b>342</b>), leaf shape information (block <b>344</b>), population texture (block <b>346</b>), plant height (block <b>348</b>), etc. Of course, the images can be classified in other ways as well. This is represented by block <b>350</b>.</p>
<p id="p-0068" num="0067">At block <b>352</b>, the weed map is output. For example, the weed map can be output to control system <b>108</b> for use by weed seed mapping system <b>109</b> to control pre-emergence weed mitigation system <b>144</b>. In another example, the weed map can be output for storage and/or display to remote user <b>118</b> and/or operator <b>130</b> using a display device.</p>
<p id="p-0069" num="0068">As noted above, one example of agricultural machine <b>102</b> is a harvester or combine, such as that shown in <figref idref="DRAWINGS">FIG. <b>4</b></figref> which is a partial pictorial, partial schematic, illustration of an agricultural harvesting machine <b>400</b> (or combine). It can be seen in <figref idref="DRAWINGS">FIG. <b>4</b></figref> that combine <b>400</b> illustratively includes an operator compartment <b>401</b>, which can have a variety of different operator interface mechanisms, for controlling combine <b>400</b>, as will be discussed in more detail below. Combine <b>400</b> can include a set of front end equipment that can include header <b>402</b>, and a cutter generally indicated at <b>404</b>. It can also include a feeder house <b>406</b>, a feed accelerator <b>408</b>, and a thresher generally indicated at <b>410</b>. Thresher <b>410</b> illustratively includes a threshing rotor <b>412</b> and a set of concaves <b>414</b>. Further, combine <b>400</b> can include a separator <b>416</b> that includes a separator rotor. Combine <b>400</b> can include a cleaning subsystem (or cleaning shoe) <b>418</b> that, itself, can include a cleaning fan <b>420</b>, chaffer <b>422</b> and sieve <b>424</b>. The material handling subsystem in combine <b>400</b> can include (in addition to a feeder house <b>406</b> and feed accelerator <b>408</b>) discharge beater <b>426</b>, tailings elevator <b>428</b>, clean grain elevator <b>430</b> (that moves clean grain into clean grain tank <b>432</b>) as well as unloading auger <b>434</b> and spout <b>436</b>. Combine <b>400</b> can further include a residue subsystem <b>438</b> that can include chopper <b>440</b> and spreader <b>442</b>. Combine <b>400</b> can also have a propulsion subsystem that includes an engine that drives ground engaging wheels <b>444</b> or tracks, etc. It will be noted that combine <b>400</b> may also have more than one of any of the subsystems mentioned above (such as left and right cleaning shoes, separators, etc.).</p>
<p id="p-0070" num="0069">In operation, and by way of overview, combine <b>400</b> illustratively moves through a field in the direction indicated by arrow <b>446</b>. As it moves, header <b>402</b> engages the crop to be harvested and gathers it toward cutter <b>404</b>. After it is cut, it is moved through a conveyor in feeder house <b>406</b> toward feed accelerator <b>408</b>, which accelerates the crop into thresher <b>410</b>. The crop is threshed by rotor <b>412</b> rotating the crop against concave <b>414</b>. The threshed crop is moved by a separator rotor in separator <b>416</b> where some of the residue is moved by discharge beater <b>426</b> toward the residue subsystem <b>438</b>. It can be chopped by residue chopper <b>440</b> and spread on the field by spreader <b>442</b>. In other implementations, the residue is simply dropped in a windrow, instead of being chopped and spread.</p>
<p id="p-0071" num="0070">Grain falls to cleaning shoe (or cleaning subsystem) <b>418</b>. Chaffer <b>422</b> separates some of the larger material from the grain, and sieve <b>424</b> separates some of the finer material from the clean grain. Clean grain falls to an auger in clean grain elevator <b>430</b>, which moves the clean grain upward and deposits it in clean grain tank <b>432</b>. Residue can be removed from the cleaning shoe <b>418</b> by airflow generated by cleaning fan <b>420</b>. That residue can also be moved rearwardly in combine <b>400</b> toward the residue handling subsystem <b>438</b>.</p>
<p id="p-0072" num="0071">Tailings can be moved by tailings elevator <b>428</b> back to thresher <b>410</b> where they can be re-threshed. Alternatively, the tailings can also be passed to a separate re-threshing mechanism (also using a tailings elevator or another transport mechanism) where they can be re-threshed as well.</p>
<p id="p-0073" num="0072"><figref idref="DRAWINGS">FIG. <b>4</b></figref> also shows that, in one example, combine <b>400</b> can include ground speed sensor <b>447</b>, one or more separator loss sensors <b>448</b>, a clean grain camera <b>450</b>, one or more cleaning shoe loss sensors <b>452</b>, forward looking camera <b>454</b>, rearward looking camera <b>456</b>, a tailings elevator camera <b>458</b>, and a wide variety of other cameras or image/video capture devices. Ground speed sensor <b>446</b> illustratively senses the travel speed of combine <b>400</b> over the ground. This can be done by sensing the speed of rotation of the wheels, the drive shaft, the axel, or other components. The travel speed can also be sensed by a positioning system, such as a global positioning system (GPS), a dead reckoning system, a LORAN system, or a wide variety of other systems or sensors that provide an indication of travel speed. In one example, optical sensor(s) capture images and optical flow is utilized to determine relative movement between two (or more) images taken at a given time spacing.</p>
<p id="p-0074" num="0073">Cleaning shoe loss sensors <b>452</b> illustratively provide an output signal indicative of the quantity of grain loss. In one example, this includes signal(s) indicative of the quality of grain loss by both the right and left sides of the cleaning shoe <b>418</b>. In one example, sensors <b>452</b> are strike sensors which count grain strikes per unit of time (or per unit of distance traveled) to provide an indication of the cleaning shoe grain loss. The strike sensors for the right and left sides of the cleaning shoe can provide individual signals, or a combined or aggregated signal. In one example, sound-based sensors across an area of the cleaning shoe and/or rotor can be utilized to obtain a count of grain strikes and a spatial distribution associated with the count. It will be noted that sensors <b>452</b> can comprise only a single sensor as well, instead of separate sensors for each shoe.</p>
<p id="p-0075" num="0074">Separator loss sensor <b>448</b> provides a signal indicative of grain loss in the left and right separators. The sensors associated with the left and right separators can provide separate grain loss signals or a combined or aggregate signal. This can be done using a wide variety of different types of sensors as well. It will be noted that separator loss sensors <b>448</b> may also comprise only a single sensor, instead of separate left and right sensors.</p>
<p id="p-0076" num="0075">Cameras <b>450</b>, <b>454</b>, <b>456</b> and <b>458</b> illustratively capture video or still images that can be transmitted to, and displayed on, a display in operator compartment <b>401</b> or a remote device (shown in more detail below) in near real time. Clean grain camera <b>450</b>, for instance, generates a video feed showing grain passing into clean grain tank <b>432</b> (or through clean grain elevator <b>430</b>). Camera <b>454</b> can illustratively generate a video feed showing a view forward of operator compartment <b>401</b>, such as showing header <b>402</b> and/or the crop in front of header <b>402</b>. Cameras <b>456</b> and <b>458</b> illustratively generate a video feed showing the tailings in elevator <b>458</b> and the discharge beater <b>442</b> and an area of the field behind combine <b>400</b>, respectively. Alternatively, or in addition to a video feed, captured images can be augmented and presented to the operator, for example in a manner aimed to reduce cognitive load on the operation. These are examples only, and additional or different cameras can be used and/or they can be devices that capture still images or other visual data.</p>
<p id="p-0077" num="0076"><figref idref="DRAWINGS">FIG. <b>5</b></figref> is a block diagram showing one example of machine <b>400</b> deployed in architecture <b>100</b>. As illustrated, combine <b>400</b> is configured to communicate over network <b>116</b> with remote computing system(s) <b>114</b>, as well as a set of assistive machines <b>502</b>, which can include a chaff collector <b>504</b>, a grain cart <b>506</b>, a tiller <b>508</b>, and/or other machines <b>510</b>. Machine <b>400</b> can also communicate with one or more grain receivers/processors <b>512</b>. This can include a grain truck <b>514</b>, a grain bin <b>516</b>, a cleaner <b>518</b>, an incinerator <b>520</b>, a burner <b>522</b>, and it can include other items <b>524</b> as well.</p>
<p id="p-0078" num="0077">As shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, combine <b>400</b> can generate operator interface displays <b>526</b> with user input mechanisms <b>528</b> for interaction by operator <b>130</b>. Operator <b>130</b> is illustratively a local operator of combine <b>400</b>, in the operator&#x2019;s compartment <b>401</b>, and can interact with user input mechanisms <b>528</b> in order to control and manipulate combine <b>400</b>.</p>
<p id="p-0079" num="0078">Combine <b>400</b> includes one or more processors or servers <b>530</b>, communication system <b>532</b>, a data store <b>534</b>, sensors <b>536</b>, controllable subsystems <b>538</b>, a control system <b>540</b>, a user interface component <b>542</b>, and can include other items <b>544</b> as well. In one example, some or all of these components are similar to the components discussed above with respect to machine <b>102</b> shown in <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p>
<p id="p-0080" num="0079">User interface component <b>542</b> can include one or more display devices, audio devices, one or more haptic devices, and it can include other items, such as a steering wheel, one or more joysticks, pedals, levers, buttons, keypads, etc. Where the user interface mechanisms include a user interface display, then user input mechanisms <b>528</b> can include buttons, icons, actuatable links, or other items that can be actuated by operator <b>130</b>. When control system <b>540</b> or other items on machine <b>400</b> use speech recognition, and/or speech synthesis, then user interface mechanisms <b>528</b> can include a microphone, a speaker, etc.</p>
<p id="p-0081" num="0080">Sensors <b>536</b>, in one example, includes one or more sensors <b>120</b> discussed above. That is, sensors <b>536</b> can include speed sensor(s) <b>546</b>, position sensor(s) <b>548</b>, environmental sensor(s) <b>550</b>, and can include other sensor(s) <b>552</b> as well. In the illustrated example, combine <b>400</b> includes weed seed sensor(s) <b>554</b> configured to sense the presence of weed seeds within combine <b>400</b>. This is discussed in further detail below. Briefly, however, sensors <b>554</b> can comprise a wide variety of different types of sensors. For instance, sensors <b>554</b> can include electromagnetic sensors, capacitive sensors, impact sensors, to name a few. In any case, sensors <b>554</b> are configured to detect the presence of weed seeds that are distinguished from crop or other material being processed through combine <b>400</b>.</p>
<p id="p-0082" num="0081">Control system <b>540</b> can include logic and actuators or other items that can perform various types of processing and generate control signals to control controllable subsystems <b>538</b>. The control signals can be generated based on user inputs, they can be generated automatically based on sensor inputs, based on detected events or otherwise. They can also be generated based on remote control inputs received from remote computing system <b>114</b>.</p>
<p id="p-0083" num="0082">Controllable subsystems <b>538</b> illustratively includes thresher <b>556</b>, which includes rotor <b>412</b>, concave(s) <b>414</b>, etc. Also, controllable subsystems <b>538</b> can include cleaner <b>558</b>, which includes cleaning shoe and/or fan <b>420</b>, sieve <b>424</b>, etc. Subsystems <b>538</b> also include chaff processing system <b>560</b>, which includes chaff separator <b>562</b>, chaff spreader <b>564</b>, etc. Controllable subsystems <b>538</b> also includes header <b>402</b>, a propulsion system <b>566</b> (e.g., system <b>148</b>), steering system <b>568</b> (e.g., system <b>150</b>), pre-emergence weed mitigation system <b>570</b> (e.g., system <b>144</b>), and can include other items <b>572</b> as well.</p>
<p id="p-0084" num="0083">It is noted that, in one example, machine <b>400</b> is deployed in a fleet of harvesting machines (which can be the same and/or different than machine <b>400</b>) that harvest a field or group of fields. The fleet of harvesting machines can be paired with one or more mitigators (e.g., <b>502</b>, <b>512</b>) that perform weed seed mitigation operations (e.g., seed collection, devitalization, etc.) for the entire fleet of machines. Accordingly, each harvesting machine can send weed seed location information to the mitigator(s) (or to another system that is accessed by the mitigator(s)) which then perform the mitigation operations in the field(s).</p>
<p id="p-0085" num="0084"><figref idref="DRAWINGS">FIG. <b>6</b></figref> is a block diagram illustrating one example of control system <b>540</b>. System <b>540</b> illustratively includes target field identification logic <b>602</b>, weed map identification logic <b>604</b>, a weed seed mapping system <b>606</b>, a user interface component <b>608</b>, control logic <b>610</b>, a communication controller <b>612</b>, one or more processors <b>614</b>, and can include other items <b>616</b> as well. In the illustrated example, control system <b>540</b> can also include weed map generator <b>194</b>, discussed above with respect to <figref idref="DRAWINGS">FIG. <b>1</b></figref>.</p>
<p id="p-0086" num="0085">Control system <b>540</b> is illustrated as receiving a number of inputs including, but not limited to, weed maps <b>618</b> and sensor signal(s) <b>620</b>. Sensor signal(s) <b>620</b> can include geoposition sensor signals <b>622</b>, speed signals <b>624</b>, images <b>626</b>, machine delay compensation signals <b>628</b>, weed seed data <b>630</b>, environmental data <b>632</b>, chaff spreader data <b>634</b>, and can include other sensor signals as well (represented by block <b>636</b>). Control system <b>540</b> is also illustrated as generated a number of outputs including, but not limited to, control signal(s) <b>638</b>, weed seed location <b>640</b> (which can be stored in data store <b>534</b>), and user interface mechanisms <b>642</b>.</p>
<p id="p-0087" num="0086">Target field identification logic <b>602</b> is configured to identify the field under consideration. This can be done based on user input from operator <b>130</b>, remote user <b>118</b>, or otherwise. Weed map identification logic <b>604</b> is configured to identify the weed map for the corresponding field identified by logic <b>602</b>. For instance, logic <b>604</b> can receive weed maps <b>618</b> generated external to control system <b>540</b>. In another example, the weed maps identified by logic <b>604</b> can be generated by weed map generator <b>194</b> on control system <b>540</b>.</p>
<p id="p-0088" num="0087">Weed seed mapping system <b>606</b> includes weed area identification logic <b>644</b> configured to identify weed areas based on the weed map, and includes weed seed location identification logic <b>646</b> configured to identify those locations on the field. For example, this can include a weed seed map generator <b>648</b> generating a weed seed map that maps the locations of weed seeds (and can include corresponding density information) to locations in the field. Logic <b>646</b> illustratively includes weed seed movement model application logic configured to apply a movement model that models movement of weed seeds to the weed seed areas. As described herein, this can be based on environmental data (e.g., weather, etc.), terrain data (e.g., slope, soil conditions, etc.), and/or machine data (e.g., chaff spreader settings, machine speed, etc.).</p>
<p id="p-0089" num="0088">In one example, machine delay compensation logic <b>650</b> is configured to compensate for delays in the processing of the plant material in machine <b>400</b>, in generating the weed seed locations from the weed maps. For instance, this can include weed seed tracking logic <b>652</b> that tracks movements of the seed within machine <b>400</b>. For instance, weed seed data <b>630</b> can be received from weed seed sensors that detect the weed seeds and their movement through machine <b>400</b>. In one example, logic <b>652</b> includes crop/weed ratio determination logic <b>652</b> configured to detect the ration of weed seeds to crop material being harvested.</p>
<p id="p-0090" num="0089">System <b>606</b> also includes machine position correlation logic <b>656</b> configured to correlate the position of machine <b>400</b> to the weed seed areas to generate weed seed location <b>640</b> and/or control signals <b>638</b>.</p>
<p id="p-0091" num="0090"><figref idref="DRAWINGS">FIG. <b>7</b></figref> is a block diagram illustrating one example of pre-emergence weed mitigation system <b>570</b>. In the illustrated example, system <b>570</b> includes one or more weed seed mitigators <b>702</b>. Illustratively, mitigator <b>702</b> includes a chaff treatment system <b>704</b> having weed seed crusher(s) <b>706</b>, weed seed burner(s) <b>708</b>, weed seed separators <b>710</b>, and/or chemical treatment mechanisms <b>712</b>, and can include other types of mitigators as well.</p>
<p id="p-0092" num="0091">Weed seed crusher(s) <b>706</b> are configured to mechanically contact (e.g., crush) the weed seeds to devitalize the weed seeds which prevents, or at least discourages, germination of the weed seeds. Similarly, weed seed burner(s) <b>708</b> are configured to thermally heat the weed seeds to a temperature that destroys the weed seeds. Chemical treatment mechanisms <b>712</b> are configured to chemically treat the weed seeds. Also, an irradiation device can irradiate the weed seeds.</p>
<p id="p-0093" num="0092">Mitigators <b>702</b> can also include on-board collectors and/or baggers <b>714</b> that are configured to collect the weed seeds. In one example, collectors <b>714</b> operate some or all of the chaff being ejected from combine <b>400</b>, which would otherwise be placed on the ground.</p>
<p id="p-0094" num="0093">In any case, collectors <b>714</b> collects the material that is being released from the crop processing components of combine <b>400</b>.</p>
<p id="p-0095" num="0094">Mitigators <b>702</b> can also include burier(s) <b>716</b> that are configured to bury the weed seeds to a threshold depth in the ground. For instance, a burier can be attached to, pulled by, or otherwise supported by combine <b>400</b>. The burier follows the chaff ejection components which can either spread the chaff on the ground, drop the chaff in a windrow, or otherwise. The buriers operate to bury the ejected chaff, and thus the weed seeds, to a threshold depth in the ground (e.g., twelve inches or deeper) which inhibits germination of the weed seeds. Also, it is noted that a burier can comprise a separate machine that follows combine <b>400</b>. Seed mitigators <b>702</b> can include other types of mitigators as well. This is represented by block <b>718</b>.</p>
<p id="p-0096" num="0095">System <b>570</b> is also illustrated as including communication/control logic <b>720</b> configured to communicate with other items in combine <b>400</b> and/or generate control signals to control weed seed mitigators <b>702</b>. Of course, system <b>570</b> can include other items <b>722</b> as well.</p>
<p id="p-0097" num="0096"><figref idref="DRAWINGS">FIGS. <b>8</b>A and <b>8</b>B</figref> (collectively referred to as <figref idref="DRAWINGS">FIG. <b>8</b></figref>) is a flow diagram <b>800</b> illustrating an example operation to generate weed seed locations and perform pre-emergent mitigation during a harvesting operation. For sake of illustration, but not by limitation, <figref idref="DRAWINGS">FIG. <b>8</b></figref> will be described in the context of combine <b>400</b> illustrated in <figref idref="DRAWINGS">FIGS. <b>4</b> and <b>5</b></figref>.</p>
<p id="p-0098" num="0097">At block <b>801</b>, a prior generated weed map of the target field (if any) is obtained. For example, this can include receiving weed map <b>618</b> shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>. At block <b>802</b>, a location and/or heading/path of combine <b>400</b> is obtained. For instance, this can be based on the sensor signals <b>620</b> which illustrate a current position and direction of combine <b>400</b>.</p>
<p id="p-0099" num="0098">At block <b>803</b>, images of plants in the path of combine <b>400</b> (e.g., forthcoming plants that are expected to reach the crop processing functionality of the combine) are obtained. For instance, this can include mono images (block <b>804</b>), stereo images (block <b>805</b>), or other images (block <b>806</b>). For example, the images obtained at block <b>803</b> can be received as images <b>626</b> from image capture system <b>124</b> that is on-board combine <b>400</b> and/or carried on a separate machine, such as UAV that operates ahead of combine <b>400</b> in the field.</p>
<p id="p-0100" num="0099">At block <b>807</b>, image classification is performed on the images obtained at block <b>803</b>. Examples of image classification are discussed above. Briefly, however, the image classification performed at block <b>807</b> classifies areas of the image as representing weed plants, crop plants, etc. Based on this, a weed map is obtained at block <b>808</b>. As represented at block <b>809</b>, the weed map can include the generation of a new weed map and/or the modification of an existing map. For example, the image classification performed at block <b>807</b> can be utilized to modify the weed map obtained at block <b>801</b>. The weed map can be obtained in other ways as well. This is represented at block <b>810</b>.</p>
<p id="p-0101" num="0100">At block <b>811</b>, weed areas are identified based on the weed map obtained at block <b>808</b>. The identified weed areas can include a spatial boundary that identifies its relative position on the field, as well as weed density information that identifies the density of the weeds within the weed area.</p>
<p id="p-0102" num="0101">At block <b>812</b>, each weed area is correlated to positions of the machine when the header 102 is within the weed area (i.e., when the header is actively cutting within the weed area).</p>
<p id="p-0103" num="0102">For sake of illustration, <figref idref="DRAWINGS">FIG. <b>9</b></figref> illustrates an example weed area <b>813</b> on a field <b>814</b> being harvested by combine <b>400</b>. The correlation at block <b>812</b> identifies the position of combine <b>400</b> when the header first reaches the beginning edge <b>815</b> of weed area <b>813</b> until the header passes the trailing edge <b>816</b>. A treatment zone is defined between edges <b>815</b> and <b>816</b> (and corresponding to the width of the header). Thus, for machine positions in which the header is within the treatment zone, the header is cutting the weed area, and is thus gathering weed seeds along with crop plants from that area of the field.</p>
<p id="p-0104" num="0103">As also shown, mitigation system <b>570</b> follows combine <b>400</b> (e.g., is attached to the combine <b>400</b>, is pulled by combine <b>400</b>, is pulled/carried by a separate machine, etc.) and is configured to perform a weed seed mitigation operation. For example, system <b>570</b> can include a trailer or container that is configured to collect the chaff or residue ejected from the rear of combine <b>400</b>, bury the chaff, burn the chaff, chemically treat the chaff, etc. In one example, a bagger collects the chaff into bags that are deposited or dropped on the field and later collected. System <b>570</b> can tag (e.g., with markings, barcodes, radio-frequency identification (RFID) tags, the bags with information on the collected chaff (e.g., location, type of material, quantity, weed seed composition, etc.). This information can be read from the tags during subsequent processing.</p>
<p id="p-0105" num="0104">Referring again to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, at block <b>817</b>, weed seed movement through the combine is determined. As discussed above, this, in one example, is based on machine delay compensation that represents the amount of time that it takes the weed seeds to move from a given point in the combine (e.g., the header cutting in the treatment zone) to a weed seed mitigator (e.g., collector, crusher, burner, etc.). This machine delay compensation is utilized by control system <b>540</b> to determine when to activate the corresponding mitigator to minimize operation of the mitigator. In other words, this operates to prevent or at least reduce operation of the mitigator during times when the mitigator is receiving material that does not include weed seeds or has weed seeds below a threshold. Thus, the mitigator is activated based on the spatial location of mitigator relative to the weed seed area. This can operate to reduce the associated costs of operating the mitigator. That is, some mitigators, such as seed crushers, have high operating costs in terms of power consumption, reduced efficiencies, wear and tear on the components, etc.</p>
<p id="p-0106" num="0105">In one example, the weed movement within combine <b>400</b> is estimated, for example based on the machine operation model and/or current settings (e.g., settings of thresher <b>556</b>, cleaner <b>558</b>, chaff processing <b>560</b>, etc.). This is represented by block <b>818</b>. Alternatively, or in addition, weed seed movement can be detected based on signals received from on-board sensors. This is represented by block <b>819</b>. For example, on-board sensors such as electromagnetic sensors (block <b>820</b>), capacitive sensors (block <b>821</b>), impact sensors (block <b>822</b>), or other types of sensors (block <b>823</b>) can be utilized.</p>
<p id="p-0107" num="0106">In some examples, chaff material such as leaves, stalks, or other residue material are typically less dense than weed seeds and have lower concentrations of protein and/or oil. Leaves and stalks are typically composed of only carbohydrates, and possibly a small amount of chlorophyll and water. This information can be leveraged from the signals received from on-board sensors <b>819</b> to determine the presence of weed seeds in the material flow.</p>
<p id="p-0108" num="0107">Referring to <figref idref="DRAWINGS">FIGS. <b>10</b>A and <b>10</b>B</figref> (collectively referred to as <figref idref="DRAWINGS">FIG. <b>10</b></figref>), an example image <b>1000</b> is received from an electromagnetic sensor that uses electromagnetic radiation that is reflected, scattered, transmitted, or absorbed by components of the material flow. In one example, image <b>1000</b> includes a grayscale image of the electromagnetic transmission through a material flow <b>1002</b>.</p>
<p id="p-0109" num="0108">Due to their differences in composition (e.g., as noted above, seeds typically have higher concentrations of oil and protein), chaff and seeds can have different electromagnetic responses that can be detected and utilized to identify weed seeds in material flow <b>1002</b>. Because seeds are denser than chaff, they show up darker in image <b>1000</b>. Similarly, size can be determined from the image and/or attenuation of the electromagnetic source signal (e.g., darker portions of the image can represent thicker material).</p>
<p id="p-0110" num="0109"><figref idref="DRAWINGS">FIG. <b>10</b>B</figref> shows image <b>1000</b> after gray objects have been classified as soybean seed (identified by reference numeral <b>1006</b>). Similarly, palmer amaranth is identified at reference numeral <b>1008</b> and common ragweed seed is identified at reference numeral <b>1010</b> using shape and size information. In one example, texture as well as non-visible spectra is utilized to determine density and/or reflectance difference. Alternatively, or in addition, active (modulated/pulsed) illumination is reposed in different spectral bands. In one example of <figref idref="DRAWINGS">FIG. <b>10</b>B</figref>, chaff material represented at reference numeral <b>1012</b> is ignored.</p>
<p id="p-0111" num="0110">It is noted that any type of classifier can be utilized for classifying the material in material flow <b>1002</b>. For example, a rules-based classifier can classify weed seeds based on size, shape, and/or color. In another example, a neural network can be trained to identify seeds.</p>
<p id="p-0112" num="0111">Referring again to <figref idref="DRAWINGS">FIG. <b>8</b></figref>, at block <b>826</b> weed seed mapping system <b>606</b> determines a concentration of weed seed within the plant material. That is, one example, block <b>826</b> determines the ratio of crops to weeds within the harvested material. At block <b>827</b>, control logic <b>610</b> can control user interface mechanism <b>642</b> to output an indication of the weed seed processing to operator <b>130</b>. For instance, an augmented view of the weed seed can be provided.</p>
<p id="p-0113" num="0112">At block <b>828</b>, one or more weed seed mitigators are controlled by control logic <b>610</b> generating control signals <b>638</b> to weed mitigation system <b>570</b>. As noted above, this can include any of a wide variety of operations performed by combine <b>400</b>. For example, the chaff treatment system can be controlled at block <b>829</b>. Alternatively, or in addition, a seed crusher is controlled at block <b>830</b>, a seed burner is controlled at block <b>831</b>, a seed collector/bagger is controlled at block <b>832</b>, a seed burier is controlled at block <b>833</b>, and/or chaff discharge can be controlled at block 834.</p>
<p id="p-0114" num="0113">For example, the chaff discharge <b>834</b> can be switched from a spreading mode to a windrowing mode. For instance, when high concentrations of weed seeds are about to be discharged from combine <b>400</b>, the discharge settings can be set to place the material in a windrow for subsequent burning, burying, and/or pickup (by combine <b>400</b> or another machine).</p>
<p id="p-0115" num="0114">Of course, other types of weed seed mitigators can be controlled as well. This is represented by block <b>835</b>.</p>
<p id="p-0116" num="0115">In one example, the control at block <b>828</b> includes adjusting header <b>402</b> of combine <b>400</b>. This is represented at block <b>836</b>. For example, in response to detecting the presence of weed plants in the path of the header, header <b>402</b> can be lowered to ensure that the crops are cut and processed through combine <b>400</b>, so their seeds do not remain on the field. Alternatively, header <b>402</b> can be raised so that the weed area is not harvested. The weed area can be treated on-site (e.g., mechanically) to minimize weed seed spread.</p>
<p id="p-0117" num="0116">In another example, the thresher settings can be adjusted at block <b>837</b>. Alternatively, or in addition, the machine speed can be adjusted at block <b>838</b>. For example, it may be that seed crusher <b>830</b> performs better at lower machine speeds. Thus, the machine can be controlled to a desired speed during operation of the weed seed mitigator.</p>
<p id="p-0118" num="0117">Also, it is noted that the control at block <b>828</b> can be automatic, for example based on weed seed concentration thresholds. This is represented at block <b>839</b>. For example, the weed seed concentration determined at block <b>826</b> can be compared against one or more thresholds and, if a particular threshold is met, one of weed seed mitigators <b>702</b> can be activated. Alternatively, or in addition, the control at block <b>828</b> can be manual, for example based on operator input. This is represented by block <b>840</b>.</p>
<p id="p-0119" num="0118">At block <b>842</b>, the weed seed locations in the field are generated. For example, the weed seed locations can be generated based on one or more factors that affect the movement of the weed seeds once they are released from combine <b>400</b>. For instance, this can be based on the machine speed, location and/or orientation when released. This is represented by block <b>844</b>. Alternatively, or in addition, the locations of the weed seed can be determined based on environmental factors, such as air density, wind, rain, surface water, surface topology, etc. This is represented at block <b>846</b>. Also, the weed seed locations can be generated based on chaff spreader data (e.g., data <b>634</b>). This is represented at block <b>847</b>.</p>
<p id="p-0120" num="0119">The weed seed locations generated at block <b>842</b> can be stored on-board combine <b>400</b> (block <b>848</b>) in data store <b>534</b>. Alternatively, or in addition, the weed seed locations can be sent to a remote system, such as system <b>114</b>, other agricultural machines <b>117</b>, and/or another machine/system (block <b>849</b>). Of course, the weed seed locations can be generated and utilized in other ways as well. This is represented by block <b>850</b>.</p>
<p id="p-0121" num="0120">At block <b>852</b>, other machines are controlled to perform pre-emergent field operations based on the weed seed locations. For instance, a tilling machine can be controlled to perform a tilling operation in treatment areas of the field that correspond to the weed seed locations. This is represented by block <b>853</b>. In another example, a chemical application machine (e.g., a sprayer) is controlled to chemically treat the weed seed locations to destroy the seeds, stimulate early germination, etc. This is represented by block <b>854</b>. In another example, at block <b>855</b>, predation can be enhanced by an application of a substance to the weed seeds. In another example, selective planting can be performed in the next growing season. This is represented by block <b>856</b>. For instance, different crop planting prescriptions can be utilized based on the identification of weed seed areas in the field and/or their corresponding weed seed densities.</p>
<p id="p-0122" num="0121">In another example, operation of a grain processor can be controlled based on the crop/weed ratio. This is represented by block <b>857</b>. For example, when a grain cart is filled by combine <b>400</b>, the weed seed concentration information determined at block <b>826</b> can be utilized to determine a subsequent grain processing operation to remove the weed seeds.</p>
<p id="p-0123" num="0122">Of course, pre-emergent operations can be performed in other ways as well. This is represented by block <b>858</b>.</p>
<p id="p-0124" num="0123">As noted above, in some examples weed plants include a second crop intercropped with a first crop and undergoing simultaneous harvest. In accordance with one example of <figref idref="DRAWINGS">FIG. <b>8</b></figref>, the weed areas identified at block <b>811</b> (e.g., based on the prior-generated weed map obtained at block <b>801</b>, the weed map obtained at block <b>808</b>, etc.) identify areas of the field that contain the second crop. For instance, the weed seed locations <b>640</b> (shown in <figref idref="DRAWINGS">FIG. <b>6</b></figref>) represent second crop locations and can include as-planted maps, crop maps from aerial images, etc.</p>
<p id="p-0125" num="0124">Further, the operations controlled at blocks <b>828</b> and/or <b>852</b> can be configured to nondestructively collect and segregate the second crop (&#x201c;the weed&#x201d;) from the first crop. For sake of illustration, at block <b>832</b> a seed collector/bagger is configured to segregate and collect the second crop. In another example, adjustments can be made (e.g., blocks <b>836</b>, <b>837</b>, etc.) to collect and keep both crops together for later separation with minimal (or at least reduced) harvest losses in the field.</p>
<p id="p-0126" num="0125">In one example, the seed collector/bagger is equipped with a crop sensor for measuring the yield or other attributes (e.g., moisture, oil, protein, starch, etc.) of the second crop. These yield and crop attribute measurements can be displayed to an operator (in place of or in addition to the those of the first crop), georeferenced and stored on a map, and/or used for machine control.</p>
<p id="p-0127" num="0126">It can thus be seen that the present system provides a number of advantages. For example, but not by limitation, the present system provides site-specific agricultural operations to mitigate weeds by identifying, before emergence, the locations of the weed seeds. Further, the weed seed locations can be accurately determined by taking into account machine data, environmental data, and/or any other data utilized to model weed seed movement. Using those weed seed locations, the weeds (including herbicide resistant varieties) can be mitigated. This can increase yields, while reducing the application of chemicals to the fields and/or machine operations (e.g., sprayer operation over the field to chemically treat weeds post-emergence. This, in turn, can decrease power/fuel consumption, reduced machine wear and tear, and/or otherwise increase efficiencies/productively of the agricultural operations.</p>
<p id="p-0128" num="0127">It will be noted that the above discussion has described a variety of different systems, components and/or logic. It will be appreciated that such systems, components and/or logic can be comprised of hardware items (such as processors and associated memory, or other processing components, some of which are described below) that perform the functions associated with those systems, components and/or logic. In addition, the systems, components and/or logic can be comprised of software that is loaded into a memory and is subsequently executed by a processor or server, or other computing component, as described below. The systems, components and/or logic can also be comprised of different combinations of hardware, software, firmware, etc., some examples of which are described below. These are only some examples of different structures that can be used to form the systems, components and/or logic described above. Other structures can be used as well.</p>
<p id="p-0129" num="0128">The present discussion has mentioned processors, processing systems, controllers and/or servers. In one example, these can include computer processors with associated memory and timing circuitry, not separately shown. They are functional parts of the systems or devices to which they belong and are activated by, and facilitate the functionality of the other components or items in those systems.</p>
<p id="p-0130" num="0129">Also, a number of user interface displays have been discussed. They can take a wide variety of different forms and can have a wide variety of different user actuatable input mechanisms disposed thereon. For instance, the user actuatable input mechanisms can be text boxes, check boxes, icons, links, drop-down menus, search boxes, etc. They can also be actuated in a wide variety of different ways. For instance, they can be actuated using a point and click device (such as a track ball or mouse). They can be actuated using hardware buttons, switches, a joystick or keyboard, thumb switches or thumb pads, etc. They can also be actuated using a virtual keyboard or other virtual actuators. In addition, where the screen on which they are displayed is a touch sensitive screen, they can be actuated using touch gestures. Also, where the device that displays them has speech recognition components, they can be actuated using speech commands.</p>
<p id="p-0131" num="0130">A number of data stores have also been discussed. It will be noted they can each be broken into multiple data stores. All can be local to the systems accessing them, all can be remote, or some can be local while others are remote. All of these configurations are contemplated herein.</p>
<p id="p-0132" num="0131">Also, the figures show a number of blocks with functionality ascribed to each block. It will be noted that fewer blocks can be used so the functionality is performed by fewer components. Also, more blocks can be used with the functionality distributed among more components.</p>
<p id="p-0133" num="0132"><figref idref="DRAWINGS">FIG. <b>11</b></figref> is a block diagram of one example of the architecture shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, where machine <b>400</b> communicates with elements in a remote server architecture <b>900</b>. In an example, remote server architecture <b>900</b> can provide computation, software, data access, and storage services that do not require end-user knowledge of the physical location or configuration of the system that delivers the services. In various examples, remote servers can deliver the services over a wide area network, such as the internet, using appropriate protocols. For instance, remote servers can deliver applications over a wide area network and they can be accessed through a web browser or any other computing component. Software or components shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> as well as the corresponding data, can be stored on servers at a remote location. The computing resources in a remote server environment can be consolidated at a remote data center location or they can be dispersed. Remote server infrastructures can deliver services through shared data centers, even though they appear as a single point of access for the user. Thus, the components and functions described herein can be provided from a remote server at a remote location using a remote server architecture. Alternatively, they can be provided from a conventional server, or they can be installed on client devices directly, or in other ways.</p>
<p id="p-0134" num="0133">In the example shown in <figref idref="DRAWINGS">FIG. <b>11</b></figref>, some items are similar to those shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref> and they are similarly numbered. <figref idref="DRAWINGS">FIG. <b>11</b></figref> specifically shows that system <b>124</b>, system <b>126</b>, system <b>540</b>, and/or data store <b>534</b> can be located at a remote server location <b>902</b>. Therefore, agricultural machine <b>400</b>, machine(s) <b>115</b>, machine(s) <b>117</b>, and/or system(s) <b>114</b> access those systems through remote server location <b>902</b>.</p>
<p id="p-0135" num="0134"><figref idref="DRAWINGS">FIG. <b>11</b></figref> also depicts another example of a remote server architecture. <figref idref="DRAWINGS">FIG. <b>11</b></figref> shows that it is also contemplated that some elements of <figref idref="DRAWINGS">FIG. <b>5</b></figref> are disposed at remote server location <b>902</b> while others are not. By way of example, data store <b>534</b> can be disposed at a location separate from location <b>902</b>, and accessed through the remote server at location <b>902</b>. Alternatively, or in addition, one or more of systems <b>124</b>, <b>126</b>, and <b>540</b> can be disposed at location(s) separate from location <b>902</b>, and accessed through the remote server at location <b>902</b>.</p>
<p id="p-0136" num="0135">Regardless of where they are located, they can be accessed directly by agricultural machine <b>400</b>, through a network (either a wide area network or a local area network), they can be hosted at a remote site by a service, or they can be provided as a service, or accessed by a connection service that resides in a remote location. Also, the data can be stored in substantially any location and intermittently accessed by, or forwarded to, interested parties. For instance, physical carriers can be used instead of, or in addition to, electromagnetic wave carriers. In such an example, where cell coverage is poor or nonexistent, another mobile machine (such as a fuel truck) can have an automated information collection system. As the agricultural machine comes close to the fuel truck for fueling, the system automatically collects the information from the machine or transfers information to the machine using any type of ad-hoc wireless connection. The collected information can then be forwarded to the main network as the fuel truck reaches a location where there is cellular coverage (or other wireless coverage). For instance, the fuel truck may enter a covered location when traveling to fuel other machines or when at a main fuel storage location. All of these architectures are contemplated herein. Further, the information can be stored on the agricultural machine until the agricultural machine enters a covered location. The agricultural machine, itself, can then send and receive the information to/from the main network.</p>
<p id="p-0137" num="0136">It will also be noted that the elements of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, or portions of them, can be disposed on a wide variety of different devices. Some of those devices include servers, desktop computers, laptop computers, tablet computers, or other mobile devices, such as palm top computers, cell phones, smart phones, multimedia players, personal digital assistants, etc.</p>
<p id="p-0138" num="0137"><figref idref="DRAWINGS">FIG. <b>12</b></figref> is a simplified block diagram of one illustrative example of a handheld or mobile computing device that can be used as a user&#x2019;s or client&#x2019;s handheld device <b>16</b>, in which the present system (or parts of it) can be deployed. For instance, a mobile device can be deployed in the operator compartment of agricultural machine <b>400</b> or as remote computing system <b>114</b>. <figref idref="DRAWINGS">FIGS. <b>13</b>-<b>14</b></figref> are examples of handheld or mobile devices.</p>
<p id="p-0139" num="0138"><figref idref="DRAWINGS">FIG. <b>12</b></figref> provides a general block diagram of the components of a client device <b>16</b> that can run some components shown in <figref idref="DRAWINGS">FIG. <b>5</b></figref>, that interacts with them, or both. In the device <b>16</b>, a communications link <b>13</b> is provided that allows the handheld device to communicate with other computing devices and under some embodiments provides a channel for receiving information automatically, such as by scanning. Examples of communications link <b>13</b> include allowing communication though one or more communication protocols, such as wireless services used to provide cellular access to a network, as well as protocols that provide local wireless connections to networks.</p>
<p id="p-0140" num="0139">In other examples, applications can be received on a removable Secure Digital (SD) card that is connected to an interface <b>15</b>. Interface <b>15</b> and communication links <b>13</b> communicate with a processor <b>17</b> (which can also embody processors or servers from previous FIGS.) along a bus <b>19</b> that is also connected to memory <b>21</b> and input/output (I/O) components <b>23</b>, as well as clock <b>25</b> and location system <b>27</b>.</p>
<p id="p-0141" num="0140">I/O components <b>23</b>, in one example, are provided to facilitate input and output operations. I/O components <b>23</b> for various embodiments of the device <b>16</b> can include input components such as buttons, touch sensors, optical sensors, microphones, touch screens, proximity sensors, accelerometers, orientation sensors and output components such as a display device, a speaker, and or a printer port. Other I/O components <b>23</b> can be used as well.</p>
<p id="p-0142" num="0141">Clock <b>25</b> illustratively comprises a real time clock component that outputs a time and date. It can also, illustratively, provide timing functions for processor <b>17</b>.</p>
<p id="p-0143" num="0142">Location system <b>27</b> illustratively includes a component that outputs a current geographical location of device <b>16</b>. This can include, for instance, a global positioning system (GPS) receiver, a LORAN system, a dead reckoning system, a cellular triangulation system, or other positioning system. It can also include, for example, mapping software or navigation software that generates desired maps, navigation routes and other geographic functions.</p>
<p id="p-0144" num="0143">Memory <b>21</b> stores operating system <b>29</b>, network settings <b>31</b>, applications <b>33</b>, application configuration settings <b>35</b>, data store <b>37</b>, communication drivers <b>39</b>, and communication configuration settings <b>41</b>. Memory <b>21</b> can include all types of tangible volatile and non-volatile computer-readable memory devices. It can also include computer storage media (described below). Memory <b>21</b> stores computer readable instructions that, when executed by processor <b>17</b>, cause the processor to perform computer-implemented steps or functions according to the instructions. Processor <b>17</b> can be activated by other components to facilitate their functionality as well.</p>
<p id="p-0145" num="0144"><figref idref="DRAWINGS">FIG. <b>13</b></figref> shows one example in which device <b>16</b> is a tablet computer <b>950</b>. In <figref idref="DRAWINGS">FIG. <b>13</b></figref>, computer <b>950</b> is shown with user interface display screen <b>952</b>. Screen <b>952</b> can be a touch screen or a pen-enabled interface that receives inputs from a pen or stylus. It can also use an on-screen virtual keyboard. Of course, it might also be attached to a keyboard or other user input device through a suitable attachment mechanism, such as a wireless link or USB port, for instance. Computer <b>950</b> can also illustratively receive voice inputs as well.</p>
<p id="p-0146" num="0145"><figref idref="DRAWINGS">FIG. <b>14</b></figref> shows that the device can be a smart phone <b>71</b>. Smart phone <b>71</b> has a touch sensitive display <b>73</b> that displays icons or tiles or other user input mechanisms <b>75</b>. Mechanisms <b>75</b> can be used by a user to run applications, make calls, perform data transfer operations, etc. In general, smart phone <b>71</b> is built on a mobile operating system and offers more advanced computing capability and connectivity than a feature phone.</p>
<p id="p-0147" num="0146">Note that other forms of the devices <b>16</b> are possible.</p>
<p id="p-0148" num="0147"><figref idref="DRAWINGS">FIG. <b>15</b></figref> is one example of a computing environment in which elements of <figref idref="DRAWINGS">FIG. <b>5</b></figref>, or parts of it, (for example) can be deployed. With reference to <figref idref="DRAWINGS">FIG. <b>15</b></figref>, an example system for implementing some embodiments includes a computing device in the form of a computer <b>1010</b>. Components of computer <b>1010</b> may include, but are not limited to, a processing unit <b>1020</b> (which can comprise processors or servers from previous FIGS.), a system memory <b>1030</b>, and a system bus <b>1021</b> that couples various system components including the system memory to the processing unit <b>1020</b>. The system bus <b>1021</b> may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. Memory and programs described with respect to <figref idref="DRAWINGS">FIG. <b>5</b></figref> can be deployed in corresponding portions of <figref idref="DRAWINGS">FIG. <b>15</b></figref>.</p>
<p id="p-0149" num="0148">Computer <b>1010</b> typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer <b>1010</b> and includes both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer readable media may comprise computer storage media and communication media. Computer storage media is different from, and does not include, a modulated data signal or carrier wave. It includes hardware storage media including both volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computer <b>1010</b>. Communication media may embody computer readable instructions, data structures, program modules or other data in a transport mechanism and includes any information delivery media. The term &#x201c;modulated data signal&#x201d; means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.</p>
<p id="p-0150" num="0149">The system memory <b>1030</b> includes computer storage media in the form of volatile and/or nonvolatile memory such as read only memory (ROM) <b>1031</b> and random access memory (RAM) <b>1032</b>. A basic input/output system <b>1033</b> (BIOS), containing the basic routines that help to transfer information between elements within computer <b>1010</b>, such as during start-up, is typically stored in ROM <b>1031</b>. RAM <b>1032</b> typically contains data and/or program modules that are immediately accessible to and/or presently being operated on by processing unit <b>1020</b>. By way of example, and not limitation, <figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates operating system <b>1034</b>, application programs <b>1035</b>, other program modules <b>1036</b>, and program data <b>1037</b>.</p>
<p id="p-0151" num="0150">The computer <b>1010</b> may also include other removable/non-removable volatile/nonvolatile computer storage media. By way of example only, <figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates a hard disk drive <b>1041</b> that reads from or writes to non-removable, nonvolatile magnetic media, an optical disk drive <b>1055</b>, and nonvolatile optical disk <b>1056</b>. The hard disk drive <b>1041</b> is typically connected to the system bus <b>1021</b> through a non-removable memory interface such as interface <b>1040</b>, and optical disk drive <b>1055</b> is typically connected to the system bus <b>1021</b> by a removable memory interface, such as interface <b>1050</b>.</p>
<p id="p-0152" num="0151">Alternatively, or in addition, the functionality described herein can be performed, at least in part, by one or more hardware logic components. For example, and without limitation, illustrative types of hardware logic components that can be used include Field-programmable Gate Arrays (FPGAs), Application-specific Integrated Circuits (e.g., ASICs), Application-specific Standard Products (e.g., ASSPs), System-on-a-chip systems (SOCs), Complex Programmable Logic Devices (CPLDs), etc.</p>
<p id="p-0153" num="0152">The drives and their associated computer storage media discussed above and illustrated in <figref idref="DRAWINGS">FIG. <b>15</b></figref>, provide storage of computer readable instructions, data structures, program modules and other data for the computer <b>1010</b>. In <figref idref="DRAWINGS">FIG. <b>15</b></figref>, for example, hard disk drive <b>1041</b> is illustrated as storing operating system <b>1044</b>, application programs <b>1045</b>, other program modules <b>1046</b>, and program data <b>1047</b>. Note that these components can either be the same as or different from operating system <b>1034</b>, application programs <b>1035</b>, other program modules <b>1036</b>, and program data <b>1037</b>.</p>
<p id="p-0154" num="0153">A user may enter commands and information into the computer <b>1010</b> through input devices such as a keyboard <b>1062</b>, a microphone <b>1063</b>, and a pointing device <b>1061</b>, such as a mouse, trackball or touch pad. Other input devices (not shown) may include a joystick, game pad, satellite dish, scanner, or the like. These and other input devices are often connected to the processing unit <b>1020</b> through a user input interface <b>1060</b> that is coupled to the system bus, but may be connected by other interface and bus structures. A visual display <b>1091</b> or other type of display device is also connected to the system bus <b>1021</b> via an interface, such as a video interface <b>1090</b>. In addition to the monitor, computers may also include other peripheral output devices such as speakers <b>1097</b> and printer <b>1096</b>, which may be connected through an output peripheral interface <b>1095</b>.</p>
<p id="p-0155" num="0154">The computer <b>1010</b> is operated in a networked environment using logical connections (such as a local area network - LAN, or wide area network - WAN or a controller area network - CAN) to one or more remote computers, such as a remote computer <b>1080</b>.</p>
<p id="p-0156" num="0155">When used in a LAN networking environment, the computer <b>1010</b> is connected to the LAN <b>1071</b> through a network interface or adapter <b>1070</b>. When used in a WAN networking environment, the computer <b>1010</b> typically includes a modem <b>1072</b> or other means for establishing communications over the WAN <b>1073</b>, such as the Internet. In a networked environment, program modules may be stored in a remote memory storage device. <figref idref="DRAWINGS">FIG. <b>15</b></figref> illustrates, for example, that remote application programs <b>1085</b> can reside on remote computer <b>1080</b>.</p>
<p id="p-0157" num="0156">It should also be noted that the different examples described herein can be combined in different ways. That is, parts of one or more examples can be combined with parts of one or more other examples. All of this is contemplated herein.</p>
<p id="p-0158" num="0157">Example 1 is an agricultural harvesting machine comprising:
<ul id="ul0001" list-style="none">
<li id="ul0001-0001" num="0158">a crop processing functionality configured to engage crop in a field, perform a crop processing operation on the crop, and move the processed crop to a harvested crop repository; and</li>
<li id="ul0001-0002" num="0159">a control system configured to:
<ul id="ul0002" list-style="none">
<li id="ul0002-0001" num="0160">identify a weed seed area indicating presence of weed seeds; and</li>
<li id="ul0002-0002" num="0161">generate a control signal associated with a pre-emergence weed seed treatment operation based on the identified weed seed area.</li>
</ul>
</li>
</ul>
</p>
<p id="p-0159" num="0162">Example 2 is the agricultural harvesting machine of any or all previous examples, wherein the control signal controls a pre-emergence weed seed mitigator to perform the pre-emergence weed seed treatment operation.</p>
<p id="p-0160" num="0163">Example 3 is the agricultural harvesting machine of any or all previous examples, wherein the pre-emergence weed seed mitigator is on-board the agricultural harvesting machine.</p>
<p id="p-0161" num="0164">Example 4 is the agricultural harvesting machine of any or all previous examples, wherein the pre-emergence weed seed mitigator is separate from the agricultural harvesting machine.</p>
<p id="p-0162" num="0165">Example 5 is the agricultural harvesting machine of any or all previous examples, wherein the pre-emergence weed seed mitigator comprises a weed seed collector configured to collect the weed seeds.</p>
<p id="p-0163" num="0166">Example 6 is the agricultural harvesting machine of any or all previous examples, wherein the pre-emergence weed seed treatment operation devitalizes the weed seeds.</p>
<p id="p-0164" num="0167">Example 7 is the agricultural harvesting machine of any or all previous examples, wherein the pre-emergence weed seed mitigator comprises at least one of:
<ul id="ul0003" list-style="none">
<li id="ul0003-0001" num="0168">a weed seed burier configured to bury the weed seeds in the field,</li>
<li id="ul0003-0002" num="0169">a weed seed crusher configured to mechanically crush the weed seeds,</li>
<li id="ul0003-0003" num="0170">a thermal weed seed treatment device configured to thermally treat the weed seeds, or</li>
<li id="ul0003-0004" num="0171">a chemical weed seed treatment device configured to chemically treat the weed seeds.</li>
</ul>
</p>
<p id="p-0165" num="0172">Example 8 is the agricultural harvesting machine of any or all previous examples, wherein the control signal controls at least one of:
<ul id="ul0004" list-style="none">
<li id="ul0004-0001" num="0173">a display device to display an indication of the weed seed area to an operator, or</li>
<li id="ul0004-0002" num="0174">a data storage device to store an indication of the identified weed seed area.</li>
</ul>
</p>
<p id="p-0166" num="0175">Example 9 is the agricultural harvesting machine of any or all previous examples, wherein the weed seed area is identified based on an a priori weed map.</p>
<p id="p-0167" num="0176">Example 10 is the agricultural harvesting machine of any or all previous examples, and further comprising: 
<ul id="ul0005" list-style="none">
<li id="ul0005-0001" num="0177">an imaging sensor, wherein the weed seed area is identified based on one or more images, obtained from the imaging sensor, of the field in a path of the agricultural harvesting machine.</li>
</ul>
</p>
<p id="p-0168" num="0178">Example 11 is the agricultural harvesting machine of any or all previous examples, and further comprising:
<ul id="ul0006" list-style="none">
<li id="ul0006-0001" num="0179">a weed seed detector configured to detect weed seeds, wherein the weed seed area is identified based on a weed seed presence signal received from the weed seed detector.</li>
</ul>
</p>
<p id="p-0169" num="0180">Example 12 is the agricultural harvesting machine of any or all previous examples, wherein the weed seed area is identified based on a weed seed movement model that models movement of the weed seeds.</p>
<p id="p-0170" num="0181">Example 13 is the agricultural harvesting machine of any or all previous examples, wherein the weed seed movement model is based on machine delay compensation that represents movement of the weed seeds through the agricultural harvesting machine.</p>
<p id="p-0171" num="0182">Example 14 is the agricultural harvesting machine of any or all previous examples, wherein the weed seed area is identified based on chaff spreader data received from a chaff spreader sensor on the agricultural harvesting machine.</p>
<p id="p-0172" num="0183">Example 15 is the agricultural harvesting machine of any or all previous examples, wherein the weed seed area is identified based on at least one of:
<ul id="ul0007" list-style="none">
<li id="ul0007-0001" num="0184">environment data representing an environment of the field,</li>
<li id="ul0007-0002" num="0185">terrain data representing a terrain of the field, or</li>
<li id="ul0007-0003" num="0186">machine data representing machine operating characteristics.</li>
</ul>
</p>
<p id="p-0173" num="0187">Example 16 is a method performed by an agricultural machine, the method comprising:
<ul id="ul0008" list-style="none">
<li id="ul0008-0001" num="0188">obtaining a weed seed movement model that models movement of weed seeds during a crop processing operation that engages crop in a field and moves the processed crop to a harvested crop repository;</li>
<li id="ul0008-0002" num="0189">identifying a weed seed area based on the weed seed movement model; and</li>
<li id="ul0008-0003" num="0190">generating a control signal associated with a pre-emergence weed seed treatment operation based on the identified weed seed area.</li>
</ul>
</p>
<p id="p-0174" num="0191">Example 17 is the method of any or all previous examples, and further comprising: obtaining a weed map that identifies weed area in the field; and
<ul id="ul0009" list-style="none">
<li id="ul0009-0001" num="0192">applying the weed seed movement model to determining movement of the weed seeds from the identified weed area; and</li>
<li id="ul0009-0002" num="0193">identifying the weed area based on the determined movement.</li>
</ul>
</p>
<p id="p-0175" num="0194">Example 18 is the method of any or all previous examples, wherein the weed seed movement model is based on at least one of:
<ul id="ul0010" list-style="none">
<li id="ul0010-0001" num="0195">environment data representing an environment of the field,</li>
<li id="ul0010-0002" num="0196">terrain data representing a terrain of the field, or</li>
<li id="ul0010-0003" num="0197">machine data representing machine operating characteristics.</li>
</ul>
</p>
<p id="p-0176" num="0198">Example 19 is a computing system comprising:
<ul id="ul0011" list-style="none">
<li id="ul0011-0001" num="0199">at least one processor; and</li>
<li id="ul0011-0002" num="0200">memory storing instructions executable by the at least one processor, wherein the instructions, when executed, cause the computing system to:</li>
<li id="ul0011-0003" num="0201">identify a weed seed area indicating presence of weed seeds on a field during a harvesting operation that harvests crops from the field; and</li>
<li id="ul0011-0004" num="0202">generate a control signal associated with a pre-emergence weed seed treatment operation based on the identified weed seed area.</li>
</ul>
</p>
<p id="p-0177" num="0203">Example 20 is the computing system of any or all previous examples, wherein the instructions cause the computing system to identify the weed seed area based on a weed seed movement model models the movement of weed seeds based on at least one of:
<ul id="ul0012" list-style="none">
<li id="ul0012-0001" num="0204">environment data representing an environment of the field,</li>
<li id="ul0012-0002" num="0205">terrain data representing a terrain of the field, or</li>
<li id="ul0012-0003" num="0206">machine data representing machine operating characteristics.</li>
</ul>
</p>
<p id="p-0178" num="0207">Although the subject matter has been described in language specific to structural features and/or methodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather, the specific features and acts described above are disclosed as example forms of implementing the claims.</p>
<?detailed-description description="Detailed Description" end="tail"?>
</description>
<us-claim-statement>What is claimed is:</us-claim-statement>
<claims id="claims">
<claim id="CLM-00001" num="00001">
<claim-text><b>1</b>. An agricultural harvesting machine comprising:
<claim-text>crop processing functionality configured to engage crop in a field, perform a crop processing operation on the crop to obtain processed crop, and move the processed crop to a harvested crop repository; and</claim-text>
<claim-text>a control system configured to:
<claim-text>identify a weed seed area indicating presence of weed seeds based on a weed seed movement model that projects likely locations of the weed seeds given a location of one or more weed plants in the field that produced the weed seeds; and</claim-text>
<claim-text>generate a control signal associated with a pre-emergence weed seed treatment operation on the weed seeds, prior to emergence of the weed seeds, based on the weed seed area.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00002" num="00002">
<claim-text><b>2</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the weed seed movement model represents machine delay compensation and models a distance, relative to a surface of the field, between:
<claim-text>when a weed plant that carried the weed seeds is cut by the agricultural harvesting machine, and</claim-text>
<claim-text>the weed seeds are discharged on to the surface of the field by the agricultural harvesting machine.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00003" num="00003">
<claim-text><b>3</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the weed seed area is identified based on chaff spreader data received from a chaff spreader sensor on the agricultural harvesting machine, wherein the chaff spreader data represents chaff ejected from the agricultural harvesting machine during the crop processing operation.</claim-text>
</claim>
<claim id="CLM-00004" num="00004">
<claim-text><b>4</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the weed seed area is identified based on environment data representing an environment of the field.</claim-text>
</claim>
<claim id="CLM-00005" num="00005">
<claim-text><b>5</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the weed seed area is identified based on terrain data representing a terrain of the field.</claim-text>
</claim>
<claim id="CLM-00006" num="00006">
<claim-text><b>6</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the weed seed area is identified based on machine data representing machine operating characteristics.</claim-text>
</claim>
<claim id="CLM-00007" num="00007">
<claim-text><b>7</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control signal controls a pre-emergence weed seed mitigator to perform the pre-emergence weed seed treatment operation on the weed seeds prior to emergence of the weed seeds.</claim-text>
</claim>
<claim id="CLM-00008" num="00008">
<claim-text><b>8</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the pre-emergence weed seed mitigator is on-board the agricultural harvesting machine.</claim-text>
</claim>
<claim id="CLM-00009" num="00009">
<claim-text><b>9</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the pre-emergence weed seed mitigator comprises a mitigator machine that is separate from the agricultural harvesting machine, wherein the control system is configured to transmit the control signal to the mitigator machine.</claim-text>
</claim>
<claim id="CLM-00010" num="00010">
<claim-text><b>10</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the pre-emergence weed seed mitigator comprises:
<claim-text>a weed seed collector configured to collect the weed seeds.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00011" num="00011">
<claim-text><b>11</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the pre-emergence weed seed treatment operation devitalizes the weed seeds.</claim-text>
</claim>
<claim id="CLM-00012" num="00012">
<claim-text><b>12</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the pre-emergence weed seed mitigator comprises at least one of:
<claim-text>a weed seed burier configured to bury the weed seeds in the field,</claim-text>
<claim-text>a weed seed crusher configured to mechanically crush the weed seeds,</claim-text>
<claim-text>a thermal weed seed treatment device configured to thermally treat the weed seeds, or</claim-text>
<claim-text>a chemical weed seed treatment device configured to chemically treat the weed seeds.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00013" num="00013">
<claim-text><b>13</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the control signal controls at least one of:
<claim-text>a display device to display an indication of the weed seed area to an operator, or</claim-text>
<claim-text>a data storage device to store an indication of the weed seed area.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00014" num="00014">
<claim-text><b>14</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the weed seed area is identified based on an a priori weed map.</claim-text>
</claim>
<claim id="CLM-00015" num="00015">
<claim-text><b>15</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00001">claim 1</claim-ref>, and further comprising:
<claim-text>an imaging sensor, wherein the weed seed area is identified based on one or more images, obtained from the imaging sensor, of the field in a path of the agricultural harvesting machine.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00016" num="00016">
<claim-text><b>16</b>. The agricultural harvesting machine of <claim-ref idref="CLM-00001">claim 1</claim-ref>, and further comprising:
<claim-text>a weed seed detector configured to detect weed seeds, wherein the weed seed area is identified based on a weed seed presence signal received from the weed seed detector.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00017" num="00017">
<claim-text><b>17</b>. A method performed by an agricultural machine, the method comprising:
<claim-text>obtaining a weed seed movement model that models movement of weed seeds during a crop processing operation that engages crop in a field and moves the processed crop to a harvested crop repository;</claim-text>
<claim-text>identifying a weed seed area based on the weed seed movement model; and</claim-text>
<claim-text>generating a control signal associated with a pre-emergence weed seed treatment operation based on the weed seed area.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00018" num="00018">
<claim-text><b>18</b>. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, and further comprising:
<claim-text>obtaining a weed map that identifies weed area in the field; and</claim-text>
<claim-text>applying the weed seed movement model to determining movement of the weed seeds from the identified weed area; and</claim-text>
<claim-text>identifying the weed area based on the determined movement.</claim-text>
</claim-text>
</claim>
<claim id="CLM-00019" num="00019">
<claim-text><b>19</b>. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein 
<claim-text>the agricultural machine comprises a harvesting machine,</claim-text>
<claim-text>the crop processing operation comprises a harvesting operation, and</claim-text>
<claim-text>the weed seed movement model is based on at least one of: 
<claim-text>environment data representing an environment of the field during the harvesting operation,</claim-text>
<claim-text>terrain data representing a terrain of the field, or</claim-text>
<claim-text>harvesting machine data representing machine operating characteristics of the harvesting machine used to perform the harvesting operation.</claim-text>
</claim-text>
</claim-text>
</claim>
<claim id="CLM-00020" num="00020">
<claim-text><b>20</b>. A control system for an agricultural harvesting machine, the control system comprising: 
<claim-text>at least one processor; and
<claim-text>memory storing instructions executable by the at least one processor, wherein the instructions, when executed, cause the control system to:
<claim-text>control crop processing functionality of the agricultural harvesting machine to engage crop in a field, perform a crop processing operation on the crop to obtain processed crop, and move the processed crop to a harvested crop repository;</claim-text>
<claim-text>identify a weed seed area indicating presence of weed seeds based on a weed seed movement model that projects likely locations of the weed seeds given a location of one or more weed plants in the field that produced the weed seeds; and</claim-text>
<claim-text>generate a control signal associated with a pre-emergence weed seed treatment operation on the weed seeds, prior to emergence of the weed seeds, based on the weed seed area.</claim-text>
</claim-text>
</claim-text>
</claim-text>
</claim>
</claims>
</us-patent-application>
